{"meta":{"title":"逍客 - Stay Happy and Enjoy Life!","subtitle":"保持快乐 享受生活; 放下自我 换位思维。","description":"旧书的个人网站，记录生活点滴，也可能记录了各种心得；同时会分享一些没好的照片和户外活动内容。","author":"Joe Li","url":"http://it.jiu-shu.com"},"pages":[],"posts":[{"title":"符号英语","slug":"English-Material/symbol-english","date":"2018-12-21T01:49:27.259Z","updated":"2018-12-24T02:41:24.620Z","comments":true,"path":"English-Material/symbol-english/","link":"","permalink":"http://it.jiu-shu.com/English-Material/symbol-english/","excerpt":"","text":"符号英语表达汇总 ` back quote 反引号 ~ tilde ! exclaim @ at # number sign,英语国家是hash，美语是pound,音乐里作- - sharp,如C# $ dollar % percent ^ caret &amp; ampersand * asterisk, star(美语),数学公式中作multiply ( parenleft,opening parentheses ) parenright,closing paretheses minus; hyphen连字符,不读 _ underscore + plus = equal [ bracketleft,opening bracket ] bracketright,closing bracket { bracelet } brace right ; semicolon : colon ‘ quote “ double quote / slash \\ backslash 反斜杠 | bar , comma &lt; less > greater . period ? question space 空格 下面是一些特殊符号的英文读法,主要是数学符号 ＜ is less than ＞ is more than ≮ is not less than ≯ is not more than ≤ is less than or equal to 小于或等于号 hyphen 连字符 ≥ is more than or equal to 大于或等于号 ‘ apostrophe 省略号,英文中省略字符用的撇号;所有格符号 ％ percent － dash 破折号 ‰ per mille ∞ infinity 无限大号 ∝ varies as 与…成比例 ( ) parentheses 圆括号 √ (square) root 平方根 square brackets 方括号 ∵ since; because 因为 《 》 French quotes 法文引号;书名号 ∴ hence 所以 … ellipsis 省略号 ∷ equals, as (proportion) 等于，成比例 ¨ tandem colon 双点号 ∠ angle 角 ∶ ditto 双点号 ⌒ semicircle 半圆 ‖ parallel 双线号 ⊙ circle 圆 ／ virgule 斜线号 ○ circumference 圆周 ～ swung dash 代字号 △ triangle 三角形 § section; division 分节号 ⊥ perpendicular to 垂直于 → arrow 箭号；参见号 ∪ union of 并，合集 ∩ intersection of 交，通集 ∫ the integral of …的积分 ± plus or minus 正负号 ∑ summation of 总和 × is multiplied by 乘号 ° degree 度 ÷ is divided by 除号 ′ minute 分 ″ second 秒 ≠ is not equal to 不等于号 ≡ is equivalent to 全等于号 ℃ Celsius degree 摄氏度 ≌ is equal to or approximately equal to 等于或约等于号 再附送希腊字母的读法 α Α alpha [‘&aelig;lfa] β Β beta [‘bi:ta / ‘beita] γ Γ gamma [‘g&aelig;ma] δ Δ delta [‘delta] ε Ε epsilon [‘epsilan / ep’sailan] ζ Ζ zeta [‘zi:ta] η Η eta [‘i:ta / ‘eita] θ Θ theta [‘θita] ι Ι iota [ai’outa] κ Κ kappa [‘k&aelig;pa] λ Λ lamda [‘l&aelig;mda] μ Μ mu [mju:] ν Ν nu [nju:] ξ Ξ xi [ksai / gzai / zai] ο Ο omicron [ou’maikran] π Π pi [pai] ρ Ρ rho [rou] σ Σ sigma [‘sigma] τ Τ tau [tau] υ Υ upsilon [‘ju:psilon / ju:p’sailan] o 是反 c 。 φ Φ phi [fai] χ Χ chi [kai] ψ Ψ psi [psi:] ω Ω omega [‘oumiga / ou’mi:ga]","categories":[],"tags":[]},{"title":"Spring Data Elasticsearch 快速上手全文检索","slug":"Elastic-Technologies/spring-data-elasticsearch-quick-start","date":"2018-12-21T01:49:27.254Z","updated":"2018-12-21T02:47:14.867Z","comments":true,"path":"Elastic-Technologies/spring-data-elasticsearch-quick-start/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/spring-data-elasticsearch-quick-start/","excerpt":"","text":"通过Spring Data Elasticsearch 实现全文检索; 通过指定 boost 来控制查询语句的相对的权重; 通过自定义ResultMapper 来实现查询聚合功能。 Elasticsearch 基础知识建立对Elasticsearch的初步的认识可以参考：https://mp.weixin.qq.com/s/stC_xMP1n3aQ-0ZNAc3eQA 上面的有些解释只是为了方便初学者快速掌握知识。ES的索引的Type在后期ES中会逐渐消失。https://www.elastic.co/guide/en/elasticsearch/reference/current/removal-of-types.html 官方的中文文档参考： https://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html 版本 Spring Boot： 1.4.7 Spring Data Elasticsearch 2.0.11 Elasticsearch server 2.4 追加补充： 在随后的版本spring-data-elasticsearch 2.1.10.RELEASE 中增加了AggregatedPage ， 同时org.springframework.data.elasticsearch.core.DefaultResultMapper 也增加了聚合的支持。 笔者这里针对聚合的有部分工作，在2.1.10.RELEASE种已经不在需要，或者可以更优化一些。 安装与运行Elasticsearch 安装及运行elasticsearch 是运行于java之上，可以直接下载运行。从https://www.elastic.co/downloads/past-releases/elasticsearch-2-4-6 下载2.4.6 版本。 ZIP sha —– window安装包 TAR sha —– Mac 或者linux安装包 DEB sha RPM sha —– linux rpm 包可以安装成系统服务 ZIP包解压的直接进入 bin 目录运行 ./elasticserach, 运行 ./elasticsearch -d 后台运行 RPM 安装后通过 service elasticsearch start 来启动 Kibana 安装及运行 和es的类似，elasticsearch2.4 对应kibana的版本是4.6； 下载地址： https://www.elastic.co/downloads/past-releases/kibana-4-6-6 kibana 解压方式无后台运行命令，建议通过rpm方式安装sudo rpm -ivh kibana-4.6.6-x86_64.rpm , 以服务方式启动和停止。 安装Kibana的Sense插件此版本下没有dev tools，需要单独安装sense插件, 进入Kibana 的安装目录 /opt/kibana 运行./bin/kibana plugin --install elastic/sense。 代码https://github.com/choelea/spring-data-elasticsearch-quick-start 2.0.11.RELEASE123git clone https://github.com/choelea/spring-data-elasticsearch-quick-startcd spring-data-elasticsearch-quick-start/git checkout tags/2.0.11.RELEASE 最新的master的代码升级Spring Boot到1.5.13.RELEASE， 对应的spring-data-elasticsearch 自动升级至2.1.12.RELEASE， 在此版本基础上，DefaultResultMapper 已经支持了聚合。无需为聚合儿自定义ResultMapper。 配置12spring.data.elasticsearch.repositories.enabled = truespring.data.elasticsearch.cluster-nodes : 192.168.1.99:9300 定义Document参考： com.joe.springdataelasticsearch.document.ProductDoc . 定义文档需要注意必须有个id字段或者通过注解指定一个id字段，只有在有ID得情况下，文档才可以被更新。 否则会抛出异常：No id property found for class com.joe.springdataelasticsearch.document.ProductDoc 当前版本下需要指定Field的type，否则也会报错。 修改FieldType 会导致无法通过程序启动异常，需要手动删除后创建索引。 比如: 原有的type字段的FieldType是Long，改成String后会出现类似如下错误：mapper [type] of different type, current_type [long], merged_type [string] 创建索引系统启动后，创建索引和创建/更新mapping 123elasticsearchTemplate.deleteIndex(ProductDoc.class);elasticsearchTemplate.createIndex(ProductDoc.class);elasticsearchTemplate.putMapping(ProductDoc.class); 启动后可以通过http://192.168.1.99:9200/product-index/_mapping/main/ 来查看mapping。 Notes：文档索引的mapping的创建，不会因为注解@Document， 而是因为ElasticsearchRepository的存在。删除ProductDocRespository，可以发现启动服务后，文档不会自动创建。 参考问题：https://stackoverflow.com/questions/29496081/spring-data-elasticsearchs-field-annotation-not-working 索引文档elasticsearch 是通过PUT接口来索引文档。https://www.elastic.co/guide/cn/elasticsearch/guide/current/index-doc.html。 在使用Spring Data Elasticsearch的的时候，我们可以很方便的通过防JPA Repository的方式来操作; ProductDocRespository.save(ProductDoc doc) 来索引和更新文档。1public interface ProductDocRespository extends ElasticsearchRepository&lt;ProductDoc, Long&gt; 参考com.joe.springdataelasticsearch.listner.ContextRefreshedListener 来查看索引测试文档数据。 测试数据 全文检索查询主要解决： 多个字段搜索查询使用布尔匹配的方式， 参考官方说明 布尔匹配 不同字段的权重设置，采用设置Boost方式， 参考： 查询语句提升权重 聚合结果集 具体代码参考如下：123456789101112131415161718public Page&lt;ProductDoc&gt; search(String keyword, Boolean isSelfRun, Pageable pageable) &#123; BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery(); if (StringUtils.isNotEmpty(keyword)) &#123; queryBuilder.should(QueryBuilders.matchQuery(ProductDoc._name, keyword).boost(3)); // 给name字段更高的权重 queryBuilder.should(QueryBuilders.matchQuery(ProductDoc._description, keyword)); // description 默认权重 1 queryBuilder.minimumNumberShouldMatch(1); // 至少一个should条件满足 &#125; if (isSelfRun!=null &amp;&amp; isSelfRun) &#123; queryBuilder.must(QueryBuilders.matchQuery(ProductDoc._isSelfRun, Boolean.TRUE)); // 精准值条件查询 &#125; SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(queryBuilder) .withPageable(pageable).build(); LOGGER.info(&quot;\\n search(): searchContent [&quot; + keyword + &quot;] \\n DSL = \\n &quot; + searchQuery.getQuery().toString()); return productDocRespository.search(searchQuery); &#125; 测试全文检索 http://localhost:8080/products?keyword=huawei http://localhost:8080/products?keyword=iphone 通过对iphone的搜索可以验证boost值得效果 http://localhost:8080/products?keyword=iphone&amp;isSelfRun=true 验证精准值匹配效果 聚合查询需求： 统计搜索出来的智能手机和普通手机的数量，从而提供进一步的过滤。 聚合的详细理解参考 聚合 | Elasticsearch: 权威指南 | Elastic， 这里我们只通过简单的桶（Bucket）的方式来实现需求。 通过google搜索spring data elasticsearch aggregation example 不难找到类似如下链接中的代码：https://github.com/spring-projects/spring-data-elasticsearch/blob/master/src/test/java/org/springframework/data/elasticsearch/core/aggregation/ElasticsearchTemplateAggregationTests.java； 但是我们需要同时返回桶的信息和检索出来的分页信息。如何利用Spring Data Elasticsearch来完成？ 通过查看spring-data-elasticsearch的源代码我们可以发现org.springframework.data.elasticsearch.core.DefaultResultMapper 会被默认用来返回分页检索出来的数据。需要同时返回分页数据及桶的数据，我们就需要定制一个ResultMapper； 参考：com.joe.springdataelasticsearch.core.ProductDocAggregationResultMapper。 聚合查询测试http://localhost:8080/products/aggregation?keyword=China 可以查出总共有5条结果，聚合返回告诉你其中有4个智能手机，1个普通手机。返回JSON 数据如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&#123; &quot;content&quot;: [ &#123; &quot;id&quot;: 2, &quot;name&quot;: &quot;Huawei&quot;, &quot;description&quot;: &quot;Made by China&quot;, &quot;type&quot;: &quot;SMARTPHONE&quot;, &quot;isSelfRun&quot;: false &#125;, &#123; &quot;id&quot;: 5, &quot;name&quot;: &quot;Iphone X&quot;, &quot;description&quot;: &quot;Iphone X is made by China&quot;, &quot;type&quot;: &quot;SMARTPHONE&quot;, &quot;isSelfRun&quot;: true &#125;, &#123; &quot;id&quot;: 1, &quot;name&quot;: &quot;Mac Pro&quot;, &quot;description&quot;: &quot;Mac Pro is made by China&quot;, &quot;type&quot;: &quot;SMARTPHONE&quot;, &quot;isSelfRun&quot;: true &#125;, &#123; &quot;id&quot;: 7, &quot;name&quot;: &quot;Nokia N90&quot;, &quot;description&quot;: &quot;Nokia N 90 is made by China&quot;, &quot;type&quot;: &quot;GENERAL&quot;, &quot;isSelfRun&quot;: false &#125;, &#123; &quot;id&quot;: 3, &quot;name&quot;: &quot;Huawei Max3&quot;, &quot;description&quot;: &quot;Huawei is designed / made by China&quot;, &quot;type&quot;: &quot;SMARTPHONE&quot;, &quot;isSelfRun&quot;: false &#125; ], &quot;bucketsByType&quot;: [ &#123; &quot;key&quot;: &quot;SMARTPHONE&quot;, &quot;lable&quot;: &quot;type&quot;, &quot;docCount&quot;: 4 &#125;, &#123; &quot;key&quot;: &quot;GENERAL&quot;, &quot;lable&quot;: &quot;type&quot;, &quot;docCount&quot;: 1 &#125; ], &quot;totalElements&quot;: 5, &quot;last&quot;: true, &quot;totalPages&quot;: 1, &quot;number&quot;: 0, &quot;size&quot;: 10, &quot;sort&quot;: null, &quot;numberOfElements&quot;: 5, &quot;first&quot;: true&#125; 高亮显示参考：http://tech.jiu-shu.com/Elastic-Technologies/spring-data-elasticsearch-highlight","categories":[],"tags":[]},{"title":"Spring Data Elasticsearch 快速上手全文检索 - 进阶","slug":"Elastic-Technologies/spring-data-elasticsearch-quick-start-2","date":"2018-12-21T01:49:27.251Z","updated":"2018-12-21T02:47:14.866Z","comments":true,"path":"Elastic-Technologies/spring-data-elasticsearch-quick-start-2/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/spring-data-elasticsearch-quick-start-2/","excerpt":"","text":"继上一篇 Spring Data Elasticsearch 快速上手全文检索之后，进一步深入以下内容： 高亮显示关键词 指定Analyzer更合理的检索 最新的master的代码升级Spring Boot到1.5.13.RELEASE， 对应的spring-data-elasticsearch 自动升级至2.1.12.RELEASE， 在此版本基础上，DefaultResultMapper 已经支持了聚合。无需为聚合儿自定义ResultMapper。 代码1git clone https://github.com/choelea/spring-data-elasticsearch-quick-start https://github.com/elastic/elasticsearch/issues/11713 高亮关键词对name和description中的关键字进行高亮显示，直接参考代码：1234SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(queryBuilder) .withPageable(pageable) .withHighlightFields( new HighlightBuilder.Field(ProductDoc._name).forceSource(true), new HighlightBuilder.Field(ProductDoc._description).forceSource(true)) .addAggregation(termBuilder).build(); 默认情况下返回高亮字段不在_source内，当转成成我们的ProductDoc的时候对应的name和description是不会有变化的， 这个时候还是需要定制ResultMapper， 因此这里定制了一个ExtResultMapper。 将高亮字段覆盖到ProductDoc 中对应的字段去。","categories":[],"tags":[]},{"title":"文档的title，页面及列表都会展示","slug":"Elastic-Technologies/spring-data-elasticsearch-2.1.12-highlight","date":"2018-12-21T01:49:27.237Z","updated":"2018-12-21T02:18:32.212Z","comments":true,"path":"Elastic-Technologies/spring-data-elasticsearch-2.1.12-highlight/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/spring-data-elasticsearch-2.1.12-highlight/","excerpt":"","text":"这个是一个模板, 请务必将showOnHome 修改为true 欢迎使用本Markdown编辑器使用simplemde-plus，用它写博客，将会带来全新的体验哦： Markdown和扩展Markdown简洁的语法 代码块高亮 图片链接和图片上传 丰富的快捷键 快捷键 Cmd-‘ 引用 Cmd-B 加粗 Cmd-E 清除Block Cmd-H 标题Header变小 Cmd-I 斜体 Cmd-K 链接 Cmd-L 无序列表 Cmd-P Preview Cmd-Alt-C 代码块 Cmd-Alt-I 插入图片 Cmd-Alt-L 有序列表 Shift-Cmd-H 标题Header变大 F9 窗口拆分 F11 全屏","categories":[],"tags":[]},{"title":"kibana的访问控制 - Nginx 反向代理 - 免费","slug":"Elastic-Technologies/Nignx-Kibana-Security","date":"2018-12-21T01:49:27.229Z","updated":"2018-03-05T01:03:32.242Z","comments":true,"path":"Elastic-Technologies/Nignx-Kibana-Security/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Nignx-Kibana-Security/","excerpt":"","text":"前一篇 Kibana 5.x 加强安全 采用的是官方的x-pack 插件来实现elastic技术栈的相关产品的权限控制。功能不错，也提供了很大的灵活性，不过x-pack并非免费产品；咨询了下licence价格，大概三个节点年费六千多美刀。。。废话不多说了，想想替代方案 - Nginx 反向代理 （收回5601端口，通过nginx反向代理+basic authentication来保证安全） 参考：How To Create a Self-Signed SSL Certificate for Nginx on CentOS 7 配置Nginx SSL第一步: 安装 Nginx 并配置防火墙参考上面的文章 注意： 80 和 443 端口必须对外打开。 当遇见ERR_CONNECTION_REFUSED 这类错误的时候，一定要提高警惕查看端口是否打开。以免浪费时间在配置上面。可以ssh到nginx机器上通过curl 的命令来验证，如果服务器上curl可以访问，外面不可访问；那么很可能端口没开放 第二步：生成证书参考上面的文章 第三步：添加kibana.https.conf配置配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041server &#123; listen 443 http2 ssl; listen [::]:443 http2 ssl; server_name kibana.domain.com; ssl_certificate /etc/ssl/certs/nginx-selfsigned.crt; ssl_certificate_key /etc/ssl/private/nginx-selfsigned.key; ssl_dhparam /etc/ssl/certs/dhparam.pem; ######################################################################## # from https://cipherli.st/ # # and https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html # ######################################################################## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_ciphers &quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH&quot;; ssl_ecdh_curve secp384r1; ssl_session_cache shared:SSL:10m; ssl_session_tickets off; ssl_stapling on; ssl_stapling_verify on; resolver 8.8.8.8 8.8.4.4 valid=300s; resolver_timeout 5s; # Disable preloading HSTS for now. You can use the commented out header line that includes # the &quot;preload&quot; directive if you understand the implications. #add_header Strict-Transport-Security &quot;max-age=63072000; includeSubdomains; preload&quot;; add_header Strict-Transport-Security &quot;max-age=63072000; includeSubdomains&quot;; add_header X-Frame-Options DENY; add_header X-Content-Type-Options nosniff; ################################## # END https://cipherli.st/ BLOCK # ################################## # 这里是反向代理到kibana服务 走http协议 location / &#123; proxy_pass http://localhost:5601; &#125;&#125; 第四步：验证SSL 访问为设置http跳转的时候，注意在浏览器地址栏中输入https://kibana.domain.com 来验证 第五步： 添加Nginx的Basic Authentication 访问控制 查看是否有安装httpd-tools sudo rpm -qa | grep httpd-tools, 如果有，则可以看到如下信息：httpd-tools-2.4.6-40.el7.centos.4.x86_64 如果没有安装，可以通过sudo yum -y install httpd-tools 来安装 配置nginx 反向代理 添加 12auth_basic &quot; Basic Authentication &quot;; auth_basic_user_file &quot;/etc/nginx/.htpasswd&quot;; 添加至反向代理的配置 1234567......location / &#123; proxy_pass http://localhost:5601; auth_basic &quot; Basic Authentication &quot;; auth_basic_user_file &quot;/etc/nginx/.htpasswd&quot;; &#125;..... 生成密码文件 sudo htpasswd -c /etc/nginx/.htpasswd username 根据提示输入密码 重新加载ngixn sudo service nginx reload 再次登录来，提示弹出框，输入用户名和密码","categories":[],"tags":[]},{"title":"Metricbeat 的使用","slug":"Elastic-Technologies/Metricbeat-Usage","date":"2018-12-21T01:49:27.226Z","updated":"2018-12-21T02:47:14.880Z","comments":true,"path":"Elastic-Technologies/Metricbeat-Usage/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Metricbeat-Usage/","excerpt":"","text":"目标统计并展示系统的信息 cpu， 内存等 (当然metricbeat能收集的信息种类还很多) 前提 版本： 5.x 已经安装了ELK (elasticsearch, logstash (可选）, kibana) 安装了x-pack （配置了对应的security）（可选） 参考 Kibana 5.x 加强安全 安装配置安装，配置参考 官方网站使用OOTB配置即可，一般只需要修改ES的端口和地址。 如果加强了security，也需要更改 metricbeat.yml。 这里已经加强了安全，配置了用户，故需要更改metricbeat.yml添加elasticsearch的相关访问用户。（创建角色和用户可以参考 Kibana 5.x 加强安全 ，这里角色需要用操作索引metricbeat-*） elasticsearch 默认绑定了localhost的访问，需要取消这种绑定。 设置network.host: 0.0.0.0 0.0.0.0 表示任意地址，如果设置成了IP地址，那么同台机器的kibana和logstash的需要做对应的修改。（比如：192.168.1.50， logstash和kibana需要把链接elasticsearch的hosts 从localhost改成：192.168.1.50） 加载kibana的示例 index template 和 dashboards 因为metricbeat 可能装在多个机器，index template 和dashboard 只需要导入一次即可。默认会自动加载index template到elasticsearch。 1./scripts/import_dashboards -es http://localhost:9200 -user elastic -pass changeme kibana中查看对应的结果登录kibana打开对应的dashboard 既可以看到统计报告了","categories":[],"tags":[]},{"title":"Logstash Filter 配置","slug":"Elastic-Technologies/Logstash-Filter","date":"2018-12-21T01:49:27.224Z","updated":"2018-03-05T01:03:32.240Z","comments":true,"path":"Elastic-Technologies/Logstash-Filter/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Logstash-Filter/","excerpt":"","text":"笔者这里仅仅列出配置文件，在研究之后最红并没有采用在logstash的接下日志为json的做法。而是将json的输出放在了各个服务/应用中处理， spring boot的app可以参考：logstash-logback-encoder1234567891011121314151617181920212223242526272829303132333435input &#123; beats &#123; port =&gt; 5044 &#125;&#125;filter &#123; #If log line contains tab character followed by &apos;at&apos; then we will tag that entry as stacktrace if [message] =~ &quot;\\tat&quot; &#123; grok &#123; match =&gt; [&quot;message&quot;, &quot;^(\\tat)&quot;] add_tag =&gt; [&quot;stacktrace&quot;] &#125; &#125; #Grokking Spring Boot&apos;s default log format grok &#123; match =&gt; [ # Record transaction &quot;message&quot;,&quot;(?&lt;timestamp&gt;%&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125; %&#123;TIME&#125;) %&#123;LOGLEVEL:level&#125; %&#123;NUMBER:pid&#125; --- \\[\\s*(?&lt;thread&gt;[^\\]]+)\\] (?&lt;class&gt;[A-Za-z0-9.#_]+)\\s*: \\[\\s*(?&lt;transactionInfo&gt;[^\\]]+)\\]&quot;, &quot;message&quot;, &quot;(?&lt;timestamp&gt;%&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125; %&#123;TIME&#125;) %&#123;LOGLEVEL:level&#125; %&#123;NUMBER:pid&#125; --- \\[\\s*(?&lt;thread&gt;[^\\]]+)\\] (?&lt;class&gt;[A-Za-z0-9.#_]+)\\s*:\\s+(?&lt;logmessage&gt;.*)&quot;, &quot;message&quot;, &quot;(?&lt;timestamp&gt;%&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125; %&#123;TIME&#125;) %&#123;LOGLEVEL:level&#125; %&#123;NUMBER:pid&#125; --- .+? :\\s+(?&lt;logmessage&gt;.*)&quot; ] &#125; #Parsing out timestamps which are in timestamp field thanks to previous grok section date &#123; match =&gt; [ &quot;timestamp&quot; , &quot;yyyy-MM-dd HH:mm:ss.SSS&quot; ] &#125;&#125;output &#123; elasticsearch&#123;&#125; stdout&#123; codec =&gt; rubydebug &#125;&#125; 这里grok配置了三册过滤， 第一层用作统计，message的格式如下： 12016-07-15 20:30:30.884 INFO 14624 --- [nio-8081-exec-3] c.l.a.w.controller.OfbizProxyController : [&#123;&quot;transactionCode&quot;:&quot;ofbizProxy&quot;,&quot;transactionDuration&quot;:246&#125;] 使用Grok Debugger 解析后如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&#123; \"timestamp\": [ [ \"2016-07-15 20:30:30.884\" ] ], \"YEAR\": [ [ \"2016\" ] ], \"MONTHNUM\": [ [ \"07\" ] ], \"MONTHDAY\": [ [ \"15\" ] ], \"TIME\": [ [ \"20:30:30.884\" ] ], \"HOUR\": [ [ \"20\" ] ], \"MINUTE\": [ [ \"30\" ] ], \"SECOND\": [ [ \"30.884\" ] ], \"level\": [ [ \"INFO\" ] ], \"pid\": [ [ \"14624\" ] ], \"BASE10NUM\": [ [ \"14624\" ] ], \"thread\": [ [ \"nio-8081-exec-3\" ] ], \"class\": [ [ \"c.l.a.w.controller.OfbizProxyController\" ] ], \"transactionInfo\": [ [ \"&#123;\"transactionCode\":\"ofbizProxy\",\"transactionDuration\":246&#125;\" ] ]&#125; 第二层针对普通的log 12016-07-15 20:30:07.768 INFO 14624 --- [nio-8081-exec-1] c.l.a.web.controller.LoginController : Login username:vincent.chen@okchem.com IP is:0:0:0:0:0:0:0:1 解析后的json如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&#123; &quot;timestamp&quot;: [ [ &quot;2016-07-15 20:30:07.768&quot; ] ], &quot;YEAR&quot;: [ [ &quot;2016&quot; ] ], &quot;MONTHNUM&quot;: [ [ &quot;07&quot; ] ], &quot;MONTHDAY&quot;: [ [ &quot;15&quot; ] ], &quot;TIME&quot;: [ [ &quot;20:30:07.768&quot; ] ], &quot;HOUR&quot;: [ [ &quot;20&quot; ] ], &quot;MINUTE&quot;: [ [ &quot;30&quot; ] ], &quot;SECOND&quot;: [ [ &quot;07.768&quot; ] ], &quot;level&quot;: [ [ &quot;INFO&quot; ] ], &quot;pid&quot;: [ [ &quot;14624&quot; ] ], &quot;BASE10NUM&quot;: [ [ &quot;14624&quot; ] ], &quot;thread&quot;: [ [ &quot;nio-8081-exec-1&quot; ] ], &quot;class&quot;: [ [ &quot;c.l.a.web.controller.LoginController&quot; ] ], &quot;logmessage&quot;: [ [ &quot;Login username:vincent.chen@okchem.com IP is:0:0:0:0:0:0:0:1&quot; ] ]&#125; 第三层针对遗漏的无法匹配到的log再次解析， 这里暂时没有示例","categories":[],"tags":[]},{"title":"Elasticsearch 自定义Mapping","slug":"Elastic-Technologies/Elasticsearch-Mapping","date":"2018-12-21T01:49:27.218Z","updated":"2018-03-05T01:03:32.239Z","comments":true,"path":"Elastic-Technologies/Elasticsearch-Mapping/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Elasticsearch-Mapping/","excerpt":"","text":"Mapping 定义前面有一个篇简单的关于mapping的博客，当时是基于2.4 版本。 elastic技术栈在最近很活跃，目前版本已经更新至5.x。5.x有了比较大的变化。2.4 版本的定义在5.x上大部分已经失去了意义。（比如：5.x已经不再支持string 类型）这里截取一点官网对应的定义： elasticsearch 通过定义的映射mapping来决定文档及其字段改如何被存储和索引。比如：字段是否可以支持全文搜索; 字段是否包含日期，地理位置; 日期的格式; 自定义自动映射的规则。 基于5.x，前面博客 提到的user，uri等字段就可以使用keyword type。 12345678910PUT /business-index-*/_mapping/business&#123; &quot;properties&quot; : &#123; &quot;uri&quot; : &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;user&quot; : &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;keyword&quot; : &#123;&quot;type&quot;: &quot;keyword&quot;&#125;, &quot;responseStatus&quot; : &#123; &quot;type&quot; : &quot;integer&quot; &#125;, &quot;responseTime&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125; &#125;&#125; elastic的文档维护的算是比较好的，基本英语OK的都是直接去参考官方文档。 mapping的更新可以参考 elastic 官网","categories":[],"tags":[]},{"title":"使用ELK来做日志归总","slug":"Elastic-Technologies/Elasticsearch-Logstash-Kibana-Log-Collecting","date":"2018-12-21T01:49:27.215Z","updated":"2018-12-21T02:47:14.866Z","comments":true,"path":"Elastic-Technologies/Elasticsearch-Logstash-Kibana-Log-Collecting/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Elasticsearch-Logstash-Kibana-Log-Collecting/","excerpt":"","text":"ELK 初探ELK实时日志分析平台 初次尝试。 ELK 的多种架构请参考文章: 漫谈ELK在大数据运维中的应用 平台 CentOS 7 Oracle JDK 8 Kibana 4.5.2 Elaticsearch 2.3.4 logstash 2.3.4 filebeat 1.2.3查看version command： filebeat --version系统架构图软件的安装采用yum的安装模式。首先需要添加对应的repo文件。 对应的详细的安装方法可以参考在线文档， 这里以logstash为例。logstash 安装 Download and install the public signing key 1rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch 添加Repo到目录/etc/yum.repos.d/， 比如：logstash.repo 123456[logstash-2.3]name=Logstash repository for 2.3.x packagesbaseurl=https://packages.elastic.co/logstash/2.3/centosgpgcheck=1gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearchenabled=1 安装 1yum install logstash 随系统自动启动1sudo chkconfig --add filebeat 其他软件的repositoriesfilebeat 123456[beats]name=Elastic Beats Repositorybaseurl=https://packages.elastic.co/beats/yum/el/$basearchenabled=1gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearchgpgcheck=1 elasticsearch 官方介绍 123456[elasticsearch-2.x]name=Elasticsearch repository for 2.x packagesbaseurl=https://packages.elastic.co/elasticsearch/2.x/centosgpgcheck=1gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearchenabled=1 kibana 在线文档 123456[kibana-4.5]name=Kibana repository for 4.5.x packagesbaseurl=http://packages.elastic.co/kibana/4.5/centosgpgcheck=1gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearchenabled=1 查看服务状态 1servie logstash status 查看服务文件路径 1rpm -ql logstash FileBeat 使用filebeat 安装后的配置文件存放于：/etc/filebeat/下修改配置文件filebeat.yml1， 修改文件的路径：比如：/home/osboxes/app.log12345filebeat: prospectors: - paths: - &quot;/home/osboxes/app.log&quot; 2， 修改输出， 默认是直接输出到Elasticsearch，我们修改输出到logstash只需要打开对应的注释即可，将elasticsearch相关注释掉， 打开logstash的注释。 123456output: logstash: hosts: [&quot;127.0.0.1:5044&quot;] # Optional load balance the events between the Logstash hosts #loadbalance: true filebeat.yml 已经配置了多个output选项，我们只需要打开注解。 这里可以做个小的测试。 修改配置后可运行命令验证：filebeat -configtest -e. filebeat只能配置一个output项，修改配置后需要重启1，找到Console output，打开注解 1234##Console output console: # Pretty print json event pretty: true 2， 停止filebeat服务 sudo service filebeat stop，手动启动filebeat来方便我们观察console输出sudo filebeat -e -c /etc/filebeat/filebeat.yml。(On windows: filebeat.exe -e -c filebeat.yml)3， 新开窗口输出信息至文件/var/log/app.log1echo &quot;2016-06-29 17:14:13.802 INFO 6244 --- [main] org.hibernate.Version : HHH000412: Hibernate Core &#123;4.3.11.Final&#125;&quot; &gt;&gt; app.log 4，切换至filebeat的启动窗口可以看到如下的输出。 123456789101112131415[osboxes@osboxes logstash]$ sudo filebeat -e -c /etc/filebeat/filebeat.yml&#123; &quot;@timestamp&quot;: &quot;2016-07-11T13:44:43.926Z&quot;, &quot;beat&quot;: &#123; &quot;hostname&quot;: &quot;osboxes&quot;, &quot;name&quot;: &quot;osboxes&quot; &#125;, &quot;count&quot;: 1, &quot;fields&quot;: null, &quot;input_type&quot;: &quot;log&quot;, &quot;message&quot;: &quot;2016-06-29 17:14:13.802 INFO 6244 --- [main] org.hibernate.Version : HHH000412: Hibernate Core &#123;4.3.11.Final&#125;&quot;, &quot;offset&quot;: 130, &quot;source&quot;: &quot;/home/osboxes/app.log&quot;, &quot;type&quot;: &quot;log&quot;&#125; LogStash 配置 上面的小测做完后，将filebeat的配置改回输出到logstash。 连通filebeat和logstash 1， 添加logstash.conf 文件在/etc/logstash/conf.d/logstash.conf 123456789input &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; stdout&#123;&#125;&#125; 修改后可以通过命令验证配置是否正确： 1sudo /opt/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf --configtest 2, 启动logstash采用命令启动方便从console观察输出。sudo /opt/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf如果采用service的启动方式，需要去/var/log/logstash/logstash.stdout 查看log3，启动filebeat 然后向文件app.log 写入log 1echo &quot;2016-06-29 17:14:13.802 INFO 6244 --- [main] org.hibernate.Version : HHH000412: Hibernate Core &#123;4.3.11.Final&#125;&quot; &gt;&gt; app.log 4，切换至logstash窗口， 可以观察到一下输出，证明filebeat已经可以成功输出到logstash 1234[osboxes@osboxes bin]$ sudo ./logstash -f /etc/logstash/conf.d/logstash.conf Settings: Default pipeline workers: 1Pipeline main started2016-07-12T05:57:46.877Z osboxes 2016-06-29 17:14:13.802 INFO 6244 --- [main] org.hibernate.Version : HHH000412: Hibernate Core &#123;4.3.11.Final&#125; 使用Grok Filter Plugin解析日志 （spring boot 的默认日志格式）1， 修改logstash.conf 添加filter，重启logstash 1234567891011121314151617181920212223242526272829303132input &#123; beats &#123; port =&gt; 5044 &#125;&#125;filter &#123; #If log line contains tab character followed by &apos;at&apos; then we will tag that entry as stacktrace if [message] =~ &quot;\\tat&quot; &#123; grok &#123; match =&gt; [&quot;message&quot;, &quot;^(\\tat)&quot;] add_tag =&gt; [&quot;stacktrace&quot;] &#125; &#125; #Grokking Spring Boot&apos;s default log format grok &#123; match =&gt; [ &quot;message&quot;, &quot;(?&lt;timestamp&gt;%&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125; %&#123;TIME&#125;) %&#123;LOGLEVEL:level&#125; %&#123;NUMBER:pid&#125; --- \\[(?&lt;thread&gt;[A-Za-z0-9-]+)\\] (?&lt;class&gt;[A-Za-z0-9.#_]+)\\s*:\\s+(?&lt;logmessage&gt;.*)&quot;, &quot;message&quot;, &quot;(?&lt;timestamp&gt;%&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125; %&#123;TIME&#125;) %&#123;LOGLEVEL:level&#125; %&#123;NUMBER:pid&#125; --- .+? :\\s+(?&lt;logmessage&gt;.*)&quot; ] &#125; #Parsing out timestamps which are in timestamp field thanks to previous grok section date &#123; match =&gt; [ &quot;timestamp&quot; , &quot;yyyy-MM-dd HH:mm:ss.SSS&quot; ] &#125;&#125;output &#123; stdout&#123; codec =&gt; rubydebug &#125; 2，写入log到文件app.log 1echo &quot;2016-06-29 17:14:09.477 INFO 6244 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named &apos;errorChannel&apos; has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.&quot; &gt;&gt; app.log 3， 切换logstash查看输出 12345678910111213141516171819202122232425&#123; &quot;message&quot; =&gt; &quot;2016-06-29 17:14:09.477 INFO 6244 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named &apos;errorChannel&apos; has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.&quot;, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;@timestamp&quot; =&gt; &quot;2016-06-29T16:14:09.477Z&quot;, &quot;count&quot; =&gt; 1, &quot;fields&quot; =&gt; nil, &quot;source&quot; =&gt; &quot;/home/osboxes/app.log&quot;, &quot;offset&quot; =&gt; 987, &quot;type&quot; =&gt; &quot;log&quot;, &quot;input_type&quot; =&gt; &quot;log&quot;, &quot;beat&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;osboxes&quot;, &quot;name&quot; =&gt; &quot;osboxes&quot; &#125;, &quot;host&quot; =&gt; &quot;osboxes&quot;, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;timestamp&quot; =&gt; &quot;2016-06-29 17:14:09.477&quot;, &quot;level&quot; =&gt; &quot;INFO&quot;, &quot;pid&quot; =&gt; &quot;6244&quot;, &quot;thread&quot; =&gt; &quot;main&quot;, &quot;class&quot; =&gt; &quot;faultConfiguringBeanFactoryPostProcessor&quot;, &quot;logmessage&quot; =&gt; &quot;No bean named &apos;errorChannel&apos; has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.&quot;&#125; 至此，完成了初步的日志的解析，日志别解析至对应的fields中。 接下来将这些数据推送至Elasticsearch进行索引。 修改logstash配置，输出到elasticsearch修改配置文件的output。 1234output &#123; elasticsearch &#123; &#125;&#125; 用这样的结构，Logstash使用http协议连接到Elasticsearch。上面的例子假设Logstash和Elasticsearch运行在同一个机器上。您可以使用主机配置hosts =&gt; &quot;es-machine:9092指定远程Elasticsearch实例。 查看结果一次启动elasticsearch，kibana，logstash，filebeat。 （filebeat已启动的话，无需重启） 安装Sense进入/opt/kibana/ 运行：$sudo ./bin/kibana plugin --install elastic/senseYou should now be able to access Sense with a web browser on http://localhost:5601/app/sense spring boot 日志配置尽量采用统一的日志输出格式1, JPA 的sql输出 12#spring.jpa.show-sql = true #不推荐这种方式logging.level.org.hibernate.SQL=DEBUG 常见的部署方式由于logstash比较消耗系统资源， 采用filebeat 来采集数据， 然后推送到logstash。 简单的case可以将logstash elasticsearch kibana 放在一个虚拟机。 filebeat可以分别安装在各个对应的微服务上。 注意：当这些部署在不同的机器上的时候，需要打开对应的端口。 对应的配置也需要相对修改下。打开logstash的端口： 12$ sudo firewall-cmd --zone=public --add-port=5044/tcp --permanent$ sudo firewall-cmd --reload filebeat的配置修改 123logstash: # The Logstash hosts hosts: [&quot;192.168.1.186:5044&quot;] 修改hostName如果微服务部署在不同的虚拟机中， 可以通过修改hostname，然后在ES的index中通过hostname 来区分日志的来源 12$ hostnamectl status# hostnamectl set-hostname Your-New-Host-Name-Here 关于日志采集的策略（网上未提及此topic）配置logstash是件麻烦事情。 一下两种策略互相冲突1， 保证所有的log都index到ES这中策略方便用户查找问题， 因为所有的log都可以搜索到2， 严格过滤， 只提取我们需要的log信息这种很方便做统计， 但是其他很多log会被过滤掉， 用来找问题不方便。 服务器时间设置最好保证日志源的服务器时间和ELK的数据库服务器时间一直1# ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime","categories":[],"tags":[]},{"title":"Kibana 5.x 加强安全 - x-pack篇","slug":"Elastic-Technologies/Elasticsearch-Kibana-Security-xpack","date":"2018-12-21T01:49:27.213Z","updated":"2018-12-21T02:47:14.921Z","comments":true,"path":"Elastic-Technologies/Elasticsearch-Kibana-Security-xpack/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Elasticsearch-Kibana-Security-xpack/","excerpt":"","text":"此文之前，假定读者已经一次完成了Kibana和elasticsearch的安装。参考官方文档，安装后默认配置已经可以连通kibana和es。 系统： centos7 内容： 增加authentication &amp; enable ssl elastic 技术栈 的另外一个重要的角色是x-pack. ES安装xpack插件参考安装xpackRun bin/elasticsearch-plugin install from ES_HOME on each node in your cluster:1bin/elasticsearch-plugin install x-pack Kibana 安装xpack 插件参考安装xpack Install X-Pack into Kibana by running bin/kibana-plugin in your Kibana installation directory.1bin/kibana-plugin install x-pack 依次启动elasticsearch 和kibana修改用户elastic 和 kibana的密码X-Pack 文档：修改密码 X-Pack security provides a built-in elastic superuser you can use to start setting things up. The default password for the elastic user is changeme. 123curl -XPUT -u elastic &apos;localhost:9200/_xpack/security/user/elastic/_password&apos; -d &apos;&#123; &quot;password&quot; : &quot;elasticpassword&quot;&#125;&apos; 123curl -XPUT -u elastic &apos;localhost:9200/_xpack/security/user/kibana/_password&apos; -d &apos;&#123; &quot;password&quot; : &quot;kibanapassword&quot;&#125;&apos; CURL授权在访问需要授权的页面时，可通过-u选项提供用户名和密码进行授权。 通常的做法是在命令行只输入用户名，之后会提示输入密码，这样可以保证在查看历史记录时不会将密码泄露 Enable Kibana SSLUsing Kibana in a Production Environment配置上证书的路径即可：123# SSL for outgoing requests from the Kibana Server (PEM formatted)server.ssl.key: /path/to/your/server.keyserver.ssl.cert: /path/to/your/server.crt 修改了超级用户的密码，enable ssl后，就可以放心的去使用kibana的Dev Tools 或者chrome插件（sense）进行大部分API 的操作。 （在此之前需要ssh到服务器通过curl来操作以保证安全） 创建用户logstash_writer官方参考上面步骤完成后会发现logstash推送给es报错了。因为现在ES需要用户名和密码了。 这里我们需要创建一个用户拥有write, delete, and create_index的权限。 12[2016-12-23T20:42:19,350][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. &#123;:url=&gt;#&lt;URI::HTTP:0x17b5a1bd URL:http://localhost:9200&gt;, :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::BadResponseCodeError, :error=&gt;&quot;Got response code &apos;401&apos; contact Elasticsearch at URL &apos;http://localhost:9200/&apos;&quot;&#125;[2016-12-23T20:42:20,132][WARN ][logstash.shutdownwatcher ] &#123;&#125; 先创建一个role：logstash_writer 12345678910POST _xpack/security/role/logstash_writer&#123; &quot;cluster&quot;: [&quot;manage_index_templates&quot;, &quot;monitor&quot;], &quot;indices&quot;: [ &#123; &quot;names&quot;: [ &quot;logstash-*&quot;,&quot;business-index-*&quot;], &quot;privileges&quot;: [&quot;write&quot;,&quot;delete&quot;,&quot;create_index&quot;] &#125; ]&#125; 再创建一个用户：logstash_internal拥有Role：logstash_writer 123456POST /_xpack/security/user/logstash_internal&#123; &quot;password&quot; : &quot;changeme&quot;, &quot;roles&quot; : [ &quot;logstash_writer&quot;], &quot;full_name&quot; : &quot;Internal Logstash User&quot;&#125; 上面的操作也可以通过Kibana的Management UI来操作 配置logstash.conf 123456output &#123; elasticsearch &#123; ... user =&gt; logstash_internal password =&gt; changeme &#125; logstash, elasticsearch, kibana 如果在同一网络，而暴露出去的只有kibana的话，logstash和elasticsearch 之前是无需授权的。可以参考Enabling Anonymous Access 另外，logstash和elasticsearch之间如果需要授权，会不会有性能的影响？ 给Kibana用户加上index的读的权限Kibana安装xpack后默认就需要登录了。也可以用超级用户elastic登录登录后打开DevTools进行ES API的操作。 修改后停掉kibana服务。修改kibana的配置： Once you change the password, you need to specify it with the elasticsearch.password property in kibana.yml: 1elasticsearch.password: &quot;s0m3th1ngs3cr3t&quot; 坑 （Tricky Part） /etc/logstash/conf.d 下不要有多余的文件。比如logstash.conf.bak， 似乎logstash会读这个文件夹下的不止logstash.conf这个文件配置。logstash.conf.bak 会导致死循环一样的重启。elastic community","categories":[],"tags":[]},{"title":"Elasticsearch 模糊匹配","slug":"Elastic-Technologies/elasticsearch-fuzzy-query","date":"2018-12-21T01:49:27.211Z","updated":"2018-12-21T02:18:10.581Z","comments":true,"path":"Elastic-Technologies/elasticsearch-fuzzy-query/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/elasticsearch-fuzzy-query/","excerpt":"","text":"这个是一个模板, 请务必将showOnHome 修改为true https://www.elastic.co/guide/cn/elasticsearch/guide/cn/fuzzy-scoring.html以下来自123456模糊性评分编辑用户喜欢模糊查询。他们认为这种查询会魔法般的找到正确拼写组合。 很遗憾，实际效果平平。假设我们有1000个文档包含 ``Schwarzenegger`` ，只是一个文档的出现拼写错误 ``Schwarzeneger`` 。 根据 term frequency/inverse document frequency 理论，这个拼写错误文档比拼写正确的相关度更高，因为错误拼写出现在更少的文档中！换句话说，如果我们对待模糊匹配 类似其他匹配方法，我们将偏爱错误的拼写超过了正确的拼写，这会让用户抓狂。","categories":[],"tags":[]},{"title":"Elastcisearch 6.2 Restful API","slug":"Elastic-Technologies/Elasticsearch-6_2-Restful-API","date":"2018-12-21T01:49:27.208Z","updated":"2018-12-21T02:18:06.458Z","comments":true,"path":"Elastic-Technologies/Elasticsearch-6_2-Restful-API/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Elasticsearch-6_2-Restful-API/","excerpt":"","text":"Elastcisearch详细的API请参考官方网站： https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html 这里只列举常用的方式。 索引API官方链接： https://www.elastic.co/guide/en/elasticsearch/reference/6.2/indices.html 创建索引快速创建1PUT /news 创建名为test的索引，没有创建任何对应的Type,以及Mapping12345&#123; &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;index&quot;: &quot;news&quot;&#125; 查看索引1GET /news 123456789101112131415161718&#123; &quot;news&quot;: &#123; &quot;aliases&quot;: &#123;&#125;, &quot;mappings&quot;: &#123;&#125;, &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;creation_date&quot;: &quot;1535677066065&quot;, &quot;number_of_shards&quot;: &quot;5&quot;, &quot;number_of_replicas&quot;: &quot;1&quot;, &quot;uuid&quot;: &quot;-fZX17QdQjWE_AK79pO8lQ&quot;, &quot;version&quot;: &#123; &quot;created&quot;: &quot;6020499&quot; &#125;, &quot;provided_name&quot;: &quot;news&quot; &#125; &#125; &#125;&#125; 删除索引1curl -XDELETE &quot;http://192.168.1.99:9200/news&quot; // 删除索引 1234&#123; &quot;ok&quot;: true, &quot;acknowledged&quot;: true&#125; 设置类型并定义Mapping (推荐)1234567891011121314151617181920PUT /news/_mapping/_doc&#123; &quot;properties&quot;:&#123; &quot;title&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125;, &quot;content&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125;, &quot;postDate&quot;:&#123; &quot;type&quot;:&quot;date&quot; &#125;, &quot;categories&quot;:&#123; &quot;type&quot;:&quot;keyword&quot; &#125;, &quot;tags&quot;:&#123; &quot;type&quot;:&quot;keyword&quot; &#125; &#125;&#125; title和content是用于全文检索的，同时需要分词的 categories tags无需分词，这里的categories和tags都会存放多个值的数组。关于数组类型参考Array DataType elasticsearch 支持 Dynamical Mapping, 大多数情况下，这都不是一个推荐方式。","categories":[],"tags":[]},{"title":"Elastcisearch 2.4 Restful API","slug":"Elastic-Technologies/Elasticsearch-2_4-Restful-Api","date":"2018-12-21T01:49:27.206Z","updated":"2018-12-21T02:17:57.522Z","comments":true,"path":"Elastic-Technologies/Elasticsearch-2_4-Restful-Api/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Elasticsearch-2_4-Restful-Api/","excerpt":"","text":"Elastcisearch详细的API请参考官方网站： https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html 这里只列举常用的方式。 索引API官方链接： https://www.elastic.co/guide/en/elasticsearch/reference/2.4/indices-create-index.html 创建索引1curl -XPUT &quot;http://192.168.1.99:9200/test&quot; //创建test的索引 1234&#123; &quot;ok&quot;: true, &quot;acknowledged&quot;: true&#125; 删除索引1curl -XDELETE &quot;http://192.168.1.99:9200/test&quot; // 删除索引 1234&#123; &quot;ok&quot;: true, &quot;acknowledged&quot;: true&#125; 以下开始使用Kibana的Sense 来简化curl的操作 查看索引1GET /test 创建索引并设置Type和Mapping 快捷键 Cmd-‘ 引用 Cmd-B 加粗 Cmd-E 清除Block Cmd-H 标题Header变小 Cmd-I 斜体 Cmd-K 链接 Cmd-L 无序列表 Cmd-P Preview Cmd-Alt-C 代码块 Cmd-Alt-I 插入图片 Cmd-Alt-L 有序列表 Shift-Cmd-H 标题Header变大 F9 窗口拆分 F11 全屏","categories":[],"tags":[]},{"title":"文档的title，页面及列表都会展示","slug":"Elastic-Technologies/Elasticsearch-2.4-Restful-Api","date":"2018-12-21T01:49:27.204Z","updated":"2018-12-21T02:18:02.696Z","comments":true,"path":"Elastic-Technologies/Elasticsearch-2.4-Restful-Api/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Elasticsearch-2.4-Restful-Api/","excerpt":"","text":"这个是一个模板, 请务必将showOnHome 修改为true 欢迎使用本Markdown编辑器使用simplemde-plus，用它写博客，将会带来全新的体验哦： Markdown和扩展Markdown简洁的语法 代码块高亮 图片链接和图片上传 丰富的快捷键 快捷键 Cmd-‘ 引用 Cmd-B 加粗 Cmd-E 清除Block Cmd-H 标题Header变小 Cmd-I 斜体 Cmd-K 链接 Cmd-L 无序列表 Cmd-P Preview Cmd-Alt-C 代码块 Cmd-Alt-I 插入图片 Cmd-Alt-L 有序列表 Shift-Cmd-H 标题Header变大 F9 窗口拆分 F11 全屏","categories":[],"tags":[]},{"title":"Elasticsearch 2.X 自定义字段的Mapping","slug":"Elastic-Technologies/Elasticsearch-2-X-Mapping","date":"2018-12-21T01:49:27.202Z","updated":"2018-03-05T01:03:32.234Z","comments":true,"path":"Elastic-Technologies/Elasticsearch-2-X-Mapping/","link":"","permalink":"http://it.jiu-shu.com/Elastic-Technologies/Elasticsearch-2-X-Mapping/","excerpt":"","text":"说到Mapping大家可能觉得有些不解，其实我大体上可以将Elasticsearch理解为一个RDBMS（关系型数据库，比如MySQL），那么index 就相当于数据库实例，type可以理解为表,这样mapping可以理解为表的结构和相关设置的信息（当然mapping有更大范围的意思）。 默认情况不需要显式的定义mapping， 当新的type或者field引入时，Elasticsearch会自动创建并且注册有合理的默认值的mapping(毫无性能压力)， 只有要覆盖默认值时才必须要提供mapping定义。 引用博客：http://blog.csdn.net/top_code/article/details/50767138 术语term - individual word （拆分后的最小单词） Mapping 简介Elasticsearch Reference [2.4] » MappingMapping是用来定义文档及包含字段的保存和索引的方式。 Why接触mapping是因为要收集除了log之外的业务信息。 业务log和系统log不同，很多的自定义字段，并将这些信息推送到单独的index。 最终目的是用过kibana的图形化的展示来统计和分析。当我们要统计比如：用户的访问排名（字段名：user：test@gmail.com）。 当没有设置任何mapping的时候，ES会采用动态mapping（Dynamic Mapping），针对String的字段默认的index方式是：analyzed。这种方式下，test@gmail.com 会被拆分成test和gmail.com(怎么拆分取决于用什么analyzer)。这样不便于统计，这里我们必须显示地去设置mapping。 Mapping parameters » index 通过kibana去选择analyzed的字段去做terms aggregation可以看到对应的warning信息 自定义mapping可以通过API 去自定义mapping。 （这个最好在数据开始index之前，因为数据index的时候会动态设置mapping，再去修改会出现一些冲突）新增加的字段可以继续通过修改mapping来增加。 ES 支持一个index多个type，mapping可以针对单个type也可以针对index。示例： 12345678910curl -XPUT http://localhost:9200/business-index-*/_mapping/biz -d &apos;&#123; &quot;properties&quot; : &#123; &quot;uri&quot; : &#123;&quot;type&quot;: &quot;string&quot;,&quot;index&quot; : &quot;not_analyzed&quot;&#125;, &quot;user&quot; : &#123;&quot;type&quot;: &quot;string&quot;, &quot;index&quot; : &quot;not_analyzed&quot;&#125;, &quot;keyword&quot; : &#123;&quot;type&quot;: &quot;string&quot;, &quot;index&quot; : &quot;not_analyzed&quot;&#125;, &quot;responseStatus&quot; : &#123; &quot;type&quot; : &quot;integer&quot; &#125;, &quot;responseTime&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125; &#125;&#125;&apos;; 自定义template对于确定的index，通过mapping的方式就可以达到我们的目的。 比如： 商品的索引，这个index不会变，里面的数据document会增删改查，但是index始终在那里。但是对于类似log和数据分析的数据，这些数据会惊人的速度增加，如果放在一个index就不现实。 所以ELK就有了 “time-based index pattern“ , 通过这种方式可以每天或者每月生成一个index文件。比如logstash的日志： logstash-2016.08.20 针对这种场景，就需要引入更高一层的配置: Index Template设定自己的template的示例如下： 1234567891011121314151617181920212223242526272829303132curl -XPUT http://localhost:9200/_template/business -d &apos;&#123; &quot;template&quot;: &quot;business*&quot;, &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1 &#125;, &quot;mappings&quot;: &#123; &quot;_default_&quot;: &#123; &quot;properties&quot;: &#123; &quot;uri&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125;, &quot;user&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125;, &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125;, &quot;responseStatus&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;responseTime&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125; &#125; &#125; &#125;&#125;&apos;; The settings and mappings will be applied to any index name that matches the business* template","categories":[],"tags":[]},{"title":"Windows 常用命令","slug":"Dev-Ops/Windows-Commands","date":"2018-12-21T01:49:27.195Z","updated":"2018-03-05T01:03:32.233Z","comments":true,"path":"Dev-Ops/Windows-Commands/","link":"","permalink":"http://it.jiu-shu.com/Dev-Ops/Windows-Commands/","excerpt":"","text":"设置环境变量doc 窗口设置环境变量1set MAVEN_OPTS=-Xmx1024m -XX:MaxPermSize=512m 删除服务删除服务名为mysql的服务： sc delete mysql 端口相关端口占用的应用的PID1netstat -aon|findstr &quot;8599&quot; 结果如下： （PID为2948）12C:\\Documents and Settings\\XPMUser&gt;netstat -aon|findstr &quot;8599&quot; TCP 0.0.0.0:8599 0.0.0.0:0 LISTENING 2948 对应PID的进程1tasklist|findstr &quot;2948&quot; 结果如下12C:\\Documents and Settings\\XPMUser&gt;tasklist|findstr &quot;2948&quot;tomcat6.exe 2948 RDP-Tcp#4 0 44,072 K 或者：打开任务管理器，切换到进程选项卡，在PID一列查看2720对应的进程是谁，如果看不到PID这一列，点击查看—&gt;选择列，将PID(进程标示符)前面的勾打上，点击确定。 结束进程结束该进程：在任务管理器中选中该进程点击”结束进程“按钮，或者是在cmd的命令窗口中输入：taskkill /f /t /im Tencentdl.exe。 列出文件夹下面的文件名称创建一个bat文件, 加入下面的内容。 将这个bat文件放入文件夹内运行即可。1DIR *.* /B&gt; LIST.TXT","categories":[],"tags":[]},{"title":"Shell 脚本学习笔记","slug":"Dev-Ops/Shell-learning-notes","date":"2018-12-21T01:49:27.190Z","updated":"2018-12-21T02:17:49.795Z","comments":true,"path":"Dev-Ops/Shell-learning-notes/","link":"","permalink":"http://it.jiu-shu.com/Dev-Ops/Shell-learning-notes/","excerpt":"","text":"杂记括号的使用说明参考：Double parenthesis with and without dollar $(…) means execute the command in the parens and return its stdout. 12$ echo &quot;The current date is $(date)&quot;The current date is Mon Jul 6 14:27:59 PDT 2015 (…) means run the commands listed in the parens in a subshell. Example: 123$ a=1; (a=2; echo &quot;inside: a=$a&quot;); echo &quot;outside: a=$a&quot;inside: a=2outside: a=1 $((…)) means perform arithmetic and return the result of the calculation. Example: 12$ a=$((2+3)); echo &quot;a=$a&quot;a=5 ((…)) means perform arithmetic, possibly changing the values of shell variables, but don’t return its result. Example: 12$ ((a=2+3)); echo &quot;a=$a&quot;a=5 ${…} means return the value of the shell variable named in the braces. Example: 12$ echo $&#123;SHELL&#125;/bin/bash {…} means execute the commands in the braces as a group. Example: 12$ false || &#123; echo &quot;We failed&quot;; exit 1; &#125;We failed 有用脚本收集文件读取读取文件目录的所有文件，按行读取每个文件，判断行文字是否包含特定字符串；如果包含，通过特殊字符来split并输出想要的值。 1234567891011#!/bin/shfor filename in /home/okchem/mysqlbackup/*.sql; do while IFS= read line do # display $line or do somthing with $line if [[ $line == *&quot;/ocf/&quot;* ]]; then SUBSTRING=$(echo $line| cut -d&apos;`&apos; -f 2) # 用&apos;`&apos;来拆分,输出数组第二个 echo $SUBSTRING fi done &lt;&quot;$&#123;filename&#125;.sql&quot;done 参考网站https://www.shellscript.sh/https://www.shellscript.sh/quickref.html","categories":[],"tags":[]},{"title":"Nginx 问题收集","slug":"Dev-Ops/Nginx-Technologies","date":"2018-12-21T01:49:27.188Z","updated":"2018-12-21T02:17:44.088Z","comments":true,"path":"Dev-Ops/Nginx-Technologies/","link":"","permalink":"http://it.jiu-shu.com/Dev-Ops/Nginx-Technologies/","excerpt":"","text":"收集在使用Nginx过程中遇见的问题。 知识积累负载均衡平均负载示例如下; 以下配置必须保证两个实例都正常运行在，因为这个配置并不会failover。1234567891011121314151617upstream backend &#123; server 127.0.0.1:8080; server 127.0.0.1:8081;&#125;server &#123; listen 80; server_name auth.jiu-shu.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://backend; client_max_body_size 10m; &#125; &#125; 上例中的8080 和 8081 端口都是Spring Boot的app。由于Java 是多线程的程序，在同一个虚拟机上运行多个实例并非最佳实践；这里只是方便测试。 问题收集反向代理后request的host和schema和浏览器请求不一致反向代理后下面如果不加proxy_set_header的两行，那么在microservice这个服务中，request.getScheme() + &quot;://&quot; + request.getServerName() 就会变成http://microservice.dev.com, nginx rewrite 之后，就可以获取到：http://www.dev.com123456server_name www.dev.com;location / &#123; proxy_set_header Host $host; proxy_set_header X-Scheme $scheme; proxy_pass http://microservice.dev.com:8091; &#125; bind() to 0.0.0.0:80 failed (98: Address already in use)启动碰见以上问题，有两种可能 先检查80端口是否已经被其他http server占用 sudo netstat -nlpt remove the IPv6 bind block (something along the lines of ::1:80。 参考：http://serverfault.com/questions/520535/nginx-is-still-on-port-80-bind-to-0-0-0-080-failed-98-address-already-in 403 forbidden (13: Permission denied)参考：Nginx报错403 forbidden (13: Permission denied)的解决办法解决办法一： 关闭 SELinux （在了解了SELinux的重要性后，决定继续寻找更好的解决办法） 需要进一步了解SELinux相关，需要解决办法二：（感谢Zeal老师给出的解决方案） Every directory has a SeLinux context and the default ‘Document Root’ ( /var/www/html ) has an context which allows the nginx / apache user to access the directory.The new ROOT ( /data/images ) will not have the same context and thus SeLinux is blocking the access.You can verify with ls -lZ /Default-Document-Root and verify the context and associate the same context to /data/images.This should ideally solve the issue, can you try and verify once :-chcon -R -u system_u -t httpd_sys_content_t /data/ 相信ftp等服务，如果更改了根目录，也会有同样的问题。需要更深入的对SELinux学习。 (13: Permission denied) while connecting to upstream:[nginx]https://stackoverflow.com/questions/23948527/13-permission-denied-while-connecting-to-upstreamnginx","categories":[],"tags":[]},{"title":"Maven父子工程的搭建","slug":"Dev-Ops/Maven-usage-of-parent","date":"2018-12-21T01:49:27.186Z","updated":"2018-12-21T02:47:14.855Z","comments":true,"path":"Dev-Ops/Maven-usage-of-parent/","link":"","permalink":"http://it.jiu-shu.com/Dev-Ops/Maven-usage-of-parent/","excerpt":"","text":"尝试dubbo+spring的同时，总结下通过maven创建父子工程的方法。（不考虑unit test） 版本Spring Boot： 1.4.7.RELEASEMaven： 3.2.5 工具eclipse 参考https://github.com/dubbo/dubbo-spring-boot-projecthttp://blog.csdn.net/yaerfeng/article/details/26448417http://blog.csdn.net/isea533/article/details/73744497 maven 国内镜像如果不翻墙，下载maven的依赖相当慢，可以添加阿里云的镜像， 速度相当快。修改conf文件夹下的settings.xml文件，添加如下镜像配置：12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt; 步骤创建父maven工程创建普通的maven工程，参考如下截图 填写参数 删除无用文件夹 修改pom.xml packaging 从jar改成pom &lt;packaging&gt;pom&lt;/packaging&gt; 添加spring-boot-starter-parent，添加dependency management。（maven的配置解释参考：http://www.blogjava.net/hellxoul/archive/2013/05/16/399345.html）修改后配置如下： 123456789101112131415161718192021222324252627282930313233343536&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.dubboot&lt;/groupId&gt; &lt;artifactId&gt;dubboot-example&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;dubboot-example&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;!-- keep the version same with $&#123;springboot.version&#125; --&gt; &lt;/parent&gt; &lt;dependencyManagement&gt; &lt;!-- 存在的价值只是为了方便管理版本 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.dubbo.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-dubbo&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 方式一：创建子maven子工程 （dubbo 服务接口） 选中父maven工程右键，新建maven module，输入相关参数即可。 - 工程导入后删除测试相关：pom.xml 的junit依赖及测试相关java文件夹。 pom.xml 添加 &lt;packaging&gt;jar&lt;/packaging&gt;方式二：创建子maven子工程 （Spring Boot， dubbo 服务实现）从https://start.spring.io/ 创建, 添加依赖，JPA， Validation, Mysql 及其他依赖项（不选Spring Cloud 相关）。下载后解压至父maven工程，修改pom.xml 中的parent使其匹配父工程。 12345&lt;parent&gt; &lt;groupId&gt;com.dubboot&lt;/groupId&gt; &lt;artifactId&gt;dubboot-example&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 在父工程中添加module： 123&lt;modules&gt; &lt;module&gt;dubboot-jpa&lt;/module&gt;&lt;/modules&gt; 然后可以顺利将子工程导入eclipse。","categories":[],"tags":[]},{"title":"利用Nexus搭建Maven私服","slug":"Dev-Ops/Maven-Private-Repository-Server","date":"2018-12-21T01:49:27.184Z","updated":"2018-03-05T01:03:32.228Z","comments":true,"path":"Dev-Ops/Maven-Private-Repository-Server/","link":"","permalink":"http://it.jiu-shu.com/Dev-Ops/Maven-Private-Repository-Server/","excerpt":"","text":"阐述如果利用Nexus来快速搭建maven仓库的私有服务器私服搭建Docker Hub链接地址： https://hub.docker.com/r/sonatype/nexus/ docker pull sonatype/nexusmkdir /data/nexus-data &amp;&amp; chown -R 200 /data/nexus-datadocker run -d -p 8081:8081 –name nexus -v /data/nexus-data:/nexus-data sonatype/nexus3​ 本地Maven配置​修改Maven的全局setting.xml文件如下： 文件路径： $MAVEN_HOME/conf/setting.xml mirrors节点加入如下内容 nexus * Nexus http://192.168.1.80:8081/repository/maven-public/ profiles节点加入如下内容 nexus central http://central true true central http://central true true activeProfiles​节点加入 nexus​ 对于Snapshot的jar，如果想及时的更新，可以在maven参数中加上-U，就可以获得最新的jar包。本地组件deploy除了配置本地Maven配置外，还需要在setting.xml文件中加入如下内容： servers节点 maven-releases admin admin123 maven-snapshots admin admin123 项目的pom.xml文件，加入如下配置： maven-releases http://192.168.1.​80:8081/repository/maven-releases/ maven-snapshots http://192.168.1.80:8081/repository/maven-snapshots/ ​","categories":[],"tags":[]},{"title":"Java 开发工具使用技巧收集","slug":"Dev-Ops/Java-IDE-Useful-Skills","date":"2018-12-21T01:49:27.175Z","updated":"2018-12-21T02:17:38.596Z","comments":true,"path":"Dev-Ops/Java-IDE-Useful-Skills/","link":"","permalink":"http://it.jiu-shu.com/Dev-Ops/Java-IDE-Useful-Skills/","excerpt":"","text":"EclipseEclipse 提速https://blog.csdn.net/leolu007/article/details/53541641 Remote System Explorer Operation卡死第一步：Eclipse -&gt; Preferences -&gt; General -&gt; Startup and Shutdown.不要勾选 RSE UI.第二步：Eclipse -&gt; Preferences -&gt; Remote Systems. 取消勾选 Re-open Remote Systems view to previous state. 在Eclispe中使用Git 命令参考： https://blog.csdn.net/wu_cai_/article/details/71637199 （建议选择git-bash）直接在eclipse中使用并不是很方便，但是可以快速打开git-bash. 配置方式参考上面。 调试断点出用于打印信息的代码收集Request的Header信息12345java.util.Enumeration headerNames = req.getHeaderNames();while(headerNames.hasMoreElements()) &#123; String headerName = (String)headerNames.nextElement(); System.out.println(&quot;Header Name - &quot; + headerName + &quot;, Value - &quot; + req.getHeader(headerName));&#125;","categories":[],"tags":[]},{"title":"Git 常用命令","slug":"Dev-Ops/Git-Commands","date":"2018-12-21T01:49:27.167Z","updated":"2018-12-24T02:51:14.737Z","comments":true,"path":"Dev-Ops/Git-Commands/","link":"","permalink":"http://it.jiu-shu.com/Dev-Ops/Git-Commands/","excerpt":"","text":"帮助命令1git help command // eg: git commit help windows 打开默认的浏览器显示帮助内容， mac直接显示 配置1234git config --global setting value示例：git config --global user.name &quot;Your Name&quot;示例：git config --global user.email &quot;you@someplace.com&quot;git config --global --list // 列出全局配置项 配置内容保存在当前用户目录下的.gitconfig文件中 本地命令设置邮箱设置全局邮箱方式一： 运行命令： git config --global user.email &quot;joe.lea@foxmail.com&quot;方式二: 编辑文件 .gitconfig, 一般在用户目录下，上面的命令运行后也同样会修改这个文件123[user]name =xiaomingemail = xiaoming@qq.com 设置项目的提交邮箱编辑文件 .git/config 即可 github 项目只有设置了提交者的邮箱，才会在contibutors中you展示。 比如：https://github.com/choelea/markdown-cms/graphs/contributors 初始化方式一：12cd projects/git init git-demo // projects下面创建文件夹 git-demo, 并初始化； 初始化其实就是在文件夹下面创建了相关内容存放在.git 隐藏文件夹下面 方式二：1234cd projects/mkdir websitecd website/git init // 初始化 方式三：大多数的方式，我们从clone一个git 库开始的。1git clone &apos;url&apos; 查看本地分支12git branch -vv // 列出本地分支 * 标识当前分支git branch -a // 列出所有分支 删除本地分支1234git branch -d &lt;BranchName&gt;``` ### 查看状态 git status // Shows which files have been modified in the working directory vs Git’s staging area.12### 添加新文件 git add file-name // Adds the new or newly modified file-name to Git’s staging area (index).1234&gt; 当很多文件修改，而且这些文件不属于同一个功能修改，想分开多个commit来提交的时候，可选择通过`git add &lt;file&gt;` 先将指定的文件Stage，然后使用`git commit -m ` 来只提交stage的文件。### Commit 修改 git commit -m “A really good commit message” // Commits all files currently in Git’s staging area.123&gt; 上面的命令只有所有的文件都在staging area在有效。 `git commit -am &quot;A really good commit message&quot;` 可以省掉git add这步，不过新文件必须先add下。### 回滚 git add . // Add all new and newly modified files.git reset HEAD file-name // Unstage the specified file from stage area. 修改的内容还在git checkout – file-name // 回滚本次修改git reset –hard HEAD^ // 回滚到远程仓库的版本，放弃本地所有包括commit的修改1### 检查修改内容 git diff // 查看unstage状态下的文件的修改内容，staged的无法查看1### 合并到上次提交 git add . // 将修改的文件 stagegit commit –amend // 将当前的staged的修改合并到上次commit，并打开编辑器修改commitgit commit –amend -m “New commit message” // 将当前的staged的修改合并到上次commit，并实用新的Message123&gt; 使用Interactive Rebasing/squash也可以达到合并的效果，区别就是一个是事先（commit 前）就合并，一个是事后（commit 后）合并。### 放弃本地修改或新增的文件放弃modified的文件 git checkout // 重新checkout文件file，相当于丢掉了本地的修改git checkout src/ // 使用通配符来checkout src文件夹下面所有的修改git reset –hard // 丢掉所有的修改modified 文件git clean -fd // 移除所有untrack的文件和文件夹git clean -fd src/ // 移除src目录下面所有的新增的文件123&gt; git clean -fd 中 -f means force, -d means &apos;remove directories&apos;### 切换分支&gt; 切换分支前必须保证工作空间是干净的。（没有未提交的修改和新增） git checkout branchename // 切换到branchname分支12### 提交历史 log日志 git log // 默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。git log –oneline –graph –decorate –colorgit log – // 查看某个文件的日志1#### 查看历史提交的内容差异 git log -p -212 我们常用 -p 选项展开显示每次提交的内容差异，用 -2 则仅显示最近的两次更新：#### 可视化查看某个文件的提交历史 gitk [filename] // 启用可视化的方式查看提交历史12### 移除文件方式一：完全通过git命令 git rm debug.log // remove and stage the changegit commit -m ‘remove file debug.log’12方式二：非git 命令删除文件后，运行下面的命令 git add -u // git 2.0 以前的版本 stage删除的changegit add file-name // git 2.0 后也可以通过这个命令达到上面的命令的效果git commit -m ‘commit message’1### 移动文件 git mv index.html web/ // 移动index.html 到web文件夹内。 命令完成后直接进入staging 状态git commit -m ‘move index.html into web folder’123456### ignore 文件编辑 .gitignore 文件## SSH 命令windows cmd并没有自带ssh命令，我们可以通过git bash命令窗来运行这些命令。假定在当前用户的目录下： cd .sshssh-keygen -t rsa -C “your email” // 生成SSH Key， 将id_rsa.pub公钥配置到github/bitbucket 等服务器上ssh -T git@github.com // 验证SSH 配置成功123## Git Remote 相关命令关联一个远程的Repo。 （针对前两种初始化方式，一般情况用不上） git remote add remote-name remote-repository-location // 示例: git remote add origin git@github.com:choelea/keycloak-demo.gitgit push -u remote-name branch-name // 示例: git push -u origin master; The -u parameter is needed the first time you push a branch to the remote.git remote -v // list the names of all the remote repositories12关联远程repo之前需要先在git服务器上创建对应的repo，如果采用的是github，在创建repository后，会有如下的提示：![Git-Push-Remote](/assets/preimg/Dev-Ops/git-push-remove.png) git pull origin master // 下载当前分支远程修改；每次push前都应该先pull123456## Git Rebase关于rebase和merge的区别，建议参考：[Merging vs Rebasing](https://www.atlassian.com/git/tutorials/merging-vs-rebasing)&gt; 一定要看看 &apos;The Golden Rule of Rebasing&apos;这部分.rebase 和 merge都是应该发生在分支之间的事情，当然在同一个分支上有时也需要。（可能不是最佳实践，git的开发流程一般建议创建单独的feature分支来完成不同的story，避免出现多人在同一个分支上直接commit）直接在当前分支做rebase git fetch // 这一步必须git rebase // 将未push的commits 放至remote所有commits之上// 修复冲突 如果有冲突必须进行修复，完成后，注意提示。一般需要git add 命令来stage下 ，接着git rebase –continue 至到没有任何冲突123## Squash通过Interactive Rebasing来完成当前分支的commits的squash git rebase -i // 列出所有未push的commit，注意是倒序1234567根据提示编辑来达到squash的作用。![git-rebase](/assets/preimg/Dev-Ops/git-rebase.png)将第二个commit（435d22b）修改为:`pick 435d22b ...` 即将这个commit压缩至上面的commit，并放弃当前的commit message。&gt; 有些公司会很强调squash。 git估计本地多次提交防止丢失，所以git的commit有可能会很多；而svn的commit就意味着修改可以被其他用户拉取到， 所以svn的每一次commit都要保证系统可以运行，svn的commit会偏少。svn的代码更新时间取决于文件多少和大小；git的代码拉取时间取决于commit的多少。所以。。。是每次提交尽量合理依然很重要，squash/Ineractive Rebasing 很实用。## Changing remote URLrepo换了名字，或者之前是https clone下来的，现在想换成ssh；这些情况都面临着修改远程的URL。 git remote -v // 查看当前的地址git remote set-url origin git@github.com:choelea/tech-docs.git` https的URL一般来说push代码是需要用户明和密码；而ssh的不需要。","categories":[],"tags":[]},{"title":"Centos 常用命令","slug":"Dev-Ops/Centos-Common-Commands","date":"2018-12-21T01:49:27.165Z","updated":"2018-12-21T02:17:29.598Z","comments":true,"path":"Dev-Ops/Centos-Common-Commands/","link":"","permalink":"http://it.jiu-shu.com/Dev-Ops/Centos-Common-Commands/","excerpt":"","text":"以下命令仅在centos7上验证过 软件安装yum 安装示例如下：1sudo yum install elasticsearch rpm 包安装1sudo rpm -ivh kibana-4.6.6-x86_64.rpm // 安装后通过 sudo service kibana start 来启动 查看安装程序路径1sudo rpm -ql kibana // 查看到安装在了/opt/kibana 开放端口12$ sudo firewall-cmd --zone=public --add-port=80/tcp --permanent$ sudo firewall-cmd --reload netstat 使用查看某个服务是否在运行1sudo netstat -aple | grep nginx 只查看tcp或者udp的connections需要添加-t参数: sudo netstat -nplt 更多更实用的netstat命令参考：Linux netstat 命令示例 查看centos 版本1cat /etc/centos-release 设置环境变量12export KAFKA_HOME=/home/osboxes/kafka_2.10-0.10.0.1echo $KAFKA_HOME 磁盘空间1df -h 1free 查看目录所占空间大小1du -smh * 统计文件夹下面的文件数量1ls -1 | wc -l grep 搜索文件内容指定的文件类型中查找当前子目录中查找： grep -r abcd *.properties 当前子目录递归查找含有abcd 的*.properties 文件指定目录及子目录中查找：grep -r 3306 /home/okchem/storage92g/srm/ 拷贝整个文件夹1cp -avr /home/vivek/letters /usb/backup 用户和组 /etc/group file that lists all users groups 可以使用cut命令列出来cut -d: -f1 /etc/group 查看当前用户的group: $ groups查看用户的group: $ groups root id -Gn root添加用户到组: $ sudo usermod -a -G osboxes nginx 添加用户nginx到组osboxes usermod -a -G &lt;groupname&gt; username 添加完成请用groups &lt;username&gt; 来验证获取组的所有用户: getent group kibana 其他有用资源： CentOS7之新建用户与SSH登陆 文件权限修改文件[夹]ownerchown 代表change owner；chown --help 提供了更详细的信息1sudo chown -R okchem:root /ebs 修改文件[夹]访问权限chmod 代表change mode;例如：chmod 644 important.txt owner可读可写,group可读，others可读 First position refers to the user. Second refers to the group of the user, and the third refers to all others.4 = read 2 = write 1 = execute 文件权限更详细的解释可以参考：Linux File Permissions PS 命令查看java进程 ps -ef|grep java产看进程的详细信息 ps -auxwe | grep subscribe命令行快捷键CTRL-a 光标移至行首CTRL-e 光标移至行尾CTRL-u 删除整行CTRL-h 删除光标前字符 gzip / gunzip 压缩单个文件 gzip fileName 压缩后的名字=原文件名字加上后缀.gz 解压缩单个文件gunzip filename 或者 gzip -d filenamegzip 不能用来压缩整个文件夹至一个.gz 文件。压缩整个文件夹请参考targ + gzip 命令 即： tar -z命令。 gzip -r dictName 命令会压缩整个文件夹dictName 里面的所有文件，每个文件被压缩成一个单独的*.gz 文件 tar 命令gzip / bzip2 是用来压缩单个文件， tar是用来归档。 所以tar结合gzip/bzip2 可以方便的进行整个文件夹的压缩及归档。压缩整个文件夹tar -zcvf outputFileName folderToCompressExamples1ar -xvf videos-14-09-12.tar.bz2 // 解压 bzip2 sftp 命令sftp登录1sftp name@123.21.331.1 sftp 下载文件夹1get -r folder /home/joe/ sftp 上传文件1put /name1.html /name2/ crontab 命令创建执行任务， 添加cron job参考cronjob crontab -l编辑cronjob crontab -e 120 1 * * * /data/scripts/mysql-job.sh A // 每天1点执行20 1 * * 0 /data/scripts/mysql-job.sh I // 每周日1点20 执行 Cron Job的日志位置： /var/log/cron参考：crontab 时间可以参考： https://www.cnblogs.com/intval/p/5763929.html 注意cron的时间有可能和date命令的时间不一致。tail -f /var/log/cron 这个命令可以查看cron的时间。 当执行crontab -e的时候/var/log/cron会有记录。","categories":[],"tags":[]},{"title":"Mysql 运维相关脚本收集","slug":"Database-Technologies/Mysql-Administration","date":"2018-12-21T01:49:27.116Z","updated":"2018-12-21T02:17:17.064Z","comments":true,"path":"Database-Technologies/Mysql-Administration/","link":"","permalink":"http://it.jiu-shu.com/Database-Technologies/Mysql-Administration/","excerpt":"","text":"mysql 版本： 5.6 建库及用户创建数据库dbname及用户dbuser/dbpassword 并授权数据库全不权限给用户dbuser12CREATE DATABASE IF NOT EXISTS `dbname` /*!40100 DEFAULT CHARACTER SET utf8 COLLATE utf8_bin */grant all privileges on dbname.* to dbuser@localhost identified by 'dbpassword'; SQL 收集找出有记录的表1SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = &apos;okchem&apos; and table_rows &gt; 0; 快速删除树形表数据如何快速删除树形比如：ProductCategory 这类模型的数据：123SET FOREIGN_KEY_CHECKS=0;DELETE FROM okchem.ProductCategory where id &gt; 0; -- id&gt;0 可以去除错误SET FOREIGN_KEY_CHECKS=1; 采用where条件where id &gt; 0可以去除如下错误：Error Code: 1175. You are using safe update mode and you tried to update a table without a WHERE that uses a KEY column To disable safe mode, toggle the option in Preferences -&gt; SQL Editor and reconnect. 快速查询表的依赖查询表依赖那些表和查询那些表依赖此表； 查询我依赖的：123456789SELECT TABLE_NAME, COLUMN_NAME, CONSTRAINT_NAME, REFERENCED_TABLE_NAME, REFERENCED_COLUMN_NAMEFROM INFORMATION_SCHEMA.KEY_COLUMN_USAGEWHERE TABLE_SCHEMA = &quot;schemaName&quot; AND TABLE_NAME = &quot;TableName&quot; AND REFERENCED_COLUMN_NAME IS NOT NULL; 查询依赖‘我的’：123456789 SELECT TABLE_NAME, COLUMN_NAME, CONSTRAINT_NAME, REFERENCED_TABLE_NAME, REFERENCED_COLUMN_NAMEFROM INFORMATION_SCHEMA.KEY_COLUMN_USAGEWHERE TABLE_SCHEMA = &quot;schemaName&quot; AND REFERENCED_TABLE_NAME = &quot;TableName&quot;; 删除重复的行12345DELETE t1 FROM contacts t1 INNER JOIN contacts t2 WHERE t1.id &lt; t2.id AND t1.email = t2.email; // 当表的记录太多，这种join很危险， 最好的方式是先查出来重复的email，再加上in的条件12345DELETE t1 FROM contacts t1 INNER JOIN contacts t2 WHERE t1.id &lt; t2.id AND t1.email = t2.email and t2.email in (&apos;..&apos;,,,,,,,); 使用函数为空的时候给默认值1select ifnull(p.isActive,0) from product 转换成JSON创建FunctionSplit delimited strings参考： https://blog.fedecarg.com/2009/02/22/mysql-split-string-function/ 123456789CREATE FUNCTION SPLIT_STR( x VARCHAR(255), delim VARCHAR(12), pos INT)RETURNS VARCHAR(255)RETURN REPLACE(SUBSTRING(SUBSTRING_INDEX(x, delim, pos), LENGTH(SUBSTRING_INDEX(x, delim, pos -1)) + 1), delim, &apos;&apos;); Mysql 分库备份脚本1234567891011121314151617#!/bin/sh#Backup databases into separated files excluding system schemasBACKUP_FOLDER=/home/okchem/mysqlbackupMYUSER=userMYPASS=passwordSOCKET=/data/mysql/mysql.sockMYCMD=&quot;mysql -u$MYUSER -p$MYPASS -S $SOCKET&quot;MYDUMP=&quot;mysqldump -u$MYUSER -p$MYPASS -S $SOCKET&quot;mkdir -p $&#123;BACKUP_FOLDER&#125;#for database in `$MYDUMP -e &quot;show databases;&quot;|sed &apos;1,2d&apos;|egrep -v &quot;mysql|schema&quot;`for database in `$MYCMD -e &quot;show databases;&quot; | egrep -Evi &quot;database|mysql|schema|test&quot;`do $MYDUMP $database &gt;$&#123;BACKUP_FOLDER&#125;/$&#123;database&#125;_$(date +%Y%m%d).sql #If compression is needed, use this command: $MYDUMP $database |gzip &gt;/server/backup/$&#123;database&#125;_$(date +$F).sql.gzdone Mysql 客户端导出数据在mysql 服务端可以很方便的导出到文件，也有灵活的选择。 如果需要导出的文件到其他服务器，不在mysql服务器上。 有两个选择： 在mysql 服务器上导出文件，通过sftp上传至目标机器 在目标机器安装mysql 客户端，通过shell 脚本来导出数据 （此篇关注点） 验证环境Linux 系统：Centos 7 安装Mysql Client参考：Installing MySQL on Linux Using RPM Packages from Oracle Shell 脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/bin/sh############################################################################################################################################### This script is used to retrieve data from mysql and output it into txt file. Also it will generate md5 file which can be used to verify the integrity.# Script will make folder named \"YYYYMMDD\", also the file name will follow the pattern A/I&#123;tableName&#125;YYYYMMDD&#123;6 sequence number&#125; such as I0100320170303000001############################################################################################################################################################Global Configuration begins ##################### Root folder where the data will be storedBEE_ROOT_GLOBAL=/data/b2bbuyerdataMYSQL_HOST=192.168.1.90MYSQL_PORT=3306MYSQL_USERNAME=usernameMYSQL_PASSWD=password##############Global Configuration ends ##################### exportAndMD5Sum querySql tableName. Output the query result into tableNameYYYYMMDD000001.txt and tableNameYYYYMMDD000001.md5# .md5 file is used to verify data integrity. exportAndMD5Sum()&#123; if [ \"$#\" != 2 ];then echo \"Usage: exportAndMD5Sum querySql tableName\"; exit; fi # Starting export data using mysql command SQL=$1; tableName=$2; TIMESTAMP=`date +%Y%m%d` BEE_ROOT=$&#123;BEE_ROOT_GLOBAL&#125;/$&#123;TIMESTAMP&#125; _tmpFile=$&#123;BEE_ROOT&#125;/$&#123;tableName&#125;$&#123;TIMESTAMP&#125;000001.tmp; destFile=$&#123;BEE_ROOT&#125;/$&#123;tableName&#125;$&#123;TIMESTAMP&#125;000001.AVL; destMD5File=$&#123;BEE_ROOT&#125;/$&#123;tableName&#125;$&#123;TIMESTAMP&#125;000001.CHK; # Create Folder [ ! -d \"$BEE_ROOT\" ] &amp;&amp; mkdir \"$BEE_ROOT\" # Mysql command to output data into file `mysql -h $&#123;MYSQL_HOST&#125; -p$&#123;MYSQL_PORT&#125; -u $&#123;MYSQL_USERNAME&#125; --password=$&#123;MYSQL_PASSWD&#125; -e \"$&#123;SQL&#125;\" &gt; \"$&#123;_tmpFile&#125;\"` # If not empty(has records) change the file name, otherwise remove it. if [ -f \"$_tmpFile\" ] &amp;&amp; [ -s \"$_tmpFile\" ] then mv $&#123;_tmpFile&#125; $&#123;destFile&#125; #`md5sum $&#123;destFile&#125; &gt; $&#123;destMD5File&#125;` md5=($(md5sum $&#123;destFile&#125;)) echo $md5 &gt; $&#123;destMD5File&#125; else rm $&#123;_tmpFile&#125; fi&#125;if [ \"$1\" = \"I\" ]; then echo \"Starting export all data from mysql .............\" exportAndMD5Sum \"SELECT username,country,source,city,email,first_name,last_name,province,status,CAST(is_reveive_email AS UNSIGNED) AS is_reveive_email,created_stamp,last_updated_stamp FROM b2bbuyer.user\" \"I01001\" exportAndMD5Sum \"select u.username,a.address,a.city,a.company_name,a.country,a.first_name,CAST(a.is_default AS UNSIGNED) AS is_default ,a.last_name,a.province,a.tel_country_code,a.tel_ext,a.tel_no,a.zip_code,a.created_stamp,a.last_updated_stamp from b2bbuyer.user u inner join b2bbuyer.user_delivery_address a where a.user_id=u.id\" \"I01002\" exportAndMD5Sum \"select u.username,c.email,c.address,c.city,c.company_name,c.contact,c.country,c.fax_country_code,c.fax_ext,c.fax_tel_no,c.main_products,c.province,c.register_no,c.tax_no,c.tel_country_code,c.tel_ext,c.tel_no,c.website from b2bbuyer.user u inner join b2bbuyer.user_company c where c.user_id=u.id\" \"I01003\"else echo \"Starting export yesterday's data from mysql .............\" exportAndMD5Sum \"SELECT username,country,source,city,email,first_name,last_name,province,status,CAST(is_reveive_email AS UNSIGNED) AS is_reveive_email,created_stamp,last_updated_stamp FROM b2bbuyer.user where last_updated_stamp &lt; (UNIX_TIMESTAMP(CURDATE())*1000) and last_updated_stamp &gt; ((UNIX_TIMESTAMP(CURDATE())-60*60*24)*1000)\" \"A01001\" exportAndMD5Sum \"select u.username,a.address,a.city,a.company_name,a.country,a.first_name,CAST(a.is_default AS UNSIGNED) AS is_default ,a.last_name,a.province,a.tel_country_code,a.tel_ext,a.tel_no,a.zip_code,a.created_stamp,a.last_updated_stamp from b2bbuyer.user u inner join b2bbuyer.user_delivery_address a where a.user_id=u.id and a.last_updated_stamp &lt; (UNIX_TIMESTAMP(CURDATE())*1000) and a.last_updated_stamp &gt; ((UNIX_TIMESTAMP(CURDATE())-60*60*24)*1000)\" \"A01002\" exportAndMD5Sum \"select u.username,c.email,c.address,c.city,c.company_name,c.contact,c.country,c.fax_country_code,c.fax_ext,c.fax_tel_no,c.main_products,c.province,c.register_no,c.tax_no,c.tel_country_code,c.tel_ext,c.tel_no,c.website from b2bbuyer.user u inner join b2bbuyer.user_company c where c.user_id=u.id and c.last_updated_stamp &lt; (UNIX_TIMESTAMP(CURDATE())*1000) and c.last_updated_stamp &gt; ((UNIX_TIMESTAMP(CURDATE())-60*60*24)*1000)\" \"A01003\"fi 添加cron job参考cronjob crontab -l编辑cronjob crontab -e 120 1 * * * /data/scripts/mysql-job.sh A20 1 * * 0 /data/scripts/mysql-job.sh I 两个cron job 分别： 每天1点执行 每周日1点20 执行 参考：crontab 时间可以参考： https://www.cnblogs.com/intval/p/5763929.html Mysql 客户端导入数据从txt文件导入参考： https://blog.csdn.net/huihui520com/article/details/79080512 https://segmentfault.com/a/1190000009333563 123use test;load data infile &apos;D:/tmp/hotwords.txt&apos; into table hot fields terminated by &apos;,&apos; lines terminated by&apos;\\r\\n&apos;;ALTER TABLE okchem.hot ADD `id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY; 需要解决问题：–secure-file-priv option so it cannot execute this statement123windows下：修改my.ini 在[mysqld]内加入secure_file_priv =linux下：修改my.cnf 在[mysqld]内加入secure_file_priv = mysql 数据迁移自增字段问题新增表格，需要将旧的数据迁入新表。Mysql的自增字段默认行为： 取最大的(比如： 创建表后，只插入一条数据， ID直接指定为9， 那么下一条插入的数据在不指定ID值的情况下，ID是10） 删除数据后，ID的起点不会因为删除而改变。 （插入N条数据，假如这N条都是未指定ID的插入，也就是说下一个ID是N+1， 这个时候删除所有的数据，再以不指定ID的方式插入一条数据，这个时候ID是N+1）Mysql 系统变量配置windows 下安装的mysql的配置文件地址从服务列表services.msc 中找到mysql的服务，右键查看属性中的“可执行文件路径”。参考：https://blog.csdn.net/postnull/article/details/72455768Win 7 设置表明区分大小写参考： https://blog.csdn.net/postnull/article/details/72455768在my.ini 文件中添加 lower_case_table_names=2","categories":[],"tags":[]},{"title":"Mongodb 和 Mysql 的性能测试","slug":"Database-Technologies/Mongodb-vs-Mysql-basic","date":"2018-12-21T01:49:27.108Z","updated":"2018-12-21T02:47:14.849Z","comments":true,"path":"Database-Technologies/Mongodb-vs-Mysql-basic/","link":"","permalink":"http://it.jiu-shu.com/Database-Technologies/Mongodb-vs-Mysql-basic/","excerpt":"","text":"尝试测试Mongodb 和 Mysql的性能，测试/数据导入代码：github: mongo-vs-mysql 性能比较很复杂，不能简单就说谁的性能高，谁的低。要基于场景，基于并发请求数量来谈，同时也要知道如何调优，本文只是初探，在没有任何调优的基础上，在本地windows 7上进行测试。 版本及环境 操作系统： windows 7 硬件环境： （只做对比，mongodb和mysql都装在同一台机器上） mongodb： 3.2.5 mysql： 5.7 Data-demoData-demo 是一个Spring Boot的项目， 通过Spring Boot的CommandLineRunner来批量动态插入1000,020 条数据。 数据结构采用常用的产品和类目的多对多的设计。 Category 数据如下： id code name ‘1’ ‘cate-1’ ‘Category 1’ ‘2’ ‘cate-2’ ‘Category 2’ ‘3’ ‘cate-3’ ‘Category 3’ ‘4’ ‘cate-4’ ‘Category 4’ Product 数据如下 id code name price ‘1’ ‘p-0’ ‘product 0’ ‘19’ ‘2’ ‘p-1’ ‘product 1’ ‘19’ ‘3’ ‘p-2’ ‘product 2’ ‘19’ … … … … ‘1000000’ ‘p-999999’ ‘product 999999’ ‘19’ ‘1000001’ ‘pp-0’ ‘iphone’ ‘19’ ‘1000002’ ‘pp-1’ ‘iphone’ ‘19’ ‘1000003’ ‘pp-2’ ‘iphone’ ‘19’ ‘1000004’ ‘pp-3’ ‘iphone’ ‘19’ ‘1000005’ ‘pp-4’ ‘iphone’ ‘19’ ‘1000006’ ‘pp-5’ ‘iphone’ ‘19’ ‘1000007’ ‘pp-6’ ‘iphone’ ‘19’ ‘1000008’ ‘pp-7’ ‘iphone’ ‘19’ ‘1000009’ ‘pp-8’ ‘iphone’ ‘19’ ‘1000010’ ‘pp-9’ ‘iphone’ ‘19’ ‘1000011’ ‘pp-10’ ‘iphone’ ‘19’ ‘1000012’ ‘pp-11’ ‘iphone’ ‘19’ ‘1000013’ ‘pp-12’ ‘iphone’ ‘19’ ‘1000014’ ‘pp-13’ ‘iphone’ ‘19’ ‘1000015’ ‘pp-14’ ‘iphone’ ‘19’ ‘1000016’ ‘pp-15’ ‘iphone’ ‘19’ ‘1000017’ ‘pp-16’ ‘iphone’ ‘19’ ‘1000018’ ‘pp-17’ ‘iphone’ ‘19’ ‘1000019’ ‘pp-18’ ‘iphone’ ‘19’ ‘1000020’ ‘pp-19’ ‘iphone’ ‘19’ 最后的二十行是用来方便查询验证的。 Product_Category 中间mapping的表格 Mongo 数据采用了 Nodejs+express+mongoose 来导入mongo的数据. 项目express-mongoose-microservice-api-boilerplate中的config/test.env来配置mongo的数据库地址。npm install 然后运行命令npm run produceTestData 可以初始化1000,020 条产品数据到mongodb。 数据类似mysql的产品数据： 产品 Product1234567891011&#123; &quot;_id&quot;: &quot;59cb4952d44efa2eb45d4bf7&quot;, &quot;code&quot;: &quot;p-0&quot;, &quot;name&quot;: &quot;Product 0&quot;, &quot;price&quot;: 19, &quot;__v&quot;: 0, &quot;categories&quot;: [ &quot;cate-1&quot;, &quot;cate-2&quot; ]&#125; 有20条产品数据的categories中有cate-4 通过查询脚本直接测试：通过Robomongo 连接Mongodb来测试，通过mysql的workbench来完成mysql的脚本查询。 场景一：查询单个类目下的产品mongo 查询所有的cate-4 的产品1db.getCollection(&apos;products&apos;).find(&#123;categories:&apos;cate-4&apos;&#125;) // 初次查询1.321 秒 紧接着的两次查询大概0.791 秒 mysql 查询所有的cate-4 的产品12SELECT * FROM product p inner join product_category pc inner join category c on p.id=pc.product_id and pc.category_id=c.id where c.code ='cate-4'; -- 毫秒级，时间可以忽略不计, 产品和类目的code都是unique的索引，所以查询速度很快SELECT * FROM product p inner join product_category pc inner join category c on p.id=pc.product_id and pc.category_id=c.id where c.name ='Category 4'; -- 6.2秒，name不是索引，所以慢。（索引的用处毫无疑问，无需赘述） 场景二：查询多个类目下的产品查询所有cate-4 加上 cate-5 的产品。（实际上cate-5并不存在，不过不影响测试） mongod1db.getCollection(&apos;products&apos;).find(&#123;categories:&#123;$in:[&apos;cate-4&apos;,&apos;cate-5&apos;]&#125;&#125;) // 0.89 秒； 和查询cate-4的产品相差不多，都是全表扫描 mysql12SELECT * FROM product p inner join product_category pc inner join category c on p.id = pc.product_id and pc.category_id = c.id where c.code = &apos;cate-5&apos; or c.code=&apos;cate-4&apos;; -- 6.177 秒，SELECT * FROM product p inner join product_category pc inner join category c on p.id = pc.product_id and pc.category_id = c.id where c.code in(&apos;cate-5&apos;,&apos;cate-4&apos;); -- 6.24 秒 通过上面的测试可以看出，mysql数据库在数据体量大的时候，用or或者in都有很严重的性能问题，可以考虑使用union来代替。一般电商平台的处理方式：如果是后台维护功能应该从业务上来避免这种场景，如果是前端面向用户的功能，需要引入搜索引擎 比如： elasticsearch 场景三：单表无索引查询名称是iphone的产品 Mysql1select * from product where name=&apos;iphone&apos;; -- 0.546 秒，全表扫描 mongo1db.getCollection(&apos;products&apos;).find(&#123;name:&apos;iphone&apos;&#125;) // 0.428 秒 全表扫描两者并无太大的差距。 场景四：单表索引12db.getCollection(&apos;products&apos;).find(&#123;code:&apos;pp-1&apos;&#125;) select * from product where code=&apos;pp-1&apos;; 一百万条数据，单表索引速度都是毫秒级，时间可以忽略不计。 场景五：单表索引字段使用In来查询场景二我们提到了Mysql中关联表时使用in查询的效率问题。下面测试下单表的In查询效率, 通过测试我们可以发现单表针对索引的in的查询都是毫秒级的。mongodb 历时0.004 sec. 索引被用上了123456789101112131415161718// 非ID的索引字段db.getCollection(&apos;products&apos;).find(&#123; &quot;code&quot;: &#123; &quot;$in&quot;: [ &quot;pp-0&quot;, &quot;pp-1&quot; ] &#125;&#125;)// _id 主键的$in 查询db.getCollection(&apos;products&apos;).find(&#123; &quot;_id&quot;: &#123; &quot;$in&quot;: [ ObjectId(&quot;59cb4952d44efa2eb45d4bf7&quot;), ObjectId(&quot;59cb4952d44efa2eb45d4bf8&quot;) ] &#125;&#125;) Mysql 也是毫秒级，时间忽略不计 1select * from product where code in ('pp-0','pp-4'); // 0.0000 sec","categories":[],"tags":[]},{"title":"MongoDB 命令 常用语句","slug":"Database-Technologies/mongodb-command","date":"2018-12-21T01:49:27.105Z","updated":"2018-12-21T02:17:05.348Z","comments":true,"path":"Database-Technologies/mongodb-command/","link":"","permalink":"http://it.jiu-shu.com/Database-Technologies/mongodb-command/","excerpt":"","text":"mongodb 常用命令收集 导出JSON数据1mongoexport -h localhost:27017 -d guide-chem -c product --limit 10000 --skip 10000 --jsonArray -u okchem -p okchem -o /home/okchem/products.json 参数说明 -h 指定host 和端口 -d 指定db -c 指定collection –limit 导出多少条 –skip 跳过多少条 –jsonArray 保存为json数组 -u 指定用户 -p 指定密码 -o 指定导出文件路径output 修改字段名称1db.集合名称.update(&#123;&#125;, &#123;$rename:&#123;&quot;旧键名称&quot;:&quot;新键名称&quot;&#125;&#125;, false, true) 参数说明 第一个false表示：可选，这个参数的意思是，如果不存在update的记录，true为插入新的记录，默认是false，不插入。 第二个true表示：可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。","categories":[],"tags":[]},{"title":"个人PPT汇总","slug":"Work-Related/个人PPT汇总","date":"2018-12-21T01:49:27.084Z","updated":"2018-12-21T02:47:14.921Z","comments":true,"path":"Work-Related/个人PPT汇总/","link":"","permalink":"http://it.jiu-shu.com/Work-Related/个人PPT汇总/","excerpt":"","text":"OKCHEM2.0 平台系列OKCHEM 平台技术简介 OKCHEM-Platform-Technical-Overview.pptx 其他理想的基于Rest API的微服务架构：okchem-micro-services.pptx 配合AWS S3的图片服务设计：图片服务设计.pptx Keynote 作品逍逍家的家规： Keynote 文件： jiu-shu-family-rules.key PDF在线阅读： jiu-shu-family-rules.pdf","categories":[],"tags":[]},{"title":"工具资源收集","slug":"Work-Related/resources-tools","date":"2018-12-21T01:49:27.069Z","updated":"2018-12-21T02:21:19.406Z","comments":true,"path":"Work-Related/resources-tools/","link":"","permalink":"http://it.jiu-shu.com/Work-Related/resources-tools/","excerpt":"","text":"视频及直播微吼: http://www.vhall.com/saas 字体资源 阿里 http://www.iconfont.cn/ Font Awesome https://fontawesome.com/icons?d=gallery 文件检索 火萤 http://www.huoying666.com/ 可用于PPT 文件检索 https://github.com/Wox-launcher/Wox 设计网站MAKA http://maka.im","categories":[],"tags":[]},{"title":"PPT 初学笔记","slug":"Work-Related/primary-learning-notes","date":"2018-12-21T01:49:27.066Z","updated":"2018-12-21T02:21:16.075Z","comments":true,"path":"Work-Related/primary-learning-notes/","link":"","permalink":"http://it.jiu-shu.com/Work-Related/primary-learning-notes/","excerpt":"","text":"字体选择商务字体 微软雅黑 思源黑体 方正超粗黑体 方正超粗黑体 方正兰亭黑 黑体 等线 如何做好表格三步： 建立主色调； 建立边框线；规律性底纹 排版原则 对齐 对比 （颜色， 大小，形状，距离） 亲密性 （相关内容靠近在一起） 重复性/一致性 ( logo； 图片；字体；色彩；一切为了风格一致） 排版风格 分割 分裂 对称 杂志","categories":[],"tags":[]},{"title":"使用Hexo 来建立个人网站","slug":"Work-Related/hexo-usage","date":"2018-12-21T01:49:27.025Z","updated":"2018-12-21T02:21:13.034Z","comments":true,"path":"Work-Related/hexo-usage/","link":"","permalink":"http://it.jiu-shu.com/Work-Related/hexo-usage/","excerpt":"","text":"使用说明参考: https://hexo.io/zh-cn/docs/ themes 收集艺术类： https://github.com/sharvaridesai/hexo-theme-edinburgh 带有搜索和评论的 https://github.com/wzpan/hexo-theme-freemind https://github.com/iTimeTraveler/hexo-theme-hipaper 古老新闻风格 带有markdown 目录 https://github.com/iTimeTraveler/hexo-theme-hiero 和上面类似 https://github.com/ppoffice/hexo-theme-hueman 漂亮的一个 https://github.com/xaoxuu/hexo-theme-material-x 还不错 其他： https://github.com/wuchong/jacman https://github.com/RandomAdversary/Gradient https://github.com/huan555/lemon-lime https://github.com/zalando-incubator/hexo-theme-doc 适合做项目文档","categories":[],"tags":[]},{"title":"网站SEO优化最佳实践","slug":"Web-Applications-Technologies/网站SEO经验总结","date":"2018-12-21T01:49:27.021Z","updated":"2018-12-21T02:21:08.829Z","comments":true,"path":"Web-Applications-Technologies/网站SEO经验总结/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/网站SEO经验总结/","excerpt":"","text":"网站 SEO 实践及注意事项SEO着重于提高页面的收录率及网站在搜索引擎中的排名。 代码规范 确保网页文件返回的文件头正确。 如：如果是404页面就一定是返回404文件头，如果返回错误，就会出问题的。也不要返回多个文件头。 代码中，除了&lt;!DOCTYPE声明外，请一律用小写；代码中不要有多余的换行和空格，这样凭空增加了页面的大小。 页面要尽量符合W3C标准。 如果不能做到的情况下，html标签一定要关闭，否则搜索引擎会直接略过它不能确定的内容；属性值必须带上英文双引号。 禁止使用隐藏链接。会被搜索引擎认为隐藏链接的做法，就是 标签之间是空的，没有图片或者文字。比如： 请尽量把页面中的CSS代码和 javascript代码外调。不能外调的，请尽量把代码往下挪。 一个网页中所有的链接都要尽量用绝对路径，除非影响性能或者一定需要用相对路径不可。 页面代码中，写在javascript中的链接，搜索引擎是可以读的，所以有什么不想搜索引擎收录的链接，万一要写在JS代码中的话，请把JS外调。 DIV的嵌套是不可避免的，但是在有嵌套的时候，请选择嵌套层级最少的那个方法。 URL 规范 URL 全部小写； URL中最好有关键词的存在，并且关键词之间用中划线连接； URL 尽可能静态化，参数最多不能超过3个(比如： products?category=shoes 可以静态化为/shoes/product, 对应的pattern为：/{category}/products) 使用 rel=”canonical” 链接元素指明首选网址。 页面H标签的使用H标签在页面代码当中起着引导性作用，对于搜索引擎来说，标签的存在意义是为了让搜索引擎定位并识别到这一部分的文字或是重点主题的内容。对网页的重要内容而言，它起着“强调作用”。 在实际的运用当中，由于H1-H6标签文字是由大至小，其重要与权重的高低程度是按排号依次递减的，因此我们都会对这些标签的使用进行分配：H1（内容主题）、H2（段落标题）、H3（小段落标题）以此类推至H6标签。 参考：链接：https://www.chinaz.com/web/2015/0730/428499.shtml SiteMap 网站必须有sitemap 根据语言的二级域名要分别创建各自的sitemap sitemap中的 必填 多语言 标记当前页面语言 使用标签表明当前页面内容的语言 使用 hreflang 设置语言和区域网址， 例如：123&lt;link rel=&quot;alternate&quot; hreflang=&quot;en&quot; href=&quot;https://www.okchem.com/&quot; /&gt;&lt;link rel=&quot;alternate&quot; hreflang=&quot;es&quot; href=&quot;https://es.okchem.com/&quot; /&gt;&lt;link rel=&quot;alternate&quot; hreflang=&quot;pt&quot; href=&quot;https://pt.okchem.com/&quot; /&gt; 图片相关 对于网页中图片的高或宽大于200像素的图片，一定要在代码中看到图片地址而且写上这张图片的高宽大小，以及alt文本和 title文本。 &lt;img height=&quot;290&quot; src=&quot; &quot; width=&quot;295&quot; alt=&quot; &quot; title=&quot; &quot; /&gt; alt和title可以一样，但是不能堆砌关键词。 当链接对象是图片的时候，图片要有alt和title属性 &lt;a href=&quot;****&quot; title=&quot; &quot;&gt; &lt;img src=&quot; &quot; alt=&quot; &quot; /&gt; &lt;/a&gt; 网站响应时间网站相应时间无论从用户体验或者SEO的角度来讲都很重要。影响响应时间有很多因素： 1. 利用浏览器缓存; 图片大小；一般情况所有图片必须经过压缩处理；一般来讲banner不能超过100k，缩略图不能超过15K。 优化图片可以通过压缩大图，合并小图减少网络请求 3. JS和CSS； 过多和过大的JS和CSS资源也同样会影响网页速度。合并压缩JS和CSS；适当异步加载JS都可以提高相应速度。（异步加载的JS不参与页面的渲染） 4. CDN 缓存静态资源； 5. 独立静态资源的服务，提高浏览器并发 Etag 和 Cache Controller 都需要etag 是在服务器端做对比Cache Controller 可以让图片请求直接不去请求服务器 网站管理事项 网页上已存在的链接，如果需要撤消或更改，需要让SEO人员知道并确认；最好的情况是不要随便删除。变更URL的时候使用301重定向跳转，不要使用302。 链接的文本要和被链接的页面内容保持一致。 可用性及响应速度； 不能宕机或者经常出现404页面 擅用Robots.txt 文件。网站后台不需要展现给搜索引擎的目录，请用Robots.txt文件屏蔽。 应该形成习惯，把不需要让搜索引擎知道的目录，在网站的根目录下的robots.txt文件中屏蔽它。 要用任何阻止大量爬虫访问的系统。 比如防采集系统不要用。虽然爬虫确实占了很大一部分的带宽，但是是有价值的。 网站是否存在死链使用xenu 这个工具可以扫面网站是否存在死链接 注意事项 慎用代码copy。 网站上的某些代码，对于网站功能方面是不会有影响的。但是可能是对搜索引擎爬虫有影响的。所以以下的代码copy是要注意的：比如：&lt;title&gt;&lt;/title&gt; &lt;meta&gt; &lt;a href= rel=”nofollow”&gt; TDKTDK 规则（待补充） 不同的页面要避免重复的tdk，如果重复会导致google不认你设置的tdk。 Why Won’t Google Use My META Description Google SEO 相关链接 Google SEO的帮助文档 google可以识别的元标记 https://support.google.com/webmasters/answer/79812, （google 并不认可keyword的meta信息 https://webmasters.googleblog.com/2016/11/saying-goodbye-to-content-keywords.html?hl=zh-Hans&amp;visit_id=1-636691380412463003-1651263000&amp;rd=1） 其他参考移动前端不得不了解的HTML5 head 头标签https://www.cnblogs.com/happiness-mumu/p/6054852.html 分析工具https://gtmetrix.com/reports/www.okchem.com/3HaT9qRN","categories":[],"tags":[]},{"title":"社交分享在网站中的实现","slug":"Web-Applications-Technologies/Website-Social-Share","date":"2018-12-21T01:49:27.019Z","updated":"2018-12-21T02:47:14.905Z","comments":true,"path":"Web-Applications-Technologies/Website-Social-Share/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/Website-Social-Share/","excerpt":"","text":"公司的web项目中，经常会有社交分享，这里简单说明下，方便后面开发人员理解。 分享的原理社交分享(linkedin, facebook, twitter)的本质就是请求其一个公开的页面。通过参数告诉社交网站你需要分享的网页的网址，然后社交网站的爬虫会去爬取这个网址。显然，你分享的网页必须是可以匿名从公网访问的；爬虫爬取和谷歌，百度的爬虫是一个道理，只是各自算法不一样。常用的社交网站的分享链接如下： Linkedin http://www.linkedin.com/shareArticle?url=https://www.okchem.com/instant-quote Facebook http://www.facebook.com/sharer.php?u= https://www.okchem.com/instant-quote Twitter http://twitter.com/share?url=https://www.okchem.com/instant-quote更多参数可以参考相关文档，但是基本上这个参数就行了 分享内容定制一般情况下，类似谷歌和百度的爬虫，会爬取title description （和SEO中的一样）还有图片等作为缩略展示。 因为各自算法的原因，并不是100%能保证你的title和description就会被展示出来；也不能保证你想要出现的图片就以一定会出现在缩略中。如果想告知爬虫你的网页的title description和图片等，可以通过Open Graph Meta Tags 来指引爬虫。 具体可以参考http://ogp.me/， 详情请去百度和google。示例： 123456&lt;meta property=&quot;og:title&quot; content=&quot;[Hot Item] Ce Approved Superfine Synthetic Graphite Spheroidization Grinding Mill&quot;/&gt;&lt;meta property=&quot;og:type&quot; content=&quot;product&quot;/&gt;&lt;meta property=&quot;og:url&quot; content=&quot;http://leap-tech.en.made-in-china.com/product/gBvQXLzMCKcJ/China-Ce-Approved-Superfine-Synthetic-Graphite-Spheroidization-Grinding-Mill.html&quot;/&gt;&lt;meta property=&quot;og:image&quot; content=&quot;http://image.made-in-china.com/2f0j00sJdQPUDMngkI/Ce-Approved-Superfine-Synthetic-Graphite-Spheroidization-Grinding-Mill.jpg&quot;/&gt;&lt;meta property=&quot;og:site_name&quot; content=&quot;Made-in-China.com&quot;/&gt;&lt;meta property=&quot;og:description&quot; content=&quot;This site would be your best choice when sourcing from China. Their buyer service is professional and it offers third party transaction service to protect your money&quot;/&gt; 摘自网站http://leap-tech.en.made-in-china.com/product/gBvQXLzMCKcJ/China-Ce-Approved-Superfine-Synthetic-Graphite-Spheroidization-Grinding-Mill.html 通过og标签分别告知爬虫这个页面的title, url, image, description。 当页面有很多图片，可以通过og:image来告知社交网站采用哪张图片做缩略显示。 前面的描述中，都用了告知，引导。 就像谷歌爬虫一样，社交网站的爬虫也只是尊重你的页面的设置，但是他们更依赖自己的算法。所以并不会100% follow。 注意事项在测试的时候很容易碰见，分享的时候没有看见缩略图，内容没更新等等问题。很可能和各自的缓存有关，也可能是你的页面的内容不对。Facebook有调试工具：https://developers.facebook.com/tools/debug/sharinghttps://developers.facebook.com/docs/sharing/best-practices 分享facebook的时候有可能预览的图片不能及显示，方案可以参考: https://developers.facebook.com/docs/sharing/best-practices#precaching Linked in 的分享说明参考：https://developer.linkedin.com/docs/share-on-linkedin# 注意最后提到的缓存。 Twitter的工具参考：https://cards-dev.twitter.com/validator 要想分享在Twitter上正常显示，下面的标签必须全部都加上。1234&lt;meta property=&quot;og:type&quot; content=&quot;website&quot;&gt;&lt;meta property=&quot;og:image&quot; content=&quot;your page image url&quot;/&gt;&lt;meta property=&quot;og:title&quot; content=&quot;Title of the page&quot;/&gt;&lt;meta property=&quot;og:description&quot; content=&quot;Description of your page&quot;/&gt;","categories":[],"tags":[]},{"title":"同源策略下为什么还需要防御CSRF","slug":"Web-Applications-Technologies/web-security-csrf","date":"2018-12-21T01:49:27.015Z","updated":"2018-12-21T02:47:14.918Z","comments":true,"path":"Web-Applications-Technologies/web-security-csrf/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/web-security-csrf/","excerpt":"","text":"前面的章节搞定跨域资源共享 (CORS)中我们提到了浏览器的同源的安全策略，就算允许跨域，也可以限制被允许的域；比如只限制同一个父域下面的子域名来访问资源。 为什么在这样的策略下面，我们依然需要应对CSRF（Cross Site Request Forgery，跨站请求伪造）？ 通过下面的两张图来快速理解CSRF的存在。 CSRF攻击的一个很好的例子可能是受害者最近在他们的银行登录帐户并且有效会话启动并运行的攻击。在登录时，会向用户发送一封假冒电子邮件作为他的银行。单击该电子邮件会将他发送到攻击者的站点，该站点的外观可能看起来像银行站点。实际上，该网站对真实银行的运营终端执行POST，以便汇款，将资金从受害者帐户转移到攻击者手中。由于用户的会话仍然有效，因此接受操作并且攻击成功。 演示CSRF的存在 我们采用第二章图的方式来演示在同源策略下CSRF的示例。 首先注册并登录： https://www.okchem.com/group-buying 然后打开页面: http://corsweb.jiu-shu.com/csrf-chembnb-logout.html ，此页面会通过以下方式将用户的会话注销。 1&lt;img style=&quot;display:none&quot; src=&quot;https://www.okchem.com/group-buying/logout&quot;&gt; 再次回到https://www.okchem.com/group-buying 刷新页面，可以发现会话已经注销。 这里只是个简单的验证，消除疑虑，证明Web网站CRSF防御的存在的必要性。 阻止CSRF策略CSRF 的两个重要特点 伪造请求的网站必须利用用户在被攻击的网站的会话 伪造请求的网站并没有访问被攻击网站的页面 策略一 从上可以看出，可以在form表单中添加csrf token，服务器端验证比对来防止csrf。 另外两点和浏览器本身及同源策略有关的是 你在domain a 的页面发送一个请求向domain b的时候可以自动带上domain b的cookie。( 这点给了CSRF的机会) 你在domain a的页面无法读取domain b的cookie (这里引出了另一个策略) 策略二 domain b的交易比对请求头中的csrf token和cookie中的token；b网站只需要在请求的时候从cookie中读取csrf token 放入请求头中个， 在服务器端进行比对即可。","categories":[],"tags":[]},{"title":"Nodejs oauth2 结合 Spring Boot Oauth2 自建 Oauth2 Provider","slug":"Web-Applications-Technologies/Spring-Boot-Oauth2-Provider-Nodejs-Client","date":"2018-12-21T01:49:27.011Z","updated":"2018-12-21T02:21:05.552Z","comments":true,"path":"Web-Applications-Technologies/Spring-Boot-Oauth2-Provider-Nodejs-Client/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/Spring-Boot-Oauth2-Provider-Nodejs-Client/","excerpt":"","text":"参考文档Spring Boot 官方文档 Spring Security Oauth org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerSecurityConfiguration.class line 8912345http .authorizeRequests() .antMatchers(tokenEndpointPath).fullyAuthenticated() // 写死了。。。。 .antMatchers(tokenKeyPath).access(configurer.getTokenKeyAccess()) .antMatchers(checkTokenPath).access(configurer.getCheckTokenAccess()) 运行测试配置Hosts为了更方便的区分，需要配置如下hosts：1127.0.0.1 auth.server.com client.node.com client.springboot.com","categories":[],"tags":[]},{"title":"","slug":"Web-Applications-Technologies/SEO-Public-Website-Practices","date":"2018-12-21T01:49:27.008Z","updated":"2018-03-02T00:52:07.725Z","comments":true,"path":"Web-Applications-Technologies/SEO-Public-Website-Practices/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/SEO-Public-Website-Practices/","excerpt":"","text":"网站 SEO 实践及注意事项提高页面的收录率及网站的排名。 代码规范 确保网页文件返回的文件头正确。 如：如果是404页面就一定是返回404文件头，如果返回错误，就会出问题的。也不要返回多个文件头。 代码中，除了&lt;!DOCTYPE声明外，请一律用小写；代码中不要有多余的换行和空格，这样凭空增加了页面的大小。 页面要尽量符合W3C标准。 如果不能做到的情况下，html标签一定要关闭，否则搜索引擎会直接略过它不能确定的内容；属性值必须带上英文双引号。 禁止使用隐藏链接。会被搜索引擎认为隐藏链接的做法，就是 标签之间是空的，没有图片或者文字。比如： 请尽量把页面中的CSS代码和 javascript代码外调。不能外调的，请尽量把代码往下挪。 一个网页中所有的链接都要尽量用绝对路径，除非影响性能或者一定需要用相对路径不可。 页面代码中，写在javascript中的链接，搜索引擎是可以读的，所以有什么不想搜索引擎收录的链接，万一要写在JS代码中的话，请把JS外调。 DIV的嵌套是不可避免的，但是在有嵌套的时候，请选择嵌套层级最少的那个方法。 URL 规范 URL 全部小写； URL中最好有关键词的存在，并且关键词之间用中划线连接； URL 尽可能静态化，参数最多不能超过3个 使用 rel=”canonical” 链接元素指明首选网址。 网页的URL需要根据网页的结构，有一定的分类。 比如买家个人中心所有页面统一前缀 /buyer , 后台管理统一前缀 /admin 这样方便SEO的robots.txt 的配置 SiteMap 网站必须有sitemap 根据语言的二级域名要分别创建各自的sitemap sitemap中的 必填 多语言 标记当前页面语言 使用标签表明当前页面内容的语言 使用 hreflang 设置语言和区域网址， 例如：12345#!HTML&lt;link rel=&quot;alternate&quot; hreflang=&quot;en&quot; href=&quot;https://www.okchem.com/&quot; /&gt;&lt;link rel=&quot;alternate&quot; hreflang=&quot;es&quot; href=&quot;https://es.okchem.com/&quot; /&gt;&lt;link rel=&quot;alternate&quot; hreflang=&quot;pt&quot; href=&quot;https://pt.okchem.com/&quot; /&gt; 图片相关 对于网页中图片的高或宽大于200像素的图片，一定要在代码中看到图片地址而且写上这张图片的高宽大小，以及alt文本和 title文本。 alt和title可以一样，但是不能堆砌关键词。 当链接对象是图片的时候，图片要有alt和title属性 在优化网站响应时间的各种方式中，压缩图片是性价比最高的手段，简单易行，见效高。 同时如果不考虑图片的大小，负面影响也很大。 如果自己没有好的压缩方式，可以通过google 的 Page Insights 分析网页，同时帮助你压缩。另外图片的名称也不应该随意起名字，图片的链接也是SEO的一部分。 网站响应时间网站相应时间无论从用户体验或者SEO的角度来讲都很重要。影响响应时间有很多因素： 利用浏览器缓存; 图片大小；一般情况所有图片必须经过压缩处理；一般来讲banner不能超过100k，缩略图不能超过15K。 优化图片可以通过压缩大图，合并小图减少网络请求 JS和CSS； 过多和过大的JS和CSS资源也同样会影响网页速度。合并压缩JS和CSS；适当异步加载JS都可以提高相应速度。（异步加载的JS不参与页面的渲染） CDN 缓存静态资源； 独立静态资源的服务，提高浏览器并发 网站管理事项 网页上已存在的链接，如果需要撤消或更改，需要让SEO人员知道并确认；最好的情况是不要随便删除。变更URL的时候使用301重定向跳转，不要使用302。 链接的文本要和被链接的页面内容保持一致。 可用性及响应速度； 不能宕机或者经常出现404页面 擅用Robots.txt 文件。网站后台不需要展现给搜索引擎的目录，请用Robots.txt文件屏蔽。 应该形成习惯，把不需要让搜索引擎知道的目录，在网站的根目录下的robots.txt文件中屏蔽它。 要用任何阻止大量爬虫访问的系统。 比如防采集系统不要用。虽然爬虫确实占了很大一部分的带宽，但是是有价值的。 注意事项 慎用代码copy。 网站上的某些代码，对于网站功能方面是不会有影响的。但是可能是对搜索引擎爬虫有影响的。所以以下的代码copy是要注意的：比如：","categories":[],"tags":[]},{"title":"对公网站研发的实践经验","slug":"Web-Applications-Technologies/Public-Website-Practices","date":"2018-12-21T01:49:26.998Z","updated":"2018-12-21T02:47:14.905Z","comments":true,"path":"Web-Applications-Technologies/Public-Website-Practices/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/Public-Website-Practices/","excerpt":"","text":"有过很多的面向员工系统经验的工程师，在开发一个面向客户的web网站的时候会面临和需要考虑的问题更多，也更复杂。下面列举在开发对公网站时候需要考虑的一些问题和实践。 是否有SEO 需求当有SEO需求的时候，在选择前端框架的时候，需要注意对SEO的支持。 各种流行的框架： React和Angularjs 等SPA的页面框架大部分在SEO方面都多少有些问题SEO 优化： URL 静态化，可读性 (比如： products?category=shoes 可以静态化为/shoes/product, 对应的pattern为：/{category}/products) 页面布局，图片的URL，图片的alt信息 等都需要考虑 网站内的内链 异步使用的恰当，简单的链接更有助于网站收录 SEO 的详细介绍请参考：网站SEO优化最佳实践 网页速度网页相应速度涉及用户体验，同时也会影响到SEO的排名， 可以通过Google Page Insights 来检查网页速度相关问题。 一般优化网页速度的包括： 优化图片。 优化图片一般都是性价比高的提速方案。 优化图片分为： 优化格式，压缩大小。 （之前的做了一次产品的旧图片的压缩，但是还有其他图片需要进一步排查压缩，比如banner） 合并小图片，减少网络请求。将一个个小图片合并成一个大图片，用css 控制显示范围。 懒加载, 针对页面上图片比较多的情况， 比如转灯（bootstrap的carousel），默认情况是所有的图片请求都一直并发；当图片过多的时候对页面的相应影响很大，这个时候要考虑图片的懒加载机制。懒加载参考：页面懒加载机制 合并压缩JS 和 CSS 。 （减小文件大小，减少网络请求） CDN 的引入。 暂时不考虑付费的CND，但是针对jquery及bootstrap等知名的第三方资源，可以使用免费的CDN. (具体依赖预生产的测试来做最终决定) 代码优化。 代码优化比较难在短时间完成。但是可以逐步挑选重要的页面来优化：a) 按需加载， js 引入位置，延迟/异步加载阻塞的js文件。b) 优化cookie，减少cookie的体积c) Js css规范化 Nginx优化。 在查看webpagetest的结果的时候，发现https的握手时间也占了不少比例，针对nginx的ssl的优化也是必须的。（大数据新闻的图片慢有可能和这个有关，具体需要通过测试来验证） （made-in-china 网站仍旧采用的是http，在速度上有很大优势） 将静态资源的请求放入另外的domain来提高浏览器请求的并发 （效仿made-in-china 的做法） 页面静态化处理。 前面讲到的都和服务端代码无关，页面静态化处理主要是在服务端提前将页面生成静态的html文件，提高并发。 目前服务器相应时间并不是主要拖慢网页的因素，因此这个优先级不高。 综合来讲，主要思想是： 减少请求次数，减少文件大小，延迟请求，异步加载，CDN缓存，最小化https的开销。 最后在完成这些之后，更深一步去规范页面内容，JS CSS 最佳实践。 防止攻击Bot Attack如果网站里面有开放的POST接口，通过过一段时间就会遭遇Bot 攻击。通常，添加验证码会是办法之一。 参考讨论Preventing bot form submission 采用google的recaptcha 也会是一个不错的方案。开发者文档 下载相关文件下载最好不要放在网站内， 可以放在云服务器上， 比如aws的s3， 或者其他云对象服务器上。注意download的response 相关的header设置等。比如： apk的下载， 有些浏览器无法智能的根据文件名后缀.apk来判断是安卓的安装程序。需要显示的设置： content-type： application/vnd.android.package-archive 需要更多的手段来验证网站的可用性面向员工的系统，如果系统不可用，或者有任何问题发生，员工都会立马反应。（很可能他现在要提交个工单，提交不了，着急啊。。。） 然后面向光大客户的就不是了。 比如说， 淘宝现在用不了了，系统报错，你会想淘宝反应吗？ 我想你会去京东买了算了。。。","categories":[],"tags":[]},{"title":"利用Spring Boot Oauth2 来熟悉oauth2 之 - Authorization Code Grant","slug":"Web-Applications-Technologies/Oauth2-Spring-Boot","date":"2018-12-21T01:49:26.996Z","updated":"2018-12-21T02:47:14.918Z","comments":true,"path":"Web-Applications-Technologies/Oauth2-Spring-Boot/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/Oauth2-Spring-Boot/","excerpt":"","text":"参考文献 rfc 文档： RFC 6749 - The OAuth 2.0 Authorization Framework Spring boot oauth2 示例 Tutorial · Spring Boot and OAuth2 代码：https://github.com/spring-guides/tut-spring-boot-oauth2 流程图从RFC文档复制过来的流程图， 来辅助我们理解oauth2 的Authorization Code Grant 探究竟clone代码，将maven的工程（tut-spring-boot-oauth2\\simple）导入eclipse跑起来。 You can also run all the apps on the command line using mvn spring-boot:run or by building the jar file and running it with mvn package and java -jar target/*.jar 代码就一个文件，简单如下： 123456789@SpringBootApplication@EnableOAuth2Ssopublic class SocialApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SocialApplication.class, args); &#125;&#125; 接力于Spring Boot的Auto Configuration 的功能，我们不需要做任何的配置。 由于引入了spring-boot-starter-security 默认情况下，所有的请求都需求登录。Chrome打开http://localhost:8080， 并打开开发者工具，选中’Preserve log’; 浏览器将自动重定向到/login; 由于oauth2 client的引入，请求又再次被重定向至facebook进行授权；开始了授权的流程。 在chrome的开发者工具中Network 标签， 按住CTRL/CMD 选中Doc和Other可以过滤掉大部分静态资源请求，方便我们来分析整个流程 角色解释官方解释请参考：Oauth2 Roles在我们这个示例中： Resource Owner： 人，也就是这个facebook 账号的所有人 User Agent： 这里就是Chrome 浏览器 Client：代表Owner去请求被保户的资源的应用（这里就是Spring Boot的Web App） Resource Server： Facebook 授权能访问的资源服务（这里拿到access token后获取了用户的信息，没有访问其他的Resource Server） Authorization Server： 集中授权服务器，负责验证access token 流程分解1. 请求资源服务首页请求资源首页：http://localhost:8080/ Response 302 ： 12345...Location:http://localhost:8080/login...Set-Cookie:JSESSIONID=8C24D287C93ECDE88C3D4BD7410668FB;path=/;HttpOnly... 2. 跳转至登录页面跳转至登录：http://localhost:8080/login Request Headers: SESSIONID=8C24D287C93ECDE88C3D4BD7410668FB Reponse Headers: Location:https://www.facebook.com/dialog/oauth?client_id=233668646673605&amp;redirect_uri=http://localhost:8080/login&amp;response_type=code&amp;state=undAFm 3. 页面将跳转至facebook,开始Authorization Code Grant的流程, 对应流程图中的步骤(A) https://www.facebook.com/dialog/oauth?client_id=233668646673605&amp;redirect_uri=http://localhost:8080/login&amp;response_type=code&amp;state=undAFm请求的URL参数包括了用户的标识，本地生成的state以及授权成功后返回到资源服务的地址。response_type=code 标识了授权的类型是“Authorization Code Grant” The client includes its client identifier, requested scope, local state, and a redirection URI to which the authorization server will send the user-agent back once access is granted (or denied). Facebook未检测到任何用户登录信息，重定向至facebook的登录页面。 4. 请求登录页面5. 输入账号信息后，点击登录后的post 请求登录成功后，重定向至facebook的oauth页面进行流程的（B）步骤 6. 登录成功后，进入oauth页面进入流程的(B)截图是第二次尝试，由于第一次的时候用户针对当前client已经授权访问基本信息后。 在第二次登录后，授权的页面就不会出现， 而是直接重定向到被授权client的redirect_uri。流程中的(C) 也就同B一起在没有和用户交互的情况下完成了。 C步骤中，服务器回应客户端的URI，包含以下参数：code：表示授权码，必选项。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系。state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。 7. 拿着facebook授权的code进行资源服务的login请求/login?code=** Spring Boot Oauth2 拿到对应的code后，1)去facebook请求获取access token; 2)获取到对应的token信息后既可以通过token进一步获取用户相关信息（这两步的api 请求是在服务器端进行），进而完成Spring Boot的Authentication, 成功后重定向到请求1（第一步）；同时创建了新的session。 从上面的步骤及截图的status code可以看出来整个oauth2的流程基本是在重定向中完成。3,4,5,6 分别与资源服务无关 （即：Spring Boot Web 应用无关）。 Spring是如何将authentication 导向/代理给 oauth2 client的？这些都在引入的依赖帮我们自动实现了。 其他网络资源理解OAuth 2.0 - 阮一峰的网络日志","categories":[],"tags":[]},{"title":"页面图片懒加载机制","slug":"Web-Applications-Technologies/image-lazy-loading","date":"2018-12-21T01:49:26.945Z","updated":"2018-12-21T02:47:14.893Z","comments":true,"path":"Web-Applications-Technologies/image-lazy-loading/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/image-lazy-loading/","excerpt":"","text":"页面图片请求太多，影响整个页面的相应速度，采用懒加载机制可以提速。本文采用bootstrap的转灯carousel做为示例 非懒加载如果一个页面比较复杂, 转灯有几十上百个图片，无疑会很影响页面的性能。下面这个是笔者实际经历的，转灯有几十个slides, 图片就更多了，一次性的图片并发相当大，严重影响页面的响应速度。 下面的代码是bootstrap的转灯carousel的示例，通过chrome的开发者工具可以看到，会有三个image的request 发出。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;title&gt;Bootstrap Example&lt;/title&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\"&gt; &lt;script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"container\"&gt; &lt;h2&gt;Carousel Example&lt;/h2&gt; &lt;div id=\"myCarousel\" class=\"carousel slide\" data-ride=\"carousel\"&gt; &lt;!-- Indicators --&gt; &lt;ol class=\"carousel-indicators\"&gt; &lt;li data-target=\"#myCarousel\" data-slide-to=\"0\" class=\"active\"&gt;&lt;/li&gt; &lt;li data-target=\"#myCarousel\" data-slide-to=\"1\"&gt;&lt;/li&gt; &lt;li data-target=\"#myCarousel\" data-slide-to=\"2\"&gt;&lt;/li&gt; &lt;/ol&gt; &lt;!-- Wrapper for slides --&gt; &lt;div class=\"carousel-inner\"&gt; &lt;div class=\"item active\"&gt; &lt;img src=\"images/portfolio-img1.jpg\" alt=\"Los Angeles\" style=\"width:100%;\"&gt; &lt;/div&gt; &lt;div class=\"item\"&gt; &lt;img src=\"images/portfolio-img2.jpg\" alt=\"Chicago\" style=\"width:100%;\"&gt; &lt;/div&gt; &lt;div class=\"item\"&gt; &lt;img src=\"images/portfolio-img3.jpg\" alt=\"New york\" style=\"width:100%;\"&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- Left and right controls --&gt; &lt;a class=\"left carousel-control\" href=\"#myCarousel\" data-slide=\"prev\"&gt; &lt;span class=\"glyphicon glyphicon-chevron-left\"&gt;&lt;/span&gt; &lt;span class=\"sr-only\"&gt;Previous&lt;/span&gt; &lt;/a&gt; &lt;a class=\"right carousel-control\" href=\"#myCarousel\" data-slide=\"next\"&gt; &lt;span class=\"glyphicon glyphicon-chevron-right\"&gt;&lt;/span&gt; &lt;span class=\"sr-only\"&gt;Next&lt;/span&gt; &lt;/a&gt; &lt;/div&gt;&lt;/div&gt;&lt;script&gt; $(function() &#123; $('#myCarousel').on('slide.bs.carousel', function(ev) &#123; var lazy; lazy = $(ev.relatedTarget).find(\"img[data-src]\"); lazy.attr(\"src\", lazy.data('src')); lazy.removeAttr(\"data-src\"); &#125;); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 懒加载通过chrome的开发者工具可以看到进入页面后初始只有第一个图片的请求产生。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;title&gt;Bootstrap Example&lt;/title&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\"&gt; &lt;script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"container\"&gt; &lt;h2&gt;Carousel Example&lt;/h2&gt; &lt;div id=\"myCarousel\" class=\"carousel slide lazy\" data-ride=\"carousel\"&gt; &lt;!-- Indicators --&gt; &lt;ol class=\"carousel-indicators\"&gt; &lt;li data-target=\"#myCarousel\" data-slide-to=\"0\" class=\"active\"&gt;&lt;/li&gt; &lt;li data-target=\"#myCarousel\" data-slide-to=\"1\"&gt;&lt;/li&gt; &lt;li data-target=\"#myCarousel\" data-slide-to=\"2\"&gt;&lt;/li&gt; &lt;/ol&gt; &lt;!-- Wrapper for slides --&gt; &lt;div class=\"carousel-inner\"&gt; &lt;div class=\"item active\"&gt; &lt;img src=\"images/portfolio-img1.jpg\" alt=\"Los Angeles\" style=\"width:100%;\"&gt; &lt;/div&gt; &lt;div class=\"item\"&gt; &lt;img data-src=\"images/portfolio-img2.jpg\" alt=\"Chicago\" style=\"width:100%;\"&gt; &lt;/div&gt; &lt;div class=\"item\"&gt; &lt;img data-src=\"images/portfolio-img3.jpg\" alt=\"New york\" style=\"width:100%;\"&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- Left and right controls --&gt; &lt;a class=\"left carousel-control\" href=\"#myCarousel\" data-slide=\"prev\"&gt; &lt;span class=\"glyphicon glyphicon-chevron-left\"&gt;&lt;/span&gt; &lt;span class=\"sr-only\"&gt;Previous&lt;/span&gt; &lt;/a&gt; &lt;a class=\"right carousel-control\" href=\"#myCarousel\" data-slide=\"next\"&gt; &lt;span class=\"glyphicon glyphicon-chevron-right\"&gt;&lt;/span&gt; &lt;span class=\"sr-only\"&gt;Next&lt;/span&gt; &lt;/a&gt; &lt;/div&gt;&lt;/div&gt;&lt;script&gt; $(function() &#123; $('#myCarousel').on('slide.bs.carousel', function(ev) &#123; var lazy; lazy = $(ev.relatedTarget).find(\"img[data-src]\"); lazy.attr(\"src\", lazy.data('src')); lazy.removeAttr(\"data-src\"); &#125;); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;","categories":[],"tags":[]},{"title":"Http Cookie 探索","slug":"Web-Applications-Technologies/Http-Cookie-Technologies","date":"2018-12-21T01:49:26.935Z","updated":"2018-12-21T02:47:14.905Z","comments":true,"path":"Web-Applications-Technologies/Http-Cookie-Technologies/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/Http-Cookie-Technologies/","excerpt":"","text":"Meta 信息不见了 参考：http://blog.csdn.net/lijing198997/article/details/9378047http://stackoverflow.com/questions/1062963/how-do-browser-cookie-domains-workDomain and Path作用：定义Cookie的生效作用域，只有当域名和路径同时满足的时候，浏览器才会将Cookie发送给Server。如果没有设置Domain和Path的话，他们会被默认为当前请求页面对应值。 Cookie with Domain=.example.com will be available for www.example.comCookie with Domain=.example.com will be available for example.comCookie with Domain=example.com will be converted to .example.com and thus will also be available for www.example.comCookie with Domain=example.com will not be available for anotherexample.com跨域的请求是无法设置cookie的。 （） Example： Tomcat Java Web App通过服务端来设置浏览器cookie服务端在请求的返回中向客户端的浏览器添加cookie。 示例的服务的context path 为/bee 1234567891011121314151617181920@RequestMapping(value = &quot;/cookietest&quot;, headers = &quot;Accept=image/**&quot;, method = RequestMethod.GET)public ResponseEntity&lt;?&gt; cookieTest(final HttpServletRequest request,HttpServletResponse response) &#123; Cookie cookie1 = new Cookie(&quot;cookie-1&quot;,UUID.randomUUID().toString()); cookie1.setDomain(&quot;diaoyouyun.com&quot;); cookie1.setPath(&quot;/&quot;); response.addCookie(cookie1); Cookie cookie2 = new Cookie(&quot;cookie2&quot;,&quot;Cookie2&quot;); cookie2.setDomain(&quot;www.diaoyouyun.com&quot;); cookie2.setPath(&quot;/bee/collect&quot;); response.addCookie(cookie2); Cookie cookie3 = new Cookie(&quot;cookie3&quot;,&quot;cookie3&quot;); cookie3.setDomain(&quot;www.example.com&quot;); response.addCookie(cookie3); Cookie cookie4 = new Cookie(&quot;cookie4&quot;,&quot;cookie4&quot;); response.addCookie(cookie4); return ok();&#125; 测试一请求 http://diaoyouyun.com/bee/cookietest 如下： 那些cookie会被接受呢？访问http://diaoyouyun.com/bee 从下图可以看出 访问http://www.diaoyouyun.com/bee/来查看有哪些cookie 关于Java Tomcat 服务端Set-Cookie: 可以得出以下结论： 不显示地设置domain，浏览器接受去当年请求的domain，但是前面不加点（.）。即：如果当前请求domain是example.com,那么这个cookie就不能被www.example.com 或者其他***.example.com访问到. 显示设置domain，只有设置正确的情况，cookie才会被浏览器接受 测试二 测试前清空相关站点的cookie 通过请求：http://www.diaoyouyun.com/bee/cookietest 来设置cookie访问http://www.diaoyouyun.com/bee/发现还是只有cookie-1和cookie4， 但是其实cookie2 也被浏览器接受了，只是cookie2 设置的path是/bee/collect 所以基于当前访问路径（http://www.diaoyouyun.com/bee/）chrome的开放工具中无法查看到cookie2。通过查看浏览器上所有站点cookie内容，可以在www.diaoyouyun.com 中找到cookie2。 （反思：**测试一的 cookie2 是否真的未被接受？） 访问http://diaoyouyun.com/bee/ 查看cookie发现只有cookie-1。（cookie4是子域名下的） 测试三 cookie2 在测试一是否真的未设置成功cookie2 是path导致的无法查看到? 将path修改后再次走一遍测试一1cookie2.setPath(&quot;/&quot;); 经过验证，cookies2未设置成功 测试四 跨域请求无法设置cookie以下请求是无法设置cookie的 上面的请求cookie1 2 3 4 都无法设置成功。如果在浏览器直接访问http://api/diaoyouyun.com/bee/cookietest cookie1 和cookie4 可以添加成功 总结 子域名请求可以设置父域名下cookie。即：www.diaoyouyun.com的请求可以设置cookie （domain=diaoyouyun.com，所有diaoyouyun.com及其子域名下site都能查看） 父级域名的请求不能设置子域名的cookie。 即：http://diaoyouyun.com/** 的请求无法设置cookie(domain=www.diaoyouyun.com)。 简化记忆可以理解为，有子肯定存在父，反过来就不成立了。 跨域的请求是无法成功设置cookie的。","categories":[],"tags":[]},{"title":"Google Analytics 知识点汇总","slug":"Web-Applications-Technologies/google-analytics-notes","date":"2018-12-21T01:49:26.925Z","updated":"2018-12-21T02:20:48.284Z","comments":true,"path":"Web-Applications-Technologies/google-analytics-notes/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/google-analytics-notes/","excerpt":"","text":"使用GA来分析网站的数据推广链接的参数参考 自定义广告系列 - Google Analytics（分析）帮助","categories":[],"tags":[]},{"title":"资源收集","slug":"Web-Applications-Technologies/development-resources","date":"2018-12-21T01:49:26.922Z","updated":"2018-12-21T02:20:41.927Z","comments":true,"path":"Web-Applications-Technologies/development-resources/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/development-resources/","excerpt":"","text":"网站收集 国家旗帜图标：https://countryflags.io/ JS 库Bootstrap TagsInputhttp://bootstrap-tagsinput.github.io/bootstrap-tagsinput/examples/ url.jshttps://github.com/jillix/url.js 工具Eclise 插件 资源文件（.properties 去重，多个语言并列编辑） 插件 ResourceBundle Editor 爬虫工具火车头 大文件拆分用notepad++ 64 位版 在线工具Json to Excelhttps://json-csv.com/ Excel To Jsonhttps://codebeautify.org/excel-to-json Json Validationhttps://jsonlint.com/ Excel 转 Markdown Tablehttp://www.tablesgenerator.com/markdown_tables 在线CMShttps://www.odoo.com/zh_CN/ Chrome 插件Run Javascript可以在登录后获取到会话，通过Run Javascript来爬取需要登录的API","categories":[],"tags":[]},{"title":"搞定跨域资源共享 (CORS)","slug":"Web-Applications-Technologies/cors-solution","date":"2018-12-21T01:49:26.909Z","updated":"2018-12-21T02:47:14.892Z","comments":true,"path":"Web-Applications-Technologies/cors-solution/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/cors-solution/","excerpt":"","text":"通过多个Nodejs Web App一步步来深入了解CORS每个细节，每步都通过实际的验证；最终给出Nodejs Express Web和Java Spring Web的代码示例。 测试CORS代码库： git@github.com:choelea/cors-tester.git 什么是CORS解释这个概念之前先要认识下什么是 域(Origin)。 什么是Origin域是 协议(http/https)+域名+端口的组合。 An origin is defined as a combination of URI scheme, host name, and port number.摘自：https://en.wikipedia.org/wiki/Same-origin_policy 这个是一个标准，但不是所有浏览器的所有版本都严格执行了，特别是关于端口这点。 通过下面的表可以更直观的认识到什么才是’同一个域(同源)‘。(图标截自维基百科) CORS 定义Cross-origin resource sharing (CORS)； 跨域资源共享（CORS）是一种机制，这种机制在允许在网页中请求另一个域受限制的资源。摘自维基百科: https://en.wikipedia.org/wiki/Cross-origin_resource_sharing 这里的受限制并不是说这些资源需要登录厚着授权等 哪些资源是默认可以跨域的上面定义提到了”受限制”, 也就是说不是所有的跨域资源需要CORS机制。在不做任何设置的的时候，默认图片, css, js 等请求都是可以跨域的。 如果你的css有针对字体的请求，你会发现字体请求默认也是受到同源机制的限制；包括js 和css对应的map文件的请求都无法跨域访问。 AJAX请求可以吗浏览器打开http://corsdisableapi.jiu-shu.com/users可以获取到json结果如下：12345678[ &#123; &quot;name&quot;: &quot;Joe&quot; &#125;, &#123; &quot;name&quot;: &quot;Mark&quot; &#125;] 但是我们打开页面http://corsweb.jiu-shu.com/public-resources.html (或者任何其他域),在console里面做出如下请求：123var xhr = new XMLHttpRequest();xhr.open(&apos;GET&apos;, &apos;http://corsdisableapi.jiu-shu.com/users&apos;); xhr.send(); 你会发现console报出了如下的错误; 很明显请求是收到同源机制的限制。 打开页面http://corsweb.jiu-shu.com/public-resources.html 通过源代码和开发者工具理解这一节知识。 开启CORS很明显很多时候我们必须有个策略来突破/放宽同源政策的限制； 比如Web页面www.example.com 需要请求api.example.com的资源；比如：PC站www.example.com 和M站m.example.com 需要共同获取/修改api.example.com的资源。 CORS 只是突破/放宽同源政策中的一个种, 其他具体可以参考： https://en.wikipedia.org/wiki/Same-origin_policy CORS需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，IE浏览器不能低于IE10。 整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。 因此，实现CORS通信的关键是服务器。只要服务器实现了CORS的标准，就可以跨源通信。 服务端开启CORS这里示例代码均采用nodejs express 的web应用，使用cors组件即可轻松实现服务端开启CORS。将之前的corsdisableapi.jiu-shu.com服务复制一份增加CORS的支持，以corsenable.jiu-shu.com这个域来提供；然后访问页面http://corsweb.jiu-shu.com/request-cors-resources.html 对比前面一个页面 http://corsweb.jiu-shu.com/public-resources.html 可以发现之前浏览器console抛出的cors相关的错误全部消失了。 浏览器的两种CORS请求大部分有些了解CORS都听过OPTION请求; 也叫”预检”请求（preflight）。但是前面的页面http://corsweb.jiu-shu.com/request-cors-resources.html 中的跨域的请求，通过开发者工具查看，在network这个标签中无法找到OPTION的请求。这是因为CORS有两种请求：简单请求和非简单请求；简单请求是不需要预检请求的。 但是无论是什么CORS请求，浏览器都会自动加上Origin这个header。 简单请求一般来说满足下面的有可能是简单请求。 请求方法是 HEAD/GET/POST HTTP的头信息中没有自定义的Header；Content-Type不能是application/json 简单请求，浏览器只需要发出一个请求就可以拿到想要的结果。 暂时没有完全找到简单请求的完整定于及所有场景，但是一般情况我们不需要考虑，因为你一定需要支持非简单请求的情况。 非简单请求非简单请求就需要”预检”请求(preflight); 浏览器根据preflight的结果来决定下一个正式请求是否可以发以及怎么发。 访问页面http://corsweb.jiu-shu.com/request-cors-resources.html 打开console输入下面请求，观察网络请求，可以发现两个请求。1234var xhr = new XMLHttpRequest();xhr.open(&apos;GET&apos;, &apos;http://corsenableapi.jiu-shu.com/users&apos;); xhr.setRequestHeader(&apos;Content-Type&apos;, &apos;application/json&apos;);xhr.send(); CORS相关字段理解上面之后我们需要开始了解头信息中和CORS相关的字段，这些字段都是Access-Control-开头。 预检请求的相关字段Access-Control-Request-Method该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法。 Access-Control-Request-Headers该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段。 响应的相关字段Access-Control-Allow-Origin该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 Access-Control-Allow-Methods该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了配合Access-Control-Max-Age来避免多次”预检”请求。 Access-Control-Allow-Headers如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在”预检”中请求的字段。 Access-Control-Allow-Credentials该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 这个设置是容易被忽视的，同时也需要前端配合的。一个很容易想到的场景就是Session会话，Session会话往往是以secure的cookie的形式存在，当你的网站有多个子域名，而这些子域名都共享一个会话的时候，你的AJAX的CORS请求就需要带上Cookie。如果前端用的是Jquery，可以参考：https://www.html5rocks.com/en/tutorials/cors/#toc-cors-from-jquery 当开启Credentials的时候，为了安全考虑，浏览器要求Access-Control-Allow-Origin 必须制定值不能用*，否则会得到如下的错误 12345var xhr = new XMLHttpRequest();xhr.open(&apos;GET&apos;, &apos;http://corssession.jiu-shu.com/viewhistories&apos;); xhr.setRequestHeader(&apos;Content-Type&apos;, &apos;application/json&apos;);xhr.withCredentials = true;xhr.send(); Access-Control-Max-Age该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。 Access-Control-Expose-Headers该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。 解决CORS问题的两个步骤 确定服务端响应字段是否正确 如果服务端响应字段正确，确定客户端是否正确发送了请求，需要的header是否都带上了，需要的cookie是否带上了 最佳实践介绍了这么多，是时候来点干货 了。。。 好的CORS需求如下 只允许制定的域访问 (CORS请求中的Origin如果通过，就原样设置回Access-Control-Allow-Origin) CORS请求需要带上Cookie 减少不必要的预检请求 (Access-Control-Max-Age 需要用) Nodejs Express Web的代码1234567891011const cors = require(&apos;cors&apos;);...const corsOptioin = &#123; &quot;origin&quot;: /\\.jiu-shu\\.com$/, // jiu-shu.com 的所有子域名 &quot;methods&quot;: &quot;GET,HEAD,PUT,PATCH,POST,DELETE&quot;, &quot;optionsSuccessStatus&quot;: 204, &quot;allowedHeaders&quot;:&quot;X-Csrf-Token, X-Requested-With&quot;, // 给出你允许的所有的Header &quot;credentials&quot;:true, // 服务端可以让你带上Cookie，如果没带上就去检查你的前端代码 &quot;maxAge&quot;:3600 // 一个小时内预检一次就OK啦&#125;;app.use(cors(corsOptioin)); Java Spring Web的代码 非Spring 的也同这个相似。 1234567891011121314151617181920212223242526272829303132333435363738394041424344 import java.io.IOException;import java.util.regex.Pattern;import javax.servlet.FilterChain;import javax.servlet.ServletException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;import org.springframework.web.filter.OncePerRequestFilter; @Componentpublic class CorsFilter extends OncePerRequestFilter &#123; @Value(\"$&#123;cors.origins.pattern&#125;\") private String originPattern; // (.+\\\\.)*lichao\\\\.com @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; Pattern hostAllowedPattern = Pattern.compile(originPattern, Pattern.CASE_INSENSITIVE); String origin = request.getHeader(\"Origin\"); if(origin!=null) &#123; if (hostAllowedPattern.matcher(origin).matches()) &#123; response.addHeader(\"Access-Control-Allow-Origin\", origin);// (CORS请求中的Origin如果通过，就原样设置回Access-Control-Allow-Origin) response.addHeader(\"Access-Control-Allow-Methods\",\"GET, OPTIONS, HEAD, PUT, POST, DELETE\"); response.setHeader(\"Access-Control-Allow-Credentials\", \"true\"); response.setHeader(\"Access-Control-Max-Age\", \"3600\"); if (request.getMethod().equals(\"OPTIONS\")) &#123; // response.addHeader(\"Access-Control-Allow-Headers\", request.getHeader(\"Access-Control-Request-Headers\")); response.addHeader(\"Access-Control-Allow-Headers\", \"locale, X-Csrf-Token, X-Requested-With\"); // List All response.setStatus(HttpServletResponse.SC_ACCEPTED); return; &#125; &#125; else &#123; // Throw 403 status OR send default allow response.addHeader(\"Access-Control-Allow-Origin\", \"https://www.jiu-shu.com\"); &#125; &#125; filterChain.doFilter(request, response); &#125; &#125; 参考文章: https://en.wikipedia.org/wiki/Same-origin_policy https://en.wikipedia.org/wiki/Cross-origin_resource_sharing http://www.ruanyifeng.com/blog/2016/04/cors.html http://www.ruanyifeng.com/blog/2016/04/same-origin-policy.html https://blog.csdn.net/guodengh/article/details/73187908?locationNum=7&amp;fps=1","categories":[],"tags":[]},{"title":"AWS 亚马逊云解决方案 - 动态压缩图片","slug":"Web-Applications-Technologies/aws-resize-on-fly","date":"2018-12-21T01:49:26.732Z","updated":"2018-12-21T02:47:14.900Z","comments":true,"path":"Web-Applications-Technologies/aws-resize-on-fly/","link":"","permalink":"http://it.jiu-shu.com/Web-Applications-Technologies/aws-resize-on-fly/","excerpt":"","text":"动态根据请求的尺寸生成图片方案 流程如下 用户向S3的桶（静态网站）发起resize的资源请求，桶设置了对应rule将不存在对应尺寸的资源重定向至OKCHEM-S3 (nodejs APP) 由于对应的资源不存在，重定向至OKCHEM-S3 浏览器向OKCHEM-S3发起请求 OKCHEM-S3 根据请求将图片进行resize， 然后上传至对应的桶 OKCHEM-S3 在完成上传后，永久重定向（301）到S3的URL。 （这个时候S3已经有了对应的资源） 下次再次访问同样的资源，S3直接返回 参考： https://aws.amazon.com/cn/blogs/compute/resize-images-on-the-fly-with-amazon-s3-aws-lambda-and-amazon-api-gateway/ 文章中缺失了关于API Gateway 部分的详细步骤。 测试图片http://YOUR_BUCKET_WEBSITE_HOSTNAME_HERE/300×300/blue_marble.jpg 注意，S3 host static website的时候只支持http不支持https。 https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteEndpoints.html， 因此如果网站是https的，那么就需要采取CDN策略。 关键代码：12345678910111213141516171819202122232425262728293031323334353637383940var express = require('express');var router = express.Router();const config = require('../config')const AWS = require('aws-sdk');AWS.config.update(config.aws)const S3 = new AWS.S3(&#123; signatureVersion: 'v4',&#125;);const Sharp = require('sharp');/* Resize And upload to S3 */router.get('/:BUCKET/resize', function(req, res, next) &#123; const BUCKET = req.params.BUCKET; const URL = config.s3Hosts[BUCKET]; const key = req.query.key; const match = key.match(/((\\d+)x(\\d+))\\/(.*)/); const dimensions = match[1]; const width = parseInt(match[2], 10); const height = parseInt(match[3], 10); const originalKey = match[4]; S3.getObject(&#123;Bucket: BUCKET, Key: originalKey&#125;).promise() .then(data =&gt; Sharp(data.Body) .resize(width, height) .toFormat('png') .toBuffer() ) .then(buffer =&gt; S3.putObject(&#123; Body: buffer, Bucket: BUCKET, ContentType: 'image/png', Key: key, &#125;).promise() ) .then(() =&gt; &#123; res.redirect(301, `$&#123;URL&#125;/$&#123;key&#125;`) &#125;) .catch(err =&gt; callback(err))&#125;)module.exports = router; AWS Congito - User Identity and Access Management应用程序的域将为 https://&lt;domain_prefix&gt;.auth..amazoncognito.com。您的应用程序的完整 URL 类似于此示例：https://example.auth.us-east-1.amazoncognito.com/login?redirect_uri=https://www.google.com&amp;response_type=code&amp;client_id=&lt;client_id_value&gt; 参考：https://docs.aws.amazon.com/zh_cn/cognito/latest/developerguide/cognito-user-pools-assign-domain.html 这里如果要修改域名, 比如把https://example.auth.us-east-1.amazoncognito.com 改成 https://auth.example.com, 就必须使用 类似 Domain masking 这种手段， 好在Godaddy 这个域名提供商有个更简洁的方案：参考视频: Godaddy Forwarding and Masking A Domain Name Tutorial AWS 资源文档集合AWS Serverless Authentication AWS Cognito Developer Document AWS Cognito Developer Guide Set Cache Control for Entire S3 Bucket Website Endpoints","categories":[],"tags":[]},{"title":"Tricky Part Of Spring Controller","slug":"Spring-Boot-And-Spring-Cloud/spring-tricky-controller","date":"2018-12-21T01:49:26.633Z","updated":"2018-12-21T02:47:14.899Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/spring-tricky-controller/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/spring-tricky-controller/","excerpt":"","text":"记录Spring应用中Controller容易出问题的地方 RequestMapping 位置 非简单的path，比如： robots.txt， test.html 注解在class层，无法正常工作。","categories":[],"tags":[]},{"title":"Spring 路径匹配规则","slug":"Spring-Boot-And-Spring-Cloud/spring-mappng-rules","date":"2018-12-21T01:49:26.615Z","updated":"2018-12-21T02:20:34.009Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/spring-mappng-rules/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/spring-mappng-rules/","excerpt":"","text":"https://www.tianmaying.com/tutorial/spring-mvc-request-mapping","categories":[],"tags":[]},{"title":"Spring JPA Data Auditing","slug":"Spring-Boot-And-Spring-Cloud/Spring-JPA-Auditing","date":"2018-12-21T01:49:26.610Z","updated":"2018-03-05T01:03:32.268Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-JPA-Auditing/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-JPA-Auditing/","excerpt":"","text":"阐述如何使用Spring的JpaAuditing来方便的给auditing相关的字段赋值官方文档baeldung 示例 注意：来自官方文档： If you have multiple implementations registered in the ApplicationContext, you can select the one to be used by explicitly setting the auditorAwareRef attribute of @EnableJpaAuditing. 示例： 12345678910111213@EnableJpaAuditing(auditorAwareRef=&quot;auditorProvider&quot;)public class PersistenceConfig &#123; ... @Bean AuditorAware&lt;String&gt; auditorProvider() &#123; return new AuditorAwareImpl(); &#125; ... &#125;","categories":[],"tags":[]},{"title":"Spring Boot 1.4 对Unit Test有更好的支持","slug":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Unit-Test","date":"2018-12-21T01:49:26.591Z","updated":"2018-03-05T01:03:32.267Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Unit-Test/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-Boot-Unit-Test/","excerpt":"","text":"Spring Boot 1.4 对Unit Test有更好的支持。以下代码主要覆盖： mock authentication 来测试带权限的接口 使用jsonPath来做unit test 的 expectation 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158import static org.hamcrest.Matchers.*;import static org.springframework.security.test.web.servlet.request.SecurityMockMvcRequestPostProcessors.csrf;import static org.springframework.security.test.web.servlet.request.SecurityMockMvcRequestPostProcessors.user;import static org.springframework.security.test.web.servlet.setup.SecurityMockMvcConfigurers.springSecurity;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.*;import java.util.ArrayList;import java.util.HashSet;import java.util.List;import java.util.Set;import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.http.MediaType;import org.springframework.test.context.ActiveProfiles;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.setup.MockMvcBuilders;import org.springframework.transaction.annotation.Transactional;import org.springframework.web.context.WebApplicationContext;import com.hanover.security.entity.Group;import com.hanover.security.entity.Permission;import com.hanover.security.entity.Role;import com.hanover.security.form.InListPojo;import com.hanover.security.service.PermissionService;import com.hanover.security.service.RoleService;import com.hanover.utils.JsonUtils;/** * add group test * @author Joe * */@RunWith(SpringRunner.class)@SpringBootTest@ActiveProfiles(&quot;test&quot;) public class GroupRolesIntegrationTest extends AbstractTest&#123; @Autowired private WebApplicationContext context; private MockMvc mvc; @Autowired private PermissionService permissionService; @Autowired private RoleService roleService; private Role productOperatorRole; private Role productAdminRole; @Before public void setup() &#123; mvc = MockMvcBuilders .webAppContextSetup(context) .apply(springSecurity()) .build(); prepareBaseData(); &#125; /** * Step1: createGroup * Step2: select roles for group * Step3: update group roles * @throws Exception */ @Test @Transactional public void integrationTestCase() throws Exception&#123; Group group = createGroup(&quot;productsuper&quot;,&quot;Product Super group&quot;,&quot;Group for Product Super manager.&quot;); InListPojo&lt;String&gt; rolesList = prepareInPojoForUpdate(); updateGroupRoles(group.getId(), rolesList); getGroupRoles(group.getId()); &#125; /** * Prepare a list of role codes. * @return */ private InListPojo&lt;String&gt; prepareInPojoForUpdate()&#123; List&lt;String&gt; roles = new ArrayList&lt;String&gt;(); roles.add(productOperatorRole.getCode()); roles.add(productAdminRole.getCode()); InListPojo&lt;String&gt; rolesList = new InListPojo&lt;&gt;(); rolesList.setList(roles); return rolesList; &#125; /** * Prepare accessObject, operation, permission roles. * Create 4 roles */ private void prepareBaseData()&#123; Permission productR = permissionService.createPermission(&quot;PRODUCT&quot;, &quot;Product&quot;, &quot;R&quot;, &quot;Read&quot;,&quot;Product Read&quot;); Permission productU = permissionService.createPermission(&quot;PRODUCT&quot;, &quot;Product&quot;, &quot;U&quot;, &quot;Update&quot;,&quot;Product Update&quot;); Permission productApprove = permissionService.createPermission(&quot;PRODUCT&quot;, &quot;Product&quot;, &quot;P&quot;, &quot;Approve&quot;,&quot;Product Update&quot;); Permission srmR = permissionService.createPermission(&quot;supplier&quot;, &quot;supplier&quot;, &quot;R&quot;, &quot;Read&quot;,&quot;Supplier Read&quot;); Permission srmU = permissionService.createPermission(&quot;supplier&quot;, &quot;supplier&quot;, &quot;U&quot;, &quot;Update&quot;,&quot;Supplier Update&quot;); Permission srmApprove = permissionService.createPermission(&quot;supplier&quot;, &quot;supplier&quot;, &quot;P&quot;, &quot;Approve&quot;,&quot;Supplier Update&quot;); Set&lt;String&gt; permissionsProductOperator = new HashSet&lt;String&gt;(); permissionsProductOperator.add(productU.getCode()); permissionsProductOperator.add(productR.getCode()); Set&lt;String&gt; permissionsProductAdmin = new HashSet&lt;String&gt;(); permissionsProductAdmin.addAll(permissionsProductOperator); permissionsProductAdmin.add(productApprove.getCode()); Set&lt;String&gt; permissionSupplierOperator = new HashSet&lt;String&gt;(); permissionSupplierOperator.add(srmR.getCode()); permissionSupplierOperator.add(srmU.getCode()); Set&lt;String&gt; permissionSupplierApprover = new HashSet&lt;String&gt;(); permissionSupplierApprover.add(srmApprove.getCode()); permissionSupplierApprover.addAll(permissionSupplierApprover); productOperatorRole = roleService.addOrUpdateRole(&quot;plm_operator&quot;, &quot;PLM Operator&quot;, permissionsProductOperator); productAdminRole = roleService.addOrUpdateRole(&quot;plm_approver&quot;, &quot;PLM Approver&quot;, permissionsProductAdmin); roleService.addOrUpdateRole(&quot;srm_operator&quot;, &quot;SRM Operator&quot;, permissionSupplierOperator); roleService.addOrUpdateRole(&quot;srm_approver&quot;, &quot;SRM Approver&quot;, permissionSupplierApprover); &#125; /** * Update groupRoles * @param groupId * @throws Exception */ private void updateGroupRoles(Long groupId,InListPojo&lt;String&gt; rolesList) throws Exception&#123; this.mvc.perform(put(&quot;/groups/&quot;+groupId+&quot;/roles&quot;) .content(JsonUtils.convertModelToJson(rolesList)) .contentType(MediaType.APPLICATION_JSON_UTF8) .with(csrf()).with(user(createUserDetail(&quot;joe&quot;, &quot;asdff&quot;, &quot;joe.lea@gmail.com&quot;, &quot;11111112222333&quot;, &quot;PLM,SRM&quot;))).accept(MediaType.APPLICATION_JSON_UTF8)) .andExpect(content().json(&quot;&#123;\\&quot;success\\&quot;:true&#125;&quot;)); &#125; /** * Get groupRoles * @param groupId * @throws Exception */ private void getGroupRoles(Long groupId) throws Exception&#123; this.mvc.perform(get(&quot;/groups/&quot;+groupId+&quot;/roles&quot;) .contentType(MediaType.APPLICATION_JSON_UTF8) .with(csrf()).with(user(createUserDetail(&quot;joe&quot;, &quot;asdff&quot;, &quot;joe.lea@gmail.com&quot;, &quot;11111112222333&quot;, &quot;PLM,SRM&quot;))).accept(MediaType.APPLICATION_JSON_UTF8)) .andExpect(jsonPath(&quot;$.success&quot;,is(true))) .andExpect(jsonPath(&quot;$.data.groupRoles&quot;,arrayContaining(&quot;plm_operator&quot;))) .andExpect(jsonPath(&quot;$.data.groupRoles.length()&quot;,is(2))) .andExpect(jsonPath(&quot;$.data.allRoles.length()&quot;,is(4) )); &#125;&#125;","categories":[],"tags":[]},{"title":"Spring Security  从单体到微服务的演进 - 单体web","slug":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-Security","date":"2018-12-21T01:49:26.588Z","updated":"2018-03-05T01:03:32.266Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-Security/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-Security/","excerpt":"","text":"参考：Spring Security and Angular JS代码：codes on github 术语CSRF - Cross-Site Request Forgery (跨站请求伪造)CORS - Cross Origin Resource Sharing (跨域资源共享） 单体web app创建spring web工程。 采用Spring CLI，（其他多种方式请自便）1spring init --dependencies web,security ui OOTB security123456789101112131415161718192021package com.example;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@SpringBootApplication@RestControllerpublic class UIApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UIApplication.class, args); &#125; @RequestMapping(&quot;/&quot;) public ResponseEntity&lt;?&gt; home() &#123; return ResponseEntity.ok(&quot;hello&quot;); &#125;&#125; OOTB的情况，pom引入了spring security的依赖，不做任何配置。所有的请求都需要登录。 12E:\\&gt;curl &quot;http://localhost:8080&quot;&#123;&quot;timestamp&quot;:1478501120211,&quot;status&quot;:401,&quot;error&quot;:&quot;Unauthorized&quot;,&quot;message&quot;:&quot;Full authentication is required to access this resource&quot;,&quot;path&quot;:&quot;/&quot;&#125; 从浏览器打开会提示输入用户名和密码，用户名是user，密码可以从console中看到： 1Using default security password: 60fdacf5-347d-4f6f-ac7c-bc0a9725bc55 Look under the hood: 没有任何个性化的配置的时候AuthenticationManagerConfiguration 会采用默认的配置。默认的security配置参考:SecurityProperties类。prefix = “security”。 可通过一下配置修改OOTB的用户名和密码。 12security.user.name=joesecurity.user.password=123456 自定义security参考注解： @EnableWebSecurity 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.example.security;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.builders.WebSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;/** * @author Joe * */@EnableWebSecuritypublic class ExtWebSecurityConfigurerAdapter extends WebSecurityConfigurerAdapter &#123; @Override public void configure(WebSecurity web) throws Exception &#123; web.ignoring() // Spring Security should completely ignore URLs starting with /resources/ .antMatchers(\"/resources/**\"); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() .antMatchers(\"/public/**\").permitAll() .antMatchers(\"/admin/**\").hasRole(\"ADMIN\") .and() // Possibly more configuration ... .formLogin() // enable form based log in // set permitAll for all URLs associated with Form Login .permitAll(); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; // enable in memory based authentication with a user named \"user\" and \"admin\" auth.inMemoryAuthentication().withUser(\"user\").password(\"password\").roles(\"USER\") .and().withUser(\"admin\").password(\"password\").roles(\"USER\", \"ADMIN\"); &#125; // Possibly more overridden methods ... &#125; 添加对应URL的接口 1234567891011121314151617181920212223242526package com.example;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@SpringBootApplication@RestControllerpublic class UIApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UIApplication.class, args); &#125; @GetMapping(&quot;/public/hello&quot;) public ResponseEntity&lt;?&gt; home() &#123; return ResponseEntity.ok(&quot;Hello Every one!&quot;); &#125; @GetMapping(&quot;/admin/hello&quot;) public ResponseEntity&lt;?&gt; admin() &#123; return ResponseEntity.ok(&quot;Hello Admin!&quot;); &#125;&#125; /public/hello 可以随意访问，/admin/hello 需要登录用户有admin的role。用user登录会抛出403的错误。 配置中加了.formLogin().permitAll() 未登录用户会直接重定向至OOTB的登录页面。去掉.formLogin().permitAll() 后直接访问/admin/hello会直接抛出403， 而非401 （这点笔者暂时未能理解，未登录应该抛出401 才对，如果系统中加了授权需要区分这两个状态）(什么场景不需要formLogin？用户如何登陆？满足这个场景的web app往往不是单体，可能是某个微服务，提供restful services)。这里要明白一点：一旦定制，OOTB的行为就会受影响，尽管看似你没有改.比如：不加.formLogin().permitAll() 就会导致没有登录提示框出现，访问需要授权的服务会直接抛出403 关于如何配置login的page等参考：Java Configuration and Form Login Spring Boot CORS 解决Trick：官方示例官方示例中只提到了 WebMvcConfigurerAdapter， 然而大部分程序都有WebSecurityConfigurerAdapter 相关的配置 12345678910@Configuration@EnableWebSecuritypublic class HrWebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable(); http.cors().and().authorizeRequests().antMatchers(&quot;/hr/**&quot;).authenticated(); &#125;&#125; 上面代码的：http.cors() 非常重要, 这里java doc拷贝出来 Adds a CorsFilter to be used. If a bean by the name of corsFilter is provided, that CorsFilter is used. Else if corsConfigurationSource is defined, then that CorsConfiguration is used. Otherwise, if Spring MVC is on the classpath a HandlerMappingIntrospector is used. 从注解上可以看出来，我们需要一个corsFilter： 1234567891011121314151617@Bean public CorsFilter corsFilter() &#123; final UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); final CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); config.addAllowedOrigin(&quot;*&quot;); config.addAllowedHeader(&quot;*&quot;); config.addAllowedMethod(&quot;OPTIONS&quot;); config.addAllowedMethod(&quot;HEAD&quot;); config.addAllowedMethod(&quot;GET&quot;); config.addAllowedMethod(&quot;PUT&quot;); config.addAllowedMethod(&quot;POST&quot;); config.addAllowedMethod(&quot;DELETE&quot;); config.addAllowedMethod(&quot;PATCH&quot;); source.registerCorsConfiguration(&quot;/**&quot;, config); return new CorsFilter(source); &#125; 如果用到了zuul， 上面的配置也不能生效。stackoverflow 这个issue(zuul 用在apigateway的时候，其他微服务不需要有CORS)Ticket on GitHub","categories":[],"tags":[]},{"title":"Spring Boot 开发web 应用 - 04 静态资源","slug":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-4-Static","date":"2018-12-21T01:49:26.586Z","updated":"2018-12-21T02:47:14.892Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-4-Static/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-4-Static/","excerpt":"","text":"Spring Boot 对静态资源文件的的处理方式。在Spring Boot: 开发web 应用 - 01 创建项目 中引入的H5 的模板，对应的资源文件（css,js,images 等）放入/src/main/resources/static 下面即可直接引用到&lt;link rel=&quot;stylesheet&quot; href=&quot;/css/animate.min.css&quot;&gt;。接下来看看Spring Boot 是怎么服务静态资源的。 参考文章 Common application properties Developing Web Application Resourcing Versioning With Spring MVC 代码https://github.com/choelea/spring-boot-trail-static-content/releases/tag/version-agnostic-URLs 版本 spring boot 1.5.9 默认行为OOTB 的情况下，不用任何代码Spring Boot 的Web 程序已经满足了常规静态资源的需求。默认情况下，静态资源的response header中并没有cache 相关的设置。（expires / cache-control header.） 这种情况下，各个浏览器的默认行为有可能不一样。 （简单测试：chrome貌似会无限期缓存，firefox缓存了一个小时) 设定缓存时间在application.properties 中添加如下配置：（单位：秒, 360024365 ） 1spring.resources.cache-period=31536000 application.properties/application.yml 常见的配置项可以参考：Common application properties 打开Chrome强制刷新页面，打开开发者工具，查看静态资源的response header可以看到如下的内容： 1Cache-Control:max-age=31536000 打开firefox的firebug也可以检查到过期时间为一年后。 设置访问路径（static resource path pattern）默认情况pattern是/** 即：根路径。请求类似http://localhost:8080/test/bootstrap.min.css 和 http://localhost:8080/css/bootstrap.min.css 只要classpath 下面对应的资源文件(/static，/public, /resources, /META-INF)下面有对应目录及文件既可以访问。 By default Spring Boot will serve static content from a directory called /static (or /public or /resources or /META-INF/resources) in the classpath or from the root of the ServletContext.可以通过spring.resources.static-locations来改变资源文件的实体文件路径; 但是实际中基本用不上，就不赘述了。 可以通过以下的配置来设定pattern，达到给所有静态资源一个公共的路径前缀。 1spring.mvc.static-path-pattern=/static/** 那么不管是js css还是图片的引入路径，都需要以/static开头。http://localhost:8080/static/css/bootstrap.min.css (注意：这里的项目我们没有设置server.context-path，所有端口后就直接跟URI) 设置版本为了提高页面的性能及用户体验，静态资源的缓存时间需要尽可能大；但是同时面临着迭代和频繁的发布。 如何让用户能得到最新的修改的内容呢？ 发布后URL 必须变，怎么变方便又效率高？ 不可知版本号每次内容重启后，计算文件内容生成md5值，作为新的版本号后缀。(具体的strategy类：org.springframework.web.servlet.resource.ContentVersionStrategy） 12spring.resources.chain.strategy.content.enabled=truespring.resources.chain.strategy.content.paths=/** 参考Spring Boot的官方指导文档 Static Content仅仅是上面的配置还不够，如何让这些静态资源加上版本的后缀？必须通过ResourceUrlProvider 来生成提供修改对应的URL；另外需要ResourceUrlEncodingFilter来解析请求。不同的view engine支持程度不一样，做法也不一样。针对freemarker来说, 添加全局的bean到model中。 1234567891011@ControllerAdvicepublic class ResourceUrlAdvice &#123; @Inject ResourceUrlProvider resourceUrlProvider; @ModelAttribute(&quot;urls&quot;) public ResourceUrlProvider urls() &#123; return this.resourceUrlProvider; &#125;&#125; 然后在模板中引入：&lt;link rel=&quot;stylesheet&quot; href=&quot;${urls.getForLookupPath(&#39;/static/css/animate.min.css&#39;)}&quot;&gt; 生成的HTML内容变成： &lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css/animate.min-e8c93399a158706b3ae3a9396a9c684e.css&quot;&gt; 在文件内容未修改的情况下，即使服务器重启URL也不会变。 可以参考文章： Resourcing Versioning With Spring MVC","categories":[],"tags":[]},{"title":"Spring Boot 开发web 应用 - 04 静态资源 深入探索","slug":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-4-Static-Look-Under-The-Hood","date":"2018-12-21T01:49:26.583Z","updated":"2018-12-21T02:47:14.888Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-4-Static-Look-Under-The-Hood/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-4-Static-Look-Under-The-Hood/","excerpt":"","text":"解读原代码进一步了解Spring Boot对静态资源文件的处理。 参考文章Developing Web ApplicationUsing Spring Boot Auto-configuration Spring Boot 自动配置Spring Boot自动配置尝试根据您添加的jar依赖关系自动配置您的Spring应用程序。大部分情况下，Spring Boot的 AutoConfiguration类会利用@ConditionalOnClass 或者其他的@ConditionalOn** 注解来有选择地配置你的应用。 比如： 在目前我们都还未加入security相关的依赖；SpringBootWebSecurityConfiguration 类实际已经引入， 但是@ConditionalOnClass({ EnableWebSecurity.class, AuthenticationEntryPoint.class }) 决定了security的依赖被引入之前SpringBootWebSecurityConfiguration 不会有任何作用。 WebMvcAutoConfiguration 类 此类作为webmvc的配置的集合点，下面的部分子类分别实现/扩展了spring-webmvc模块的类帮助SB（Spring Boot）Web 应用快速配置。 WebMvcConfigurerAdapter 集合了大部分webmvc的配置；后面涉及到的时候我们会尝试定制。 EnableWebMvcConfiguration @EnableWebMvc注解的替代 上一节的配置如何生效的相关properties类： WebMvcProperties ResourceProperties spring.mvc.static-path-pattern=/static/** 及spring.resources.cache-period=31536000 参考如下:1void org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration.WebMvcAutoConfigurationAdapter.addResourceHandlers(ResourceHandlerRegistry registry) spring.resources.chain.* 的配置参考如下:1void org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration.ResourceChainResourceHandlerRegistrationCustomizer.configureResourceChain(Chain properties, ResourceChainRegistration chain)","categories":[],"tags":[]},{"title":"Spring Boot 开发web 应用 - 03 Spring Framework 回顾","slug":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-3-Spring-Framework","date":"2018-12-21T01:49:26.580Z","updated":"2018-12-21T02:47:14.884Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-3-Spring-Framework/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-3-Spring-Framework/","excerpt":"","text":"回顾Spring FrameworkOverview of Spring Framework 手绘了完整版的依赖关系。（发现问题还望大家指出） 简化版的依赖关系。 结合Overview of Spring Framework 来更好的理解 Spring Framework。 关于依赖的理解Examplemodule A 中有类引用了Module B 中的class。 A依赖B吗（A -&gt; B） ?大部分的情况是这个样子的。。。打开两节的项目，我们可以看到spring-boot-starter-web 帮助我们引入了如下的module： spring-boot-starter-web -&gt; spring-boot-starter -&gt; spring-boot-autoconfigure -&gt; spring-boot 可以看出spring-boot-autoconfigure只依赖于spring-boot 模块。（spring-boot 仅依赖于spring-core和spring-context）打开spring-boot-autoconfigure-1.5.4.RELEASE-sources.jar 文件查看其中的代码： 比如：WebMvcAutoConfiguration 可以发现这个类引入了很多的spring-web 及其他module的class。 （从上面的推理来看spring-boot-autoconfigure并不依赖于spring-web） 验证新建一个Spring Boot的项目， 只选择JPA 一个Dependency， 通过pom.xml 的视图查看Resolved Dependencies 可以看到spring-boot-autoconfigure被引入，而spring-web没有被引入。 Why类WebMvcAutoConfiguration 中的如下注解决定了只有web application，这个类才会被load进来。123@ConditionalOnWebApplication@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class &#125;) Conditional 相关注解不在这一篇幅深入探究。","categories":[],"tags":[]},{"title":"Spring Boot 开发web 应用 - 02 探究竟","slug":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-2-Look-Under-The-Hood","date":"2018-12-21T01:49:26.575Z","updated":"2018-12-21T02:47:14.913Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-2-Look-Under-The-Hood/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-2-Look-Under-The-Hood/","excerpt":"","text":"进一步去了解Spring Boot的实现原理 Look Under The Hood引入了哪些jar 文件通过pom.xml 可以看到： 123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 暂时我们可以忽略掉spring-boot-starter-freemarker，这个只是引入了对freemarker的支持。 打开Dependency Hierarchy可以看看spring-boot-starter-web帮我们引入了哪些jar。 可以从上面看到引入了嵌入式的tomcat；在IDE里面去查询对应的jar文件，spring-boot-starter-* 的jar文件并没有任何的java代码，只是将相关依赖集合起来提供一站式服务。 Starter POMs are a set of convenient dependency descriptors that you can include in your application. You get a one-stop-shop for all the Spring and related technology that you need, without having to hunt through sample code and copy paste loads of dependency descriptors. For example, if you want to get started using Spring and JPA for database access, just include the spring-boot-starter-data-jpa dependency in your project, and you are good to go. Spring Boot Starter POM. spring-boot-autoconfigureSpring-Boot的很多便利之处就在于，你只需要引入相应的依赖， 无需过多的配置，就可以按照约定研发业务功能。 比如， 你无需配置页面文件存放位置，只需要按照约定即可。 这些便利都归功于spring-boot-autoconfigure这个包。 大部分的默认配置都在这里帮忙配置好了， 此外，借助于Java 条件型的annotation 比如： @ConditionalOnClass， 可以完成动态配置， Java 代码上一节中创建了项目之后，只有两个很简单的Java 类。 SpringbootStaticContentApplication123456789package com.choelea.springboot.springbootstaticcontent;.............@SpringBootApplicationpublic class SpringbootStaticContentApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootStaticContentApplication.class, args); &#125;&#125; @SpringBootApplication 只是为了方便集合了Spring Boot 常用的几个注解。（最早的Spring Boot没有这个annotation）The @SpringBootApplication annotation is equivalent to using @Configuration, @EnableAutoConfiguration and @ComponentScan with their default attributes. Refer to :Using the @SpringBootApplication annotation @SpringBootApplication 的入口住类最佳实践是放在最顶级的package中；这样默认所有子package中的class都会被Spring扫到。这点可以查看@ComponentScan 的javadoc “If specific packages are not defined, scanning will occur from the package of the class that declares this annotation. ” HomePageController此类只有放在@SpringBootApplication 所在类的下级包内才会被扫描生效。123456789package com.choelea.springboot.springbootstaticcontent.controller;.................@Controllerpublic class HomePageController &#123; @RequestMapping(&quot;/&quot;) public String home()&#123; return &quot;index&quot;; &#125;&#125;","categories":[],"tags":[]},{"title":"Spring Boot开发 web 应用 - 01 创建项目","slug":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-1-Initiate-Project","date":"2018-12-21T01:49:26.567Z","updated":"2018-12-21T02:47:14.884Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-1-Initiate-Project/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-Boot-Tutorial-1-Initiate-Project/","excerpt":"","text":"Spring Boot非常适合Web应用程序开发。使用spring-boot-starter-web模块快速启动和运行。 其中使用嵌入式Tomcat，Jetty或Undertow轻松创建自包含的HTTP服务器 Spring Boot支持多种方式来创建一个项目： 使用curl命令 Using curl 使用Spring Boot CLI 命令行工具 Using CLI https://spring.io/ 在线生成项目 使用Spring的集成开发工具 创建Spring Boot项目：这里简单在线生成一个项目; 直接访问https://start.spring.io/，填写Group和Artifact，添加Web和 Freemarker两个依赖项。 Spring Boot 支持的可以替换JSP的，view engine包括： Thymeleaf, Groovy Markup Templates, Freemarker, Velocity. (As of Spring Framework 4.3, Velocity support has been deprecated due to six years without active maintenance of the Apache Velocity project. ) 除了Velocity 以外，其他根据个人爱好自助选择。 添加HomeController12345678@Controllerpublic class HomePageController &#123; @RequestMapping(&quot;/&quot;) public String home()&#123; return &quot;index&quot;; &#125;&#125; 添加前端页面的模板采用开源bootstrap的H5 模板：awesome template默认页面文件需要添加至/src/main/resources/templates 下面；静态资源文件的位置在/src/main/resources/static (或者/src/main/resources/public)下面。目录结构如下： 运行测试运行SpringBootApplication主程序；访问http://localhost:8080验证。 截止目前，没有任何定制的情况下，我们可以看到Awesome 的模板页面。 Spring Boot App 运行方式有以下方式运行，具体请参考：Spring Boot应用的后台运行配置 运行Spring Boot的应用主类 使用Maven的Spring Boot插件mvn spring-boot:run来运行 打成jar包后，使用java -jar运行 (可以使用-Dserver.port 来在运行时修改端口; 比如：java -jar -Dserver.port=9999 boot.jar)github repospring-boot-trail-static-content tags/ootb","categories":[],"tags":[]},{"title":"使用Spring Boot构建多个moudle的web应用","slug":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Multiple-Modules","date":"2018-12-21T01:49:26.564Z","updated":"2018-12-21T02:47:14.881Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Multiple-Modules/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-Boot-Multiple-Modules/","excerpt":"","text":"A example to use demostrate how to create multiple project using spring boot. Go into Root Folder.Run mvn installjava -jar swwmp-app/target/swwmp-app-0.0.1-SNAPSHOT.jar 代码： https://github.com/choelea/swwmp Found an article on spring:Create Multi Module Project Using Spring Boot","categories":[],"tags":[]},{"title":"Spring Boot Actuator","slug":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Actuator","date":"2018-12-21T01:49:26.557Z","updated":"2018-12-21T02:21:29.006Z","comments":true,"path":"Spring-Boot-And-Spring-Cloud/Spring-Boot-Actuator/","link":"","permalink":"http://it.jiu-shu.com/Spring-Boot-And-Spring-Cloud/Spring-Boot-Actuator/","excerpt":"","text":"监控和管理 - Spring Boot ActuatorSpring Boot Actuator是spring boot的一个子集，提供的一些监控用的API。官方文档使用只需要添加一下依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 提供了以下接口具体接口请参考官方文档。 Spring Boot 1.5 后，针对添加了权限控制， 如果需要放开权限，添加配置：management.security.enabled=false management.context-path=/actuator 默认是true。 参考文档：http://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html. 参考官方文档获取最新的endpoints. 示例配置如下：12345# Spring Boot 1.5 后，针对添加了权限控制， 如果需要放开权限，添加配置：management.security.enabled=false 默认是true。 management.security.enabled=false management.context-path=/actuator# to expose everything over HTTP management.endpoints.web.exposure.include=* Actuator通过Endpionts来允许你和Spring Boot的app进行交互来监控和管理。 访问URI示例：/actuator/health Mapping URI 描述 敏感 autoconfig 显示一个auto-configuration的报告，该报告展示所有auto-configuration候选者及它们被应用或未被应用的原因 true beans 显示一个应用中所有Spring Beans的完整列表 true configprops 显示一个所有@ConfigurationProperties的整理列表 true dump 执行一个线程转储 true env 暴露来自Spring ConfigurableEnvironment的属性 true health 展示应用的健康信息（当使用一个未认证连接访问时显示一个简单的’status’，使用认证连接访问则显示全部信息详情） false info 显示任意的应用信息 false metrics 展示当前应用的’指标’信息 true mappings 显示一个所有@RequestMapping路径的整理列表 true shutdown 允许应用以优雅的方式关闭（默认情况下不启用） true trace 显示trace信息（默认为最新的一些HTTP请求） true If you are using Spring MVC, the following additional endpoints can also be used:请参考官方文档， 不在这里赘述","categories":[],"tags":[]},{"title":"使用Raneto结合Github来搭建简易个人的BLog","slug":"Nodejs-Technologies/raneto-create-markdown-site","date":"2018-12-21T01:49:26.524Z","updated":"2018-03-05T01:03:32.255Z","comments":true,"path":"Nodejs-Technologies/raneto-create-markdown-site/","link":"","permalink":"http://it.jiu-shu.com/Nodejs-Technologies/raneto-create-markdown-site/","excerpt":"","text":"使用Raneto结合Github来搭建简易个人的BLog, 将github 厂库的markdown文档展示在blog网站上。 笔者blog： http://tech.jiu-shu.com RanetoRaneo 是构建在nodejs express基础之上的web系统，不需要依赖任何数据库的的‘CMS’ Web 系统。直接将创建的Markdown文件解析展示出来。 Raneto is a free, open, simple Markdown powered Knowledgebase for Node.js. https://github.com/gilbitron/Raneto","categories":[],"tags":[]},{"title":"Centos 7 上利用pm2部署 nodejs 程序 - No Jenkins","slug":"Nodejs-Technologies/PM2-Deployment","date":"2018-12-21T01:49:26.521Z","updated":"2018-03-05T01:03:32.253Z","comments":true,"path":"Nodejs-Technologies/PM2-Deployment/","link":"","permalink":"http://it.jiu-shu.com/Nodejs-Technologies/PM2-Deployment/","excerpt":"","text":"本文探索如何利用pm2 来部署nodejs的程序到centos系统上。 参考资源 nodejs的安装 Installing Node.js via package manager npm 权限问题 Fixing npm permissions pm2 deploy PM2 deployment git 安装及版本升级 How to install GIT on CentOS Deploy and iterate faster, hello ecosystem.json版本 git version git version 2.11.1node -v v8.0.0pm2 -v 2.5.0 安装nodejs参考上面的资源链接，在目标服务器上安装nodejs， 本次尝试采用命令： 12curl --silent --location https://rpm.nodesource.com/setup_8.x | bash -yum -y install nodejs 安装pm21npm install pm2@latest -g 解决SSH用户的权限问题用root用户显然是不推荐的，然后安装nodejs和npm其他package的安装，我们可能都是通过sudo来安装的。当我们发布程序的时候，我们使用的ssh用户，这里必须解决掉npm perssmision的问题。 参考资源给出了很好的官方的指导；本文采用了第一种方式： sudo chown -R $(whoami) $(npm config get prefix)/{lib/node_modules,bin,share} 使用这边命令将owner设置为当前用户。 网上的很多文章都忽略了这个问题，这里可以暂时跳过， 到后面的pm2 deploy的时候，问题爆发了再针对性的来解决。 git 安装在目标服务器上安装git；（如果通过ssh push的方式，目前机器也可以不安装git）。本次尝试采用在目标服务器上直接pull代码。git 安装参考上面的资源链接。 本文采用了第三方repo来简化安装。（并非最佳实践，使用第三方的repo需要三思而后行 , 手动安装请参考:Git Installing from source） 12sudo rpm -U http://opensource.wandisco.com/centos/7/git/x86_64/wandisco-git-release-7-2.noarch.rpm sudo yum install -y git git 版本过低可能引发无法pull到最新的代码的问题。 Ticket Reference CentOS自带的repository只有旧版本和最新版本是1.8.x版本。 示例代码库示例代码： https://github.com/choelea/image-utils-web.git branches/pm2-deploy-1 pm2 发布参考官方文档， 截止这篇文章的时间，官方文档和代码有些不一致；但是不影响其参考价值。 前提条件 发布机器（可以是你的laptop）可以ssh到目标服务器 目标服务器可以ssh到git拉去代码 github上的开源代码不需要ssh可以直接通过https的链接拉去 配置ssh用户一般的云服务器可以通过web界面的console去配置。 如果没有可以已经有用户名和密码的登录方式，可以通过下面的命令来设置ssh。(后面有示例) 12$ ssh-keygen -t rsa$ ssh-copy-id node@myserver.com 同样方式设置目标服务器 -&gt; git 服务器的ssh访问。 创建deploy的配置文件通过pm2 ecosystem 生成模板进行修改。 可以是json,js,yaml 文件；优选前两种。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647module.exports = &#123; /** * Application configuration section * http://pm2.keymetrics.io/docs/usage/application-declaration/ */ apps : [ // First application &#123; name : &apos;image-utils-web&apos;, script : &apos;server.js&apos;, // env: &#123; If we don&apos;t comment here, it will override below deploy config // PORT: 3011 // &#125;, env_production : &#123; NODE_ENV: &apos;production&apos; &#125; &#125; ], /** * Deployment section * http://pm2.keymetrics.io/docs/usage/deployment/ */ deploy : &#123; production : &#123; user : &apos;joe&apos;,// ssh 用户名 host : &apos;192.168.1.188&apos;, // 目标服务器地址 ref : &apos;origin/master&apos;, repo : &apos;https://github.com/choelea/image-utils-web.git&apos;, path : &apos;/home/joe/nodejsapp/nodejs-playaround&apos;, // 目标服务器部署地址 &apos;post-deploy&apos; : &apos;npm install &amp;&amp; pm2 reload ecosystem.config.js --env production&apos; &#125;, dev : &#123; user : &apos;osboxes&apos;, host : &apos;192.168.1.186&apos;, ref : &apos;origin/master&apos;, repo : &apos;https://github.com/choelea/image-utils-web.git&apos;, path : &apos;/home/osboxes/temp&apos;, &apos;post-deploy&apos; : &apos;npm install &amp;&amp; pm2 reload ecosystem.config.js --env dev&apos;, env : &#123; NODE_ENV: &apos;dev&apos;, PORT: 3012 &#125; &#125; &#125;&#125;; 运行命令pm2 deploy ecosystem.config.js dev 即可进行对应环境的部署。（部署前需要运行pm2 deploy ecosystem.config.js dev setup 来创建对应的文件夹。一般会有current，shared， source 三个文件夹，current是个软连接指向了source） 示例：本地虚拟机测试示例：如下是利用本地已经生成好的公私钥(id_rsa, id_rsa.pub)，将公钥上传至目标服务器192.168.1.186绑定用户osboxes。1234567891011121314$ ssh-copy-id -i id_rsa.pub osboxes@192.168.1.186/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompt ed now it is to install the new keysosboxes@192.168.1.186&apos;s password:Number of key(s) added: 1Now try logging into the machine, with: &quot;ssh &apos;osboxes@192.168.1.186&apos;&quot;and check to make sure that only the key(s) you wanted were added.Administrator@PC-20160321GFRJ MINGW64 ~/.ssh$ ssh osboxes@192.168.1.186Last login: Wed Jul 5 1 windows 系统默认没有ssh命令，如果安装了有git，可以通过git bash来运行ssh的命令。","categories":[],"tags":[]},{"title":"向NPM仓库发布自己的Package","slug":"Nodejs-Technologies/NPM-Publish-Package","date":"2018-12-21T01:49:26.518Z","updated":"2018-12-21T02:20:02.927Z","comments":true,"path":"Nodejs-Technologies/NPM-Publish-Package/","link":"","permalink":"http://it.jiu-shu.com/Nodejs-Technologies/NPM-Publish-Package/","excerpt":"","text":"阐述如何使用npm发布自己的Package 创建Nodejs 模块参考： https://docs.npmjs.com/getting-started/creating-node-modules Publish参考官方指导 简洁总结如下步骤： 创建/添加 npm 包仓库的用户到本地，如果已经有用户直接使用命令 npm login, 通过npm whoami 查看当前用户 检查package.json 内容，编写README.md， 发布 npm publish 发布前注意npm的镜像，国内很多由于网络问题会设置淘宝的镜像，发布前记得切换到https://registry.npmjs.org， 关于NPM的源可以参考文章：https://registry.npmjs.org 问题收集问题1 Incorrect username or passwordhttps://github.com/npm/npm/issues/6545 workaround删除文件.npmrc 后重试 不同系统的文件位置不同， windows系统在当前用户的目录下，比如：C:\\Users\\Administrator\\ 问题2 you must verify your email before publishing a new package也许当时注册时候没有验证邮箱， 你需要重新验证下，去npm官网发一个验证到邮箱， 然后照着做","categories":[],"tags":[]},{"title":"如何在Linux上安装Node.js","slug":"Nodejs-Technologies/nodejs-nvm-install-uninstall","date":"2018-12-21T01:49:26.502Z","updated":"2018-12-21T02:19:55.905Z","comments":true,"path":"Nodejs-Technologies/nodejs-nvm-install-uninstall/","link":"","permalink":"http://it.jiu-shu.com/Nodejs-Technologies/nodejs-nvm-install-uninstall/","excerpt":"","text":"转自： https://blog.csdn.net/wh211212/article/details/53039286 装Nodejs之前推荐优先安装nvm参考上面链接， 去https://github.com/creationix/nvm 找到最新的版本。","categories":[],"tags":[]},{"title":"Nodejs 利用passport完成本地认证 示例","slug":"Nodejs-Technologies/Nodejs-Express-Passport","date":"2018-12-21T01:49:26.499Z","updated":"2018-12-21T02:47:14.893Z","comments":true,"path":"Nodejs-Technologies/Nodejs-Express-Passport/","link":"","permalink":"http://it.jiu-shu.com/Nodejs-Technologies/Nodejs-Express-Passport/","excerpt":"","text":"本文只涉及web相关，即浏览器作为客户端。一步一步理解认证过程，同时熟悉express-session,passport, connect-flash 各自的职责。示例并没有引入mongodb, 方便更直接的理解认证过程。（In-Memory Authentication Example） 示例实现场景介绍 用户访问需要登录的页面，被重定向至登录页面 登录界面输入用户名和密码，服务端验证并返回显示错误信息, 验证成功后返回至用户先前访问的页面 如果用户直接访问的登录页面，登录成功后返回指定页面（这里指定/session-demo 页面方便演示） 资源链接 express-session passport connect-flash 代码： https://github.com/choelea/image-utils-web releases： passport-local-authentication 逐步探索探索express + session + passport 来完成用户的基础认证。 网络上大部分文章及示例都是将mongoose，express-session，passport, connect-flash等捆绑在一起，没有一步一步解释清晰各自的职责， 其实这些组件之间并没有多大的依赖关系。 express-session 登场有过web开发经验的对session都是有所了解，简单澄清一点： session 中的数据存放服务器端，浏览器端的cookie会以某种形式存放session的ID，服务器端获取到这个id可以通过这个id索引到session data。 通过npm install express-sessioin --save 添加依赖。代码中找到合适的位置引入依赖： 123const session = require(&apos;express-session&apos;);......app.use(session(&#123; secret: &apos;secretkey&apos;, resave: false, saveUninitialized: false &#125;)); // 参数的说明请参考文档，saveUninitialized 和 resave一般推荐设置为false 搞定， 可以再次访问页面，可以通过浏览器开发者工具看到名称为’connect.sid’ 的cookie会创建。创建一下的route (/session-demo)来测试： 1app.use(&apos;/session-demo&apos;, require(&apos;./routes/session-demo&apos;)); session-demo.js 主要代码如下：12345678let router = require(&apos;express&apos;).Router();router.get(&apos;/&apos;, (req, res) =&gt; &#123; let sess = req.session; console.log(`session id is: $&#123;sess.id&#125;`) res.json(sess);&#125;);module.exports = router; 运行demo进行测试；查看cookie中’connect.sid’ 和后端log出来的id不一致，是因为cookie中的id是被加密了的。详情可以查看文档中的option - secret。 可以在/session-demo 这里添加代码往session里面添加data，刷新这个页面来测试session的效果。默认配置创建session后，在没有往session添加东西之前，session每次都会变化。 passport 入场添加依赖npm install passport --save，npm install passport-local --savepassport功能单一，只做authenticate, 但是认证方式多种多样，具体如何认证，passport采用了策略模式把具体的实现留给了具体的strategies; 比如passport-local. 策略模式是一种设计模式，它将算法和对象分离开来，通过加载不同的算法来实现不同的行为，适用于相关类的成员相同但行为不同的场景，比如在passport中，认证所需的字段都是用户名、邮箱、密码等，但认证方法是不同的。 配置passport及strategy配置passport， 方便起见，创建单独的配置文件：config/passport.js 12345678910111213141516171819202122232425262728293031&apos;use strict&apos;;/*! * Module dependencies. */const LocalStrategy = require(&apos;passport-local&apos;).Strategy;const passport = require(&apos;passport&apos;);/** * Expose */passport.serializeUser(function(user, done) &#123; done(null, user);&#125;);passport.deserializeUser(function(user, done) &#123; done(null, user);&#125;);// use these strategiespassport.use(&apos;local&apos;,new LocalStrategy( function (username, password, done) &#123; console.log(`Trying to verify user, username:$&#123;username&#125; password:$&#123;password&#125;`) if (username != &apos;joe&apos; || password != &apos;password&apos;) &#123; console.log(`Failed to verify user, username:$&#123;username&#125; password:$&#123;password&#125;`) return done(null, false, &#123; message: &apos;Invalid username or password&apos; &#125;); &#125; return done(null, &#123; &quot;username&quot;: username, &quot;password&quot;: password &#125;,&#123;message:&apos;Successfully authenticated!&apos;&#125;); &#125;));module.exports = passport; 引用passport官方文档： In a Connect or Express-based application, passport.initialize() middleware is required to initialize Passport. If your application uses persistent login sessions, passport.session() middleware must also be used. 这个示例我们不session的持久化，在内存中管理session，因此只需要在相关代码（server.js）加入： 12const passport = require(&apos;./config/passport&apos;);app.use(passport.initialize()); session的持久化在生产环境和重要，这里只是方便演示。 登录登出添加login 页面具体代码参考源代码routes.js 和 login.hbs ; form表单的post请求为/login 添加接受/login post 请求routes.js 中添加： 123456789const passport = require(&apos;passport&apos;).......app.post(&apos;/login&apos;, passport.authenticate(&apos;local&apos;, &#123; successRedirect: &apos;/session-demo&apos;, failureRedirect: &apos;/login&apos;,// 可以先尝试设置/session-demo 来查看对应的情况 failureFlash: true &#125;));....... 来自官方文档： Setting the failureFlash option to true instructs Passport to flash an error message using the message given by the strategy’s verify callback, if any. 这里的flash error message来自passport strategy的callback。比如：return done(null, false, { message: &#39;Invalid username or password&#39; }); 设置failureRedirect: &#39;/session-demo&#39; 可以看看到对应的错误信息。 输入正确用户名和密码：（joe/password）可以在session-demo的页面看到如下： connect-flash的作用又一个从express剥离的组件; 简单读取文档既可以了解到flash 的信息会保存在session中。引入此依赖，同时需要在session相关的配置代码下面添加：app.use(flash());。如果尝试将login失败重定向至session-demo页面，然后多次尝试输入错误的用户名和密码。将会在session-demo页面看到重复的类似如下的flash的error信息： 这些信息是保存在session中，又没有被消费掉；必须被消费掉，否则会挤爆内存，如何消费？看下面说明 登录错误显示错误信息存放于会话中，并且需要及时消费掉！！！ 设置login失败返回login页面，及时消费掉session中的flash信息， 代码如下： 1234app.get('/login', (req, res) =&gt; &#123; let errors = req.flash('error'); // 消费掉flash中的error信息 res.render('login', &#123; 'errors': errors &#125;) &#125;); 页面使用boostrap显示错误信息，请参考源码login.hbs。 登出参考passport文档添加一下logout代码：1234app.get(&apos;/logout&apos;, function(req, res)&#123; req.logout(); res.redirect(&apos;/session-demo&apos;);&#125;); 可以在response中看到passport信息从session中消失了。 会话中用户的序列化和发序列化截止上面，虽然完成了登录，用户的信息也在session中了，但是代码中如何获取到当前用户呢？前面的passport.js代码中的serializeUser 和 deserializeUser 分别是设置和从session中获取用户的时候被调用。 serializeUser和deserializeUser一般有两种方式：1，整个用户模型都存储于会话，获取时候(deserializeUser)无需查询数据库; 2， 只存储用户的ID，获取的时候根据ID从数据库中查询用户模型。 这里的示例采用的是第一种。 文档中多次提到了req.user， 做如下尝试： 1234app.get(&apos;/me&apos;, (req, res) =&gt; &#123; console.log(`current user is $&#123;req.user&#125;`) res.json(&#123;&apos;user&apos;:req.user&#125;);&#125;); 登录后，访问/me 无效。 Why？解决方法： 添加 app.use(passport.session());；一定要在express.session() 之后添加。 前面提到了session的持久化，由于我们并没有做持久化，所以没有引入passport.session() 这个中间件。 现在来看， 显然这个中间件并非只和会话的持久化相关。passport的文档并没有详细描述这点。 路由权限控制中间件问题：一个web网站的内容往往有公开的和私有的部分，如何配置让私有请求重定向到登录页面，甚至针对角色权限不同显示相应的错误消息？添加config/auth.js 12345exports.requiresLogin = function (req, res, next) &#123; if (req.isAuthenticated()) return next(); if (req.method == &apos;GET&apos;) req.session.returnTo = req.originalUrl; res.redirect(&apos;/login&apos;);&#125;; 在route里面来引用配置 1234567891011121314151617const auth = require(&apos;./config/auth&apos;)...app.get(&apos;/me&apos;, auth.requiresLogin, (req, res) =&gt; &#123; console.log(`current user is $&#123;req.user&#125;`) res.json(&#123; &apos;user&apos;: req.user &#125;);&#125;);...// 顺便重构下POST login 保证成功后跳转至用户之前的GET 请求页面app.post(&apos;/login&apos;, passport.authenticate(&apos;local&apos;, &#123; failureRedirect: &apos;/login&apos;, failureFlash: true &#125;), (req, res) =&gt; &#123; const redirectTo = req.session.returnTo? req.session.returnTo: &apos;/session-demo&apos;; delete req.session.returnTo; res.redirect(redirectTo); &#125;); 这里修改了/me 请求，使用auth.requiresLogin 来强制用户登录。同时注意修改了POST /login 登录请求的处理来方便登陆后重定向到之前的GET 请求页面 。 再次以未登录的状态访问/me 就会被重定向至登录界面，登录回来后直接就跳转至了/me 页面展示对应的用户信息。","categories":[],"tags":[]},{"title":"利用sharp来resize 图片","slug":"Nodejs-Technologies/image-resize-sharp","date":"2018-12-21T01:49:26.494Z","updated":"2018-12-21T02:19:47.659Z","comments":true,"path":"Nodejs-Technologies/image-resize-sharp/","link":"","permalink":"http://it.jiu-shu.com/Nodejs-Technologies/image-resize-sharp/","excerpt":"","text":"安装参考： http://sharp.pixelplumbing.com/en/stable/install/ 在Mac Pro上面直接使用npm install --save sharp 安装会报错。根据报错可以发现sharp依赖libxmljs （https://www.npmjs.com/package/libxmljs) , libxmljs 的安装需要node-gyp （https://github.com/nodejs/node-gyp#installation）。 总之很麻烦，解决办法就是更新node-gyp，参考： https://github.com/nodejs/node-gyp/wiki/Updating-npm&#39;s-bundled-node-gyp","categories":[],"tags":[]},{"title":"Spring Cloud 微服务解决方案","slug":"Micro-Services/Spring Cloud 实现全链路追踪","date":"2018-12-21T01:49:26.484Z","updated":"2018-12-21T02:47:14.884Z","comments":true,"path":"Micro-Services/Spring Cloud 实现全链路追踪/","link":"","permalink":"http://it.jiu-shu.com/Micro-Services/Spring Cloud 实现全链路追踪/","excerpt":"","text":"Spring Cloud Netflix / Nodejs尝试使用Spring Cloud Netflix 加 Nodejs 技术栈混合搭建微服务。 （示例并无任何业务意义，只为做演示） 此库为https://github.com/choelea/spring-cloud-netflix 的演进版，在此基础上增加了全链路跟踪，服务监控及跨服务日志跟踪代码： https://github.com/choelea/spring-cloud-nodejs/实现如下 服务注册发现 服务间调用（feign) 服务路由 负载均衡 (eureka client 端) 分布式链路调用监控系统 跨服务日志跟踪 服务监控 相关版本依赖Spring Boot： 1.5.9.RELEASESpring Cloud: Edgware.RELEASENodejs： v8.9.1 (本机是v8.9.1的，没有在其他版本上做测试) 架构图 (Architecture for microservice) 此图仅仅是服务注册的，监控和全链路跟踪未添加 eureka-server： Spring Boot + Cloud 技术栈搭建eureka 服务。（服务注册中心） bookmark-service： Spring Boot 的微服务程序 nodejs-bookservice nodejs开发的微服务 composite-service 聚合服务 spring-boot-admin-server Spring Boot 监控 zipkin 分布式链路追踪服务 spring-apigateway Spring Boot + Cloud Netflix技术栈搭建的网关 nodejs-web nodejs开发的网关兼web应用 eureka-server-peer1 和 eureka-server-peer2 是用来验证eureka 集群的，可以选择启动这两个服务，不启动eureka-server服务。 程序运行按照上面的顺序依次运行。 Spring Boot的程序运行：mvn spring-boot:run ; nodejs 程序运行：npm start spring-boot-admin-server 的控制台会有异常抛出，是因为nodejs的 bookservice程序无法接入spring boot admin的监控的。 —- 尽管restful的微服务号称技术平台无关，然而一旦选择了某些技术栈，基本也就限制了使用某个语言和某个技术。 测试spring-apigatewayspring-apigateway 作为eureka的客户端结合zuul proxy的反向代理，为多个微服务提供一个单一的访问节点。访问http://localhost:8080/bookmarks/jlong/bookmarks （结果同http://localhost:9098/jlong/bookmarks 完全一致） 123456789[ &#123; &quot;userId&quot;: &quot;jlong&quot;, &quot;id&quot;: 2, &quot;href&quot;: &quot;http://some-other-hostjlong.com/&quot;, &quot;description&quot;: &quot;A description for jlong&apos;s link&quot;, &quot;label&quot;: &quot;jlong&quot; &#125;] 访问http://localhost:8080/books 反向代理至nodejs-bookservice的服务：http://localhost:3001/books 12345678910[ &#123; &quot;bookname&quot;: &quot;Nodejs Web Development&quot;, &quot;author&quot;: &quot;David Herron&quot; &#125;, &#123; &quot;bookname&quot;: &quot;Mastering Web Application Development with Express &quot;, &quot;author&quot;: &quot;Alexandru Vlăduțu&quot; &#125;] 测试nodejsnodejs 采用eureka-js-client 组件获取/注册微服务。这里nodejs-web只作为服务的消费方，接入eureka server，消费上游的服务并展示给客户端（浏览器）。查看nodejs-web作为eureka client 获取到注册的服务信息，通过向服务直接发起request来获取数据并展示。访问：http://localhost:3000 即可看如下显示： 查看服务注册情况：打开http://localhost:8761/ instance信息的获取主要通过下面的链接： http://localhost:8761/eureka/apps 获取整个注册进来的服务的信息 http://localhost:8761/eureka/apps/{app} 获取某个服务的所有的实例信息 例如：http://localhost:8761/eureka/apps/BOOK-SERVICE http://localhost:8761/eureka/apps/{app}/{instanceId} 获取具体的instance的信息 nodejs 使用eureka-js-client 来配置服务的instance信息，需要配置的信息更多，也更直观的反应了instance的信息；和通过连接（http://localhost:8761/eureka/apps）查到的基本一致。 nodejs的微服务app，在eureka的client的配置中最好保持app，vipAddress（secureVipAddress 一般不会用上）一致。 经测试发现，Spring Boot / Cloud Netflix 技术栈开发的apigateway，采用Zuul Reverse Proxy 反向代理的时候，必须app 和 vipAddress设置一致。 多个instance通过instanceId来区分。 监控Spring Boot服务通过http://localhost:8088 可以进入Spring Boot的服务列表；选中服务点击Details可以查看详细信息。 调用链路跟踪通过http://localhost:9411 查询服务间调用情况","categories":[],"tags":[]},{"title":"Spring Cloud Netflix 加 Nodejs 技术栈混合搭建微服务","slug":"Micro-Services/Spring Boot & Nodejs 混合微服务示例","date":"2018-12-21T01:49:26.482Z","updated":"2018-12-21T02:47:14.870Z","comments":true,"path":"Micro-Services/Spring Boot & Nodejs 混合微服务示例/","link":"","permalink":"http://it.jiu-shu.com/Micro-Services/Spring Boot & Nodejs 混合微服务示例/","excerpt":"","text":"Spring Cloud Netflix / Nodejs尝试使用Spring Cloud Netflix 加 Nodejs 技术栈混合搭建微服务。 （示例并无任何业务意义，只为做演示）代码： https://github.com/choelea/spring-cloud-netflix/ ref： tags/micros-service-hybrid-demo 相关版本依赖Spring Boot： 1.5.4.RELEASESpring Cloud: Dalston.SR1Nodejs： 7.2.0 (本机是7.2.0的，没有在其他版本上做测试) 架构图 (Architecture for microservice) eureka-server： Spring Boot + Cloud 技术栈搭建eureka 服务。（服务注册中心） bookmark-service： Spring Boot 的微服务程序 nodejs-bookservice nodejs开发的微服务 spring-apigateway Spring Boot + Cloud Netflix技术栈搭建的网关 nodejs-web nodejs开发的网关兼web应用 程序运行按照上面的顺序依次运行。 Spring Boot的程序运行：mvn spring-boot:run ; nodejs 程序运行：npm start 查看服务注册情况：打开http://localhost:8761/instance信息的获取主要通过下面的链接： http://localhost:8761/eureka/apps 获取整个注册进来的服务的信息 http://localhost:8761/eureka/apps/{app} 获取某个服务的所有的实例信息 例如：http://localhost:8761/eureka/apps/BOOK-SERVICE http://localhost:8761/eureka/apps/{app}/{instanceId} 获取具体的instance的信息 nodejs 使用eureka-js-client 来配置服务的instance信息，需要配置的信息更多，也更直观的反应了instance的信息；和通过连接（http://localhost:8761/eureka/apps）查到的基本一致。 nodejs的微服务app，在eureka的client的配置中最好保持app，vipAddress（secureVipAddress 一般不会用上）一致。 经测试发现，Spring Boot / Cloud Netflix 技术栈开发的apigateway，采用Zuul Reverse Proxy 反向代理的时候，必须app 和 vipAddress设置一致。 多个instance通过instanceId来区分。 测试spring-apigatewayspring-apigateway 作为eureka的客户端结合zuul proxy的反向代理，为多个微服务提供一个单一的访问节点。访问http://localhost:8080/bookmarks/jlong/bookmarks （结果同http://localhost:9098/jlong/bookmarks 完全一致） 123456789[ &#123; &quot;userId&quot;: &quot;jlong&quot;, &quot;id&quot;: 2, &quot;href&quot;: &quot;http://some-other-hostjlong.com/&quot;, &quot;description&quot;: &quot;A description for jlong&apos;s link&quot;, &quot;label&quot;: &quot;jlong&quot; &#125;] 访问http://localhost:8080/books 反向代理至nodejs-bookservice的服务：http://localhost:3001/books 12345678910[ &#123; &quot;bookname&quot;: &quot;Nodejs Web Development&quot;, &quot;author&quot;: &quot;David Herron&quot; &#125;, &#123; &quot;bookname&quot;: &quot;Mastering Web Application Development with Express &quot;, &quot;author&quot;: &quot;Alexandru Vlăduțu&quot; &#125;] 测试nodejsnodejs 采用eureka-js-client 组件获取/注册微服务。这里nodejs-web只作为服务的消费方，接入eureka server，消费上游的服务并展示给客户端（浏览器）。查看nodejs-web作为eureka client 获取到注册的服务信息，通过向服务直接发起request来获取数据并展示。访问：http://localhost:3000 即可看如下显示：","categories":[],"tags":[]},{"title":"Dubbo + Spring Boot 实现微服务治理","slug":"Micro-Services/Dubbo-Spring-Boot","date":"2018-12-21T01:49:26.462Z","updated":"2018-12-21T02:47:14.856Z","comments":true,"path":"Micro-Services/Dubbo-Spring-Boot/","link":"","permalink":"http://it.jiu-shu.com/Micro-Services/Dubbo-Spring-Boot/","excerpt":"","text":"Dubbo 是国内阿里系的一个开源框架，提供基于RPC的微服务的治理框架。本文主要探索dubbo 和 spring boot 的结合, 采用https://github.com/dubbo/dubbo-spring-boot-project 来实现dubbo和spring boot的结合。（新的Spring Boot Start貌似还在研发中。）主要探索和实现如下几项： 服务注册与发现 服务提供方和消费方连通 服务管理与监控 （dubbo-admin dubbo-monitor） 负载均衡 跨服务日志追踪 （traceId的实现） RPC 调用的异常处理 示例代码https://github.com/choelea/dubboot-example 架构图分两个服务提供方：product和promotion，一个消费方web demo。web对外提供restful的服务，内部采用rpc协议。 这里product服务的模型利用了MongoDB vs Mysql 测试 的模型,代码和数据库。 项目结构介绍 服务注册注册采用推荐的zookeeper，具体安装不在这里赘述。服务注册和监控这里没有详细介绍，需要根据实际情况修改以下配置： 12spring.dubbo.registry.address=zookeeper://192.168.1.99:2181spring.dubbo.monitor.address=192.168.1.99:7070 服务管理和监控checkout dubbo工程的最新的release 代码，参考开发手册http://dubbo.io/books/dubbo-dev-book/ 构建。构建完成后，分别在dubbo-simple\\dubbo-monitor-simple 和 dubbo-admin工程里找到相应的dubbo-monitor-simple-2.5.8-assembly.tar.gz和dubbo-admin-2.5.8.war。 参考http://dubbo.io/books/dubbo-admin-book/ 进行部署。 跨服务日志追踪扩展调用拦截通过自定义调用拦截，将traceId透传给服务提供方。 这里只探索，所以只用了一个filter来供服务方和消费方用，实际中可能分开个filter更合适。 参考dubbo开发手册的SPI的调用拦截扩展，自定义filter来来完成traceid的透传。（参考：http://blog.csdn.net/coolsky600/article/details/63684046）扩展需要注意一下： META-INF/dubbo/com.alibaba.dubbo.rpc.Filter中添加：xxx=com.xxx.XxxFilter service的申明出设置filter @Service(version = &quot;1.0.0&quot;, filter=&quot;traceIdFilter&quot;) 具体实现请参考dubboot-trace-log. 增强日志功能让日志可以打印traceId参考文章：https://moelholm.com/2016/08/16/spring-boot-enhance-your-logging/traceId的发起位置是从web-demo 接受到请求开始。 具体参考：com.dubboot.webdemo.web.filter.TraceLoggingFilter。 测试验证依次启动product，promotion和web-demo服务，然后访问http://localhost:8080/product/pp-0 观察后面的日志情况。（zookeeper需要提前启动好保持运行状态） 负载均衡测试修改端口，启动多个promotion服务，查看日志来验证随机算法的负载均衡。 生产环境，在同一个容器中运行同一个服务的多个实例并不是最佳实践。为了充分利用系统的资源，可以选择启动多种服务的实例，不同服务的实例分布在不同的容器/机器上。 同一个服务的端口不变，IP地址或者hostname会不同。","categories":[],"tags":[]},{"title":"Nodejs 使用 JWT和express-http-proxy 来实现简易APIGateway","slug":"Micro-Services/APIGateway-Using-JWT","date":"2018-12-21T01:49:26.460Z","updated":"2018-12-21T02:47:14.870Z","comments":true,"path":"Micro-Services/APIGateway-Using-JWT/","link":"","permalink":"http://it.jiu-shu.com/Micro-Services/APIGateway-Using-JWT/","excerpt":"","text":"简介代码： https://github.com/choelea/tokenbased-api-gateway 构建基于jwt的apigateway; 实现资源访问的控制。 利用express-http-proxy来自动proxy到内部资源服务。 (内部资源服务没有任何的访问限制，不能直接暴露给外部APP访问)这里的用户资源也来源于内部资源服务。 测试APIPOST Request for an tokenURL: http://localhost:3000/auth/authenticatePOST-Body:1234&#123; &quot;email&quot;: &quot;joe.li@okchem.com&quot;, &quot;password&quot;: &quot;okchem&quot;&#125; Sample of Response:12345678910111213141516171819&#123; &quot;msg&quot;: null, &quot;msgCode&quot;: null, &quot;success&quot;: true, &quot;data&quot;: &#123; &quot;id&quot;: 104, &quot;userEmail&quot;: &quot;joe.li@okchem.com&quot;, &quot;userRole&quot;: &quot;BUYER&quot;, &quot;userStatus&quot;: &quot;ACTIVE&quot;, &quot;userProfile&quot;: &#123; &quot;firstName&quot;: &quot;joe&quot;, &quot;lastName&quot;: &quot;li&quot;, &quot;companyName&quot;: &quot;ly&quot;, &quot;country&quot;: &quot;CHN&quot;, &quot;telphone&quot;: &quot;8618086068133&quot; &#125; &#125;, &quot;chemToken&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MTA0LCJ1c2VyRW1haWwiOiJqb2UubGlAb2tjaGVtLmNvbSIsInVzZXJSb2xlIjoiQlVZRVIiLCJ1c2VyU3RhdHVzIjoiQUNUSVZFIiwidXNlclByb2ZpbGUiOnsiZmlyc3ROYW1lIjoiam9lIiwibGFzdE5hbWUiOiJsaSIsImNvbXBhbnlOYW1lIjoibHkiLCJjb3VudHJ5IjoiQ0hOIiwidGVscGhvbmUiOiI4NjE4MDg2MDY4MTMzIn0sImlhdCI6MTUyNTg0NjA2NCwiZXhwIjoxNTI1OTMyNDY0fQ.hIQFv71SHMX2Vd5RPD8ir08LIVeaveZEoN-DQdkxcj0&quot;&#125; Request to ResourceToken in the header:1chem-token: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MTA0LCJ1c2VyRW1haWwiOiJqb2UubGlAb2tjaGVtLmNvbSIsInVzZXJSb2xlIjoiQlVZRVIiLCJ1c2VyU3RhdHVzIjoiQUNUSVZFIiwidXNlclByb2ZpbGUiOnsiZmlyc3ROYW1lIjoiam9lIiwibGFzdE5hbWUiOiJsaSIsImNvbXBhbnlOYW1lIjoibHkiLCJjb3VudHJ5IjoiQ0hOIiwidGVscGhvbmUiOiI4NjE4MDg2MDY4MTMzIn0sImlhdCI6MTUyNTg0NjA2NCwiZXhwIjoxNTI1OTMyNDY0fQ.hIQFv71SHMX2Vd5RPD8ir08LIVeaveZEoN-DQdkxcj0 In the following request, get user from req buy req.user, Try test using ‘http://localhost:3000/api/group-buying/application-list/10/1&#39; Something you may concernHere, the jwt is actually an ‘value token’, not an ‘reference token’. Mostly the value token is rolling when request continues. It’s more like anAccess Token. Here we set the expire time to 24 hours. For me, I believe one use an app for 24 hours, so it’s not an issue. But rolling is what you need, I suggest below 2 solutions. Switch to reference token. Changes needed: Involve such as redis to store value which the token refer Fetch value from redis after you got the token Extend the expire data in redis Add refresh API to refresh a new token, so that app can call to refresh a new token each 30 minutes. Refresh API will check access token Only refresh a new token if the access is about to expire in 1 hour","categories":[],"tags":[]},{"title":"Java 短ID 随机字符串","slug":"Java-Technologies/Java-UUID","date":"2018-12-21T01:49:26.454Z","updated":"2018-03-05T01:03:32.246Z","comments":true,"path":"Java-Technologies/Java-UUID/","link":"","permalink":"http://it.jiu-shu.com/Java-Technologies/Java-UUID/","excerpt":"","text":"使用apache common的lib 包。 用1000,0000 次测试，无重复字符串。 12345678910111213141516171819202122232425262728293031323334353637383940import java.io.File;import java.io.IOException;import java.util.HashSet;import java.util.List;import java.util.Set;import org.apache.commons.io.FileUtils;import org.apache.commons.lang.RandomStringUtils;/** * 短ID 测试，使用1000,0000 次测试无重复字符串。 main1()生成500,0000。 后再用main2() 读取，然后再次新加500,0000生成，无重复记录。 * @author Joe * */public class RandomStringUtilsTrial &#123; public static void main(String[] args) throws IOException &#123; main2(); &#125; public static void main1() throws IOException &#123; System.out.print(&quot;8 char string &gt;&gt;&gt;&quot;); Set&lt;String&gt; set = new HashSet&lt;String&gt;(); for (int i = 0; i &lt; 5000000; i++) &#123; set.add(RandomStringUtils.random(9, true, true)); &#125; FileUtils.writeLines(new File(&quot;test.txt&quot;), set); &#125; public static void main2() throws IOException &#123; System.out.print(&quot;8 char string &gt;&gt;&gt;&quot;); Set&lt;String&gt; set = new HashSet&lt;String&gt;(); List&lt;String&gt; list = FileUtils.readLines(new File(&quot;test.txt&quot;)); for (String string : list) &#123; set.add(string); &#125; for (int i = 0; i &lt; 5000000; i++) &#123; set.add(RandomStringUtils.random(9, true, true)); &#125; System.out.println(set.size()); &#125;&#125;","categories":[],"tags":[]},{"title":"Java 工具类收集","slug":"Java-Technologies/java-utils","date":"2018-12-21T01:49:26.451Z","updated":"2018-12-21T02:19:41.041Z","comments":true,"path":"Java-Technologies/java-utils/","link":"","permalink":"http://it.jiu-shu.com/Java-Technologies/java-utils/","excerpt":"","text":"URI 工具类org.springframework.web.util.UriUtils - Utility class for URI encoding and decoding based on RFC 3986. Offers encoding methods for the various URI components.","categories":[],"tags":[]},{"title":"关于Java 正则表达式的介绍","slug":"Java-Technologies/java-regular-expressions","date":"2018-12-21T01:49:26.449Z","updated":"2018-12-21T02:19:37.845Z","comments":true,"path":"Java-Technologies/java-regular-expressions/","link":"","permalink":"http://it.jiu-shu.com/Java-Technologies/java-regular-expressions/","excerpt":"","text":"在本文中，我们将讨论Java Regex API以及如何在Java编程语言中使用正则表达式。 在正则表达式的世界中，有许多不同的风格可供选择，例如grep，Perl，Python，PHP，awk等等。 这意味着在一种编程语言中工作的正则表达式可能在另一种编程语言中不起作用。 Java中的正则表达式语法与Perl中的语法最相似。 这篇文章大部分内容只是针对： https://www.baeldung.com/regular-expressions-java 进行了翻译； Chrome的插件翻译的近乎完美，大部分的翻译都是直接来源于此。 要在Java中使用正则表达式，我们不需要任何特殊设置。 JDK包含一个特殊的包java.util.regex，完全专用于正则表达式操作。我们只需要将它导入我们的代码中。 此外，java.lang.String类还具有内置的正则表达式支持，我们通常在代码中使用它们 Java 正则表达式包java.util.regex包由三个类组成：Pattern，Matcher和PatternSyntaxException： Pattern对象是一个已编译的正则表达式。 Pattern类不提供公共构造函数。要创建模式，我们必须首先调用其公共静态编译方法之一，然后返回Pattern对象。这些方法接受正则表达式作为第一个参数。 Matcher对象解释模式并对输入String执行匹配操作。它还定义了没有公共构造函数。我们通过在Pattern对象上调用matcher方法来获取Matcher对象。 PatternSyntaxException对象是未经检查的异常，表示正则表达式模式中的语法错误。 简单示例来理解如何应用1234567@Testpublic void givenText_whenSimpleRegexMatches_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;foo&quot;); Matcher matcher = pattern.matcher(&quot;foo&quot;); assertTrue(matcher.find());&#125; 我们首先通过调用静态编译方法创建一个Pattern对象，并将它传递给我们想要使用的模式。 然后我们创建一个Matcher对象，调用Pattern对象的matcher方法并将它传递给我们要检查匹配的文本。 之后，我们在Matcher对象中调用方法find。 find方法不断推进输入文本并为每个匹配返回true，因此我们也可以使用它来查找匹配计数：1234567891011@Testpublic void givenText_whenSimpleRegexMatchesTwice_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;foo&quot;); Matcher matcher = pattern.matcher(&quot;foofoo&quot;); int matches = 0; while (matcher.find()) &#123; matches++; &#125; assertEquals(matches, 2);&#125; 由于我们将运行更多测试，因此我们可以在名为runTest的方法中抽象查找匹配数的逻辑：123456789public static int runTest(String regex, String text) &#123; Pattern pattern = Pattern.compile(regex); Matcher matcher = pattern.matcher(text); int matches = 0; while (matcher.find()) &#123; matches++; &#125; return matches;&#125; 元字符元字符会影响模式的匹配方式，从而为搜索模式添加逻辑。 Java API支持几个元字符，最直接的是匹配任何字符的点“.”：123456@Testpublic void givenText_whenMatchesWithDotMetach_thenCorrect() &#123; int matches = runTest(&quot;.&quot;, &quot;foo&quot;); assertTrue(matches &gt; 0);&#125; 考虑前面的例子，其中正则表达式foo与文本foo以及foofoo匹配两次。如果我们在正则表达式中使用点元字符，我们在第二种情况下不会得到两个匹配：123456@Testpublic void givenRepeatedText_whenMatchesOnceWithDotMetach_thenCorrect() &#123; int matches= runTest(&quot;foo.&quot;, &quot;foofoo&quot;); assertEquals(matches, 1);&#125; 注意正则表达式中foo之后的点。匹配器匹配前面有foo的每个文本，因为最后一个点部分表示后面的任何字符。所以在找到第一个foo之后，其余部分被视为任何角色。这就是为什么只有一个匹配。 API支持其他几个元字符&lt;（[{\\ ^ - = $！|]}）？* +。&gt;，我们将在本文中进一步研究。 字符类浏览官方Pattern类规范，我们将发现支持的正则表达式结构的摘要。在字符类下，我们有大约6个构造。 OR类构造为[abc]。集合中的任何元素都匹配：123456@Testpublic void givenORSet_whenMatchesAny_thenCorrect() &#123; int matches = runTest(&quot;[abc]&quot;, &quot;b&quot;); assertEquals(matches, 1);&#125; 如果它们都出现在文本中，则每个都是单独匹配而不考虑顺序：123456@Testpublic void givenORSet_whenMatchesAnyAndAll_thenCorrect() &#123; int matches = runTest(&quot;[abc]&quot;, &quot;cab&quot;); assertEquals(matches, 3);&#125; 它们也可以作为String的一部分进行交替。在下面的示例中，当我们通过将第一个字母与集合中的每个元素交替来创建不同的单词时，它们都匹配：123456@Testpublic void givenORSet_whenMatchesAllCombinations_thenCorrect() &#123; int matches = runTest(&quot;[bcr]at&quot;, &quot;bat cat rat&quot;); assertEquals(matches, 3);&#125; NOR 类通过添加插入符号^作为第一个元素来取消上面的设置：123456@Testpublic void givenNORSet_whenMatchesNon_thenCorrect() &#123; int matches = runTest(&quot;[^abc]&quot;, &quot;g&quot;); assertTrue(matches &gt; 0);&#125; Another case:123456@Testpublic void givenNORSet_whenMatchesAllExceptElements_thenCorrect() &#123; int matches = runTest(&quot;[^bcr]at&quot;, &quot;sat mat eat&quot;); assertTrue(matches &gt; 0);&#125; Range 类我们可以定义一个类，使用连字符（ - ）指定匹配文本应该落在的范围内，同样，我们也可以否定范围。 匹配大写的英文字母:12345678@Testpublic void givenUpperCaseRange_whenMatchesUpperCase_ thenCorrect() &#123; int matches = runTest( &quot;[A-Z]&quot;, &quot;Two Uppercase alphabets 34 overall&quot;); assertEquals(matches, 2);&#125; 匹配小写的英文字母:12345678@Testpublic void givenLowerCaseRange_whenMatchesLowerCase_ thenCorrect() &#123; int matches = runTest( &quot;[a-z]&quot;, &quot;Two Uppercase alphabets 34 overall&quot;); assertEquals(matches, 26);&#125; 匹配大小写的英文字母:12345678@Testpublic void givenBothLowerAndUpperCaseRange_ whenMatchesAllLetters_thenCorrect() &#123; int matches = runTest( &quot;[a-zA-Z]&quot;, &quot;Two Uppercase alphabets 34 overall&quot;); assertEquals(matches, 28);&#125; 匹配给定范围的数字：12345678@Testpublic void givenNumberRange_whenMatchesAccurately_ thenCorrect() &#123; int matches = runTest( &quot;[1-5]&quot;, &quot;Two Uppercase alphabets 34 overall&quot;); assertEquals(matches, 2);&#125; 匹配另一个数字范围： 12345678@Testpublic void givenNumberRange_whenMatchesAccurately_ thenCorrect2()&#123; int matches = runTest( &quot;[30-35]&quot;, &quot;Two Uppercase alphabets 34 overall&quot;); assertEquals(matches, 1);&#125; Union 类联合字符类是组合两个或多个字符类的结果：123456@Testpublic void givenTwoSets_whenMatchesUnion_thenCorrect() &#123; int matches = runTest(&quot;[1-3[7-9]]&quot;, &quot;123456789&quot;); assertEquals(matches, 6);&#125; 上面的测试只匹配9个整数中的6个，因为联合集跳过了3,4和5。 Intersection 类与union类相似，此类是从两个或多个集合之间选择公共元素得到的。要应用交集，我们使用&amp;&amp;：123456@Testpublic void givenTwoSets_whenMatchesIntersection_thenCorrect() &#123; int matches = runTest(&quot;[1-6&amp;&amp;[3-9]]&quot;, &quot;123456789&quot;); assertEquals(matches, 4);&#125; 我们得到4个匹配，因为两个集合的交集只有4个元素。 Subtraction Class我们可以使用减法来否定一个或多个字符类，例如匹配一组奇数十进制数： 123456@Testpublic void givenSetWithSubtraction_whenMatchesAccurately_thenCorrect() &#123; int matches = runTest(&quot;[0-9&amp;&amp;[^2468]]&quot;, &quot;123456789&quot;); assertEquals(matches, 5);&#125; 只有1,3,5,7,9匹配。 预定义字符类Java正则表达式API也接受预定义的字符类。上述某些字符类可以用较短的形式表示，但使代码不太直观。这个正则表达式的Java版本的一个特殊方面是转义字符。 正如我们将看到的，大多数字符将以反斜杠开头，这在Java中具有特殊含义。要由Pattern类编译这些 - 必须转义前导反斜杠，即\\ d变为\\\\ d。 匹配数字，相当于[0-9]： 匹配数字，相当于[0-9]： 123456@Testpublic void givenDigits_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;\\\\d&quot;, &quot;123&quot;); assertEquals(matches, 3);&#125; 匹配非数字，相当于[^ 0-9]： 123456@Testpublic void givenNonDigits_whenMatches_thenCorrect() &#123; int mathces = runTest(&quot;\\\\D&quot;, &quot;a6c&quot;); assertEquals(matches, 2);&#125; 匹配空白区域： 123456@Testpublic void givenWhiteSpace_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;\\\\s&quot;, &quot;a c&quot;); assertEquals(matches, 1);&#125; 匹配非白色空间：123456@Testpublic void givenNonWhiteSpace_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;\\\\S&quot;, &quot;a c&quot;); assertEquals(matches, 2);&#125; 匹配单词字符，相当于[a-zA-Z_0-9]：123456@Testpublic void givenWordCharacter_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;\\\\w&quot;, &quot;hi!&quot;); assertEquals(matches, 2);&#125; 匹配非单词字符 123456@Testpublic void givenNonWordCharacter_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;\\\\W&quot;, &quot;hi!&quot;); assertEquals(matches, 1);&#125; 量词Java正则表达式API还允许我们使用量词。这使我们能够通过指定要匹配的出现次数来进一步调整匹配的行为。 为了匹配文本零或一次，我们使用？量词：123456@Testpublic void givenZeroOrOneQuantifier_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;\\\\a?&quot;, &quot;hi&quot;); assertEquals(matches, 3);&#125; 或者，我们可以使用Java正则表达式API支持的大括号语法： 123456@Testpublic void givenZeroOrOneQuantifier_whenMatches_thenCorrect2() &#123; int matches = runTest(&quot;\\\\a&#123;0,1&#125;&quot;, &quot;hi&quot;); assertEquals(matches, 3);&#125; 此示例介绍了零长度匹配的概念。碰巧的是，如果量词的匹配阈值为零，它总是匹配文本中的所有内容，包括每个输入末尾的空字符串。这意味着即使输入为空，它也将返回一个零长度匹配。 这解释了为什么我们在上面的例子中得到3个匹配，尽管有一个长度为2的字符串。第三个匹配是零长度的空字符串。 为了匹配文本零或无限次，我们使用*量词，它类似于？： 123456@Testpublic void givenZeroOrManyQuantifier_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;\\\\a*&quot;, &quot;hi&quot;); assertEquals(matches, 3);&#125; 同等效果的另外一种写法： 123456@Testpublic void givenZeroOrManyQuantifier_whenMatches_thenCorrect2() &#123; int matches = runTest(&quot;\\\\a&#123;0,&#125;&quot;, &quot;hi&quot;); assertEquals(matches, 3);&#125; 具有差异的量词是+，它具有匹配阈值1.如果根本不发生所需的字符串，则不会匹配，甚至不是零长度字符串： 123456@Testpublic void givenOneOrManyQuantifier_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;\\\\a+&quot;, &quot;hi&quot;); assertFalse(matches);&#125; 同等效果的另外一种写法： 123456@Testpublic void givenOneOrManyQuantifier_whenMatches_thenCorrect2() &#123; int matches = runTest(&quot;\\\\a&#123;1,&#125;&quot;, &quot;hi&quot;); assertFalse(matches);&#125; 与Perl和其他语言一样，大括号语法可用于多次匹配给定文本： 123456@Testpublic void givenBraceQuantifier_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;a&#123;3&#125;&quot;, &quot;aaaaaa&quot;); assertEquals(matches, 2);&#125; 在上面的示例中，我们得到两个匹配项，因为匹配仅在连续出现三次时才会发生。但是，在下一个测试中，我们不会得到匹配，因为文本只连续出现两次： 123456@Testpublic void givenBraceQuantifier_whenFailsToMatch_thenCorrect() &#123; int matches = runTest(&quot;a&#123;3&#125;&quot;, &quot;aa&quot;); assertFalse(matches &gt; 0);&#125; 当我们在大括号中使用一个范围时，匹配将是贪婪的，从范围的较高端匹配：123456@Testpublic void givenBraceQuantifierWithRange_whenMatches_thenCorrect() &#123; int matches = runTest(&quot;a&#123;2,3&#125;&quot;, &quot;aaaa&quot;); assertEquals(matches, 1);&#125; 我们已经指定了至少两次但不超过三次，所以我们得到一个匹配，而匹配器看到一个aaa和一个无法匹配的孤独aa。 但是，API允许我们指定一个懒惰或不情愿的方法，以便匹配器可以从范围的下端开始，在这种情况下匹配两次出现为aa和aa： 123456@Testpublic void givenBraceQuantifierWithRange_whenMatchesLazily_thenCorrect() &#123; int matches = runTest(&quot;a&#123;2,3&#125;?&quot;, &quot;aaaa&quot;); assertEquals(matches, 2);&#125; 捕获组API还允许我们通过捕获组将多个字符视为一个单元。 它会将数字附加到捕获组，并允许使用这些数字进行反向引用。 在本节中，我们将看到一些关于如何在Java regex API中使用捕获组的示例。 让我们使用仅当输入文本包含彼此相邻的两个数字时才匹配的捕获组： 123456@Testpublic void givenCapturingGroup_whenMatches_thenCorrect() &#123; int maches = runTest(&quot;(\\\\d\\\\d)&quot;, &quot;12&quot;); assertEquals(matches, 1);&#125; 附加到上面匹配的数字是1，使用后向引用告诉匹配器我们要匹配文本的匹配部分的另一个出现。 123456@Testpublic void givenCapturingGroup_whenMatches_thenCorrect2() &#123; int matches = runTest(&quot;(\\\\d\\\\d)&quot;, &quot;1212&quot;); assertEquals(matches, 2);&#125; 对于输入有两个单独的匹配，我们可以有一个匹配但传播相同的正则表达式匹配以使用反向引用跨越输入的整个长度： 1234567@Testpublic void givenCapturingGroup_whenMatchesWithBackReference_ thenCorrect() &#123; int matches = runTest(&quot;(\\\\d\\\\d)\\\\1&quot;, &quot;1212&quot;); assertEquals(matches, 1);&#125; 我们必须在没有反向引用的情况下重复正则表达式以获得相同的结果： 123456@Testpublic void givenCapturingGroup_whenMatches_thenCorrect3() &#123; int matches = runTest(&quot;(\\\\d\\\\d)(\\\\d\\\\d)&quot;, &quot;1212&quot;); assertEquals(matches, 1);&#125; 类似地，对于任何其他重复次数，反向引用可以使匹配器将输入视为单个匹配： 1234567@Testpublic void givenCapturingGroup_whenMatchesWithBackReference_ thenCorrect2() &#123; int matches = runTest(&quot;(\\\\d\\\\d)\\\\1\\\\1\\\\1&quot;, &quot;12121212&quot;); assertEquals(matches, 1);&#125; 但如果你改变了哪怕最后一位数，那么匹配就会失败：123456@Testpublic void givenCapturingGroupAndWrongInput_whenMatchFailsWithBackReference_thenCorrect() &#123; int matches = runTest(&quot;(\\\\d\\\\d)\\\\1&quot;, &quot;1213&quot;); assertFalse(matches &gt; 0);&#125; 重要的是不要忘记转义反斜杠，这在Java语法中至关重要。 捕获组更有价值的地方在于通过Matcher 的 group()方法来后去捕获到的字符串；详情可以参考： http://www.runoob.com/w3cnote/java-capture-group.html 边界匹配Java正则表达式API还支持边界匹配。如果我们关心匹配应该在输入文本中的确切位置，那么这就是我们正在寻找的。在前面的例子中，我们关心的是是否找到匹配。 要仅在文本开头所需的正则表达式为真时匹配，我们使用插入符号^。 此测试将成功，因为可以在开头找到文本狗：123456@Testpublic void givenText_whenMatchesAtBeginning_thenCorrect() &#123; int matches = runTest(&quot;^dog&quot;, &quot;dogs are friendly&quot;); assertTrue(matches &gt; 0);&#125; 下面的将失败：1234567@Testpublic void givenTextAndWrongInput_whenMatchFailsAtBeginning_ thenCorrect() &#123; int matches = runTest(&quot;^dog&quot;, &quot;are dogs are friendly?&quot;); assertFalse(matches &gt; 0);&#125; 要仅在文本末尾所需的正则表达式为真时匹配，我们使用美元字符$。在以下情况中将找到匹配：123456@Testpublic void givenTextAndWrongInput_whenMatchFailsAtEnd_thenCorrect() &#123; int matches = runTest(&quot;dog$&quot;, &quot;is a dog man&apos;s best friend?&quot;); assertFalse(matches &gt; 0);&#125; 如果我们只想在单词边界找到所需的文本时匹配，我们在正则表达式的开头和结尾使用\\ b正则表达式：123456@Testpublic void givenText_whenMatchesAtWordBoundary_thenCorrect() &#123; int matches = runTest(&quot;\\\\bdog\\\\b&quot;, &quot;a dog is friendly&quot;); assertTrue(matches &gt; 0);&#125; 空格是一个词边界：123456@Testpublic void givenText_whenMatchesAtWordBoundary_thenCorrect() &#123; int matches = runTest(&quot;\\\\bdog\\\\b&quot;, &quot;a dog is friendly&quot;); assertTrue(matches &gt; 0);&#125; 一行开头的空字符串也是一个单词边界：123456@Testpublic void givenText_whenMatchesAtWordBoundary_thenCorrect2() &#123; int matches = runTest(&quot;\\\\bdog\\\\b&quot;, &quot;dog is man&apos;s best friend&quot;); assertTrue(matches &gt; 0);&#125; 这些测试通过，因为String的开头以及一个文本和另一个文本之间的空格标记了单词边界，但是，以下测试显示相反的结果：123456@Testpublic void givenWrongText_whenMatchFailsAtWordBoundary_thenCorrect() &#123; int matches = runTest(&quot;\\\\bdog\\\\b&quot;, &quot;snoop dogg is a rapper&quot;); assertFalse(matches &gt; 0);&#125; 连续出现的双字符不标记单词边界，但我们可以通过更改正则表达式的结尾来查找非单词边界：12345@Testpublic void givenText_whenMatchesAtWordAndNonBoundary_thenCorrect() &#123; int matches = runTest(&quot;\\\\bdog\\\\B&quot;, &quot;snoop dogg is a rapper&quot;); assertTrue(matches &gt; 0);&#125; Pattern Class Methods之前，我们只以基本方式创建了Pattern对象。但是，此类具有另一种编译方法，它接受一组标志以及影响模式匹配方式的正则表达式参数。 这些标志只是抽象的整数值。让我们重载测试类中的runTest方法，以便它可以将标志作为第三个参数： 123456789public static int runTest(String regex, String text, int flags) &#123; pattern = Pattern.compile(regex, flags); matcher = pattern.matcher(text); int matches = 0; while (matcher.find())&#123; matches++; &#125; return matches;&#125; 在本节中，我们将查看不同的受支持标志及其使用方式。 Pattern.CANON_EQ此标志启用规范等效。如果指定，当且仅当它们的完整规范分解匹配时，才会认为两个字符匹配。 考虑重音字符é。它的复合Unicode代码是u00E9。但是，Unicode还为其组件字符e(u0065)和急性重音u0301分别设置了一个代码点。在这种情况下，复合字符u00E9与两个字符序列u0065 u0301无法区分。在http://tool.chinaz.com/tools/unicode.aspx 输入Unicode: \\u00E9和\\u0065\\u0301转化后是同一个字符 默认情况下，匹配不会将规范等效考虑在内 123456@Testpublic void givenRegexWithoutCanonEq_whenMatchFailsOnEquivalentUnicode_thenCorrect() &#123; int matches = runTest(&quot;\\u00E9&quot;, &quot;\\u0065\\u0301&quot;); assertFalse(matches &gt; 0); // 注意这里是assertFalse&#125; 但是如果我们添加标志，那么测试将通过: 123456@Testpublic void givenRegexWithCanonEq_whenMatchesOnEquivalentUnicode_thenCorrect() &#123; int matches = runTest(&quot;\\u00E9&quot;, &quot;\\u0065\\u0301&quot;, Pattern.CANON_EQ); assertTrue(matches &gt; 0);&#125; Pattern.CASE_INSENSITIVE该标志无论大小写都能够进行匹配。默认情况下，匹配将案例考虑在内： 123456@Testpublic void givenRegexWithDefaultMatcher_whenMatchFailsOnDifferentCases_thenCorrect() &#123; int matches = runTest(&quot;dog&quot;, &quot;This is a Dog&quot;); assertFalse(matches &gt; 0);&#125; 因此，使用此标志，我们可以更改默认行为： 1234567@Testpublic void givenRegexWithCaseInsensitiveMatcher_whenMatchesOnDifferentCases_thenCorrect() &#123; int matches = runTest( &quot;dog&quot;, &quot;This is a Dog&quot;, Pattern.CASE_INSENSITIVE); assertTrue(matches &gt; 0);&#125; 我们还可以使用等效的嵌入式标志表达式来实现相同的结果：123456@Testpublic void givenRegexWithEmbeddedCaseInsensitiveMatcher_whenMatchesOnDifferentCases_thenCorrect() &#123; int matches = runTest(&quot;(?i)dog&quot;, &quot;This is a Dog&quot;); assertTrue(matches &gt; 0);&#125; Pattern.COMMENTSTJava API允许在正则表达式中使用＃包含注释。这有助于记录复杂的正则表达式，这对于另一个程序员来说可能并不是很明显。 comments标志使匹配器忽略正则表达式中的任何空格或注释，只考虑模式。在默认匹配模式下，以下测试将失败： 1234567@Testpublic void givenRegexWithComments_whenMatchFailsWithoutFlag_thenCorrect() &#123; int matches = runTest( &quot;dog$ #check for word dog at end of text&quot;, &quot;This is a dog&quot;); assertFalse(matches &gt; 0);&#125; 这是因为匹配器将在输入文本中查找整个正则表达式，包括空格和＃字符。但是当我们使用该标志时，它将忽略额外的空格，并且以＃开头的每个文本将被视为每行忽略的注释： 1234567@Testpublic void givenRegexWithComments_whenMatchesWithFlag_thenCorrect() &#123; int matches = runTest( &quot;dog$ #check end of text&quot;,&quot;This is a dog&quot;, Pattern.COMMENTS); assertTrue(matches &gt; 0);&#125; 还有一个替代的嵌入式标志表达式： 1234567@Testpublic void givenRegexWithComments_whenMatchesWithEmbeddedFlag_thenCorrect() &#123; int matches = runTest( &quot;(?x)dog$ #check end of text&quot;, &quot;This is a dog&quot;); assertTrue(matches &gt; 0);&#125; Pattern.DOTALL默认情况下，当我们在regex中使用点“.”表达式时，我们匹配输入String中的每个字符，直到遇到新的行字符。 使用此标志，匹配也将包括行终止符。 我们将通过以下示例更好地理解。这些例子会有所不同。由于我们对匹配的String断言感兴趣，因此我们将使用matcher的group方法返回上一个匹配项。 首先，我们将看到默认行为： 12345678910@Testpublic void givenRegexWithLineTerminator_whenMatchFails_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;(.*)&quot;); Matcher matcher = pattern.matcher( &quot;this is a text&quot; + System.getProperty(&quot;line.separator&quot;) + &quot; continued on another line&quot;); matcher.find(); assertEquals(&quot;this is a text&quot;, matcher.group(1));&#125; 我们可以看到，只有行终止符之前输入的第一部分匹配。 下面的示例处于dotall模式，包括行终止符的整个文本将匹配： 1234567891011@Testpublic void givenRegexWithLineTerminator_whenMatchesWithDotall_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;(.*)&quot;, Pattern.DOTALL); Matcher matcher = pattern.matcher( &quot;this is a text&quot; + System.getProperty(&quot;line.separator&quot;) + &quot; continued on another line&quot;); matcher.find(); assertEquals( &quot;this is a text&quot; + System.getProperty(&quot;line.separator&quot;) + &quot; continued on another line&quot;, matcher.group(1));&#125; 我们还可以使用嵌入式标志表达式来启用dotall模式： 12345678910111213@Testpublic void givenRegexWithLineTerminator_whenMatchesWithEmbeddedDotall_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;(?s)(.*)&quot;); Matcher matcher = pattern.matcher( &quot;this is a text&quot; + System.getProperty(&quot;line.separator&quot;) + &quot; continued on another line&quot;); matcher.find(); assertEquals( &quot;this is a text&quot; + System.getProperty(&quot;line.separator&quot;) + &quot; continued on another line&quot;, matcher.group(1));&#125; Pattern.LITERAL在此模式下，matcher对任何元字符，转义字符或正则表达式语法没有特殊含义。如果没有此标志，匹配器将对任何输入字符串匹配以下正则表达式： 123456@Testpublic void givenRegex_whenMatchFailsWithLiteralFlag_thenCorrect() &#123; int matches = runTest(&quot;(.*)&quot;, &quot;text&quot;, Pattern.LITERAL); assertFalse(matches &gt; 0);&#125; 现在，如果我们添加所需的字符串，测试将通过： 123456@Testpublic void givenRegex_whenMatchesWithLiteralFlag_thenCorrect() &#123; int matches = runTest(&quot;(.*)&quot;, &quot;text(.*)&quot;, Pattern.LITERAL); assertTrue(matches &gt; 0);&#125; 没有用于启用文字解析的嵌入标志字符。 Pattern.MULTILINE默认情况下，^和$ metacharacters分别在整个输入String的开头和结尾处匹配。匹配器忽略任何行终止符：12345678@Testpublic void givenRegex_whenMatchFailsWithoutMultilineFlag_thenCorrect() &#123; int matches = runTest( &quot;dog$&quot;, &quot;This is a dog&quot; + System.getProperty(&quot;line.separator&quot;) + &quot;this is a fox&quot;); assertFalse(matches &gt; 0);&#125; 上面匹配失败，因为匹配器在整个String的末尾搜索dog，但是狗出现在字符串第一行的末尾。 但是，使用该标志，相同的测试将通过，因为匹配器现在考虑了行终止符。所以String line就在行终止之前找到，因此成功：12345678@Testpublic void givenRegex_whenMatchesWithMultilineFlag_thenCorrect() &#123; int matches = runTest( &quot;dog$&quot;, &quot;This is a dog&quot; + System.getProperty(&quot;line.separator&quot;) + &quot;this is a fox&quot;, Pattern.MULTILINE); assertTrue(matches &gt; 0);&#125; 这是嵌入式标志版本： 123456789@Testpublic void givenRegex_whenMatchesWithEmbeddedMultilineFlag_ thenCorrect() &#123; int matches = runTest( &quot;(?m)dog$&quot;, &quot;This is a dog&quot; + System.getProperty(&quot;line.separator&quot;) + &quot;this is a fox&quot;); assertTrue(matches &gt; 0);&#125; Matcher Class Methods在本节中，我们将介绍Matcher类的一些有用方法。我们将根据功能对它们进行分组以便清晰。 Index Methods索引方法提供有用的索引值，可以精确显示在输入String中找到匹配的位置。在下面的测试中，我们将在输入String中确认dog匹配的开始和结束索引： 123456789@Testpublic void givenMatch_whenGetsIndices_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;dog&quot;); Matcher matcher = pattern.matcher(&quot;This dog is mine&quot;); matcher.find(); assertEquals(5, matcher.start()); assertEquals(8, matcher.end());&#125; Methods match and lookingAt研究方法遍历输入String并返回一个布尔值，指示是否找到该模式。常用的是match和lookingAt方法。 matches和lookingAt方法都尝试将输入序列与模式匹配。不同之处在于，匹配需要匹配整个输入序列，而查找则不需要。 Both methods start at the beginning of the input String : 12345678@Testpublic void whenStudyMethodsWork_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;dog&quot;); Matcher matcher = pattern.matcher(&quot;dogs are friendly&quot;); assertTrue(matcher.lookingAt()); assertFalse(matcher.matches());&#125; 两种方法都从输入String的开头开始： 1234567@Testpublic void whenMatchesStudyMethodWorks_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;dog&quot;); Matcher matcher = pattern.matcher(&quot;dog&quot;); assertTrue(matcher.matches());&#125; Replacement Methods替换方法对于替换输入字符串中的文本很有用。常见的是replaceFirst和replaceAll。 replaceFirst和replaceAll方法替换匹配给定正则表达式的文本。正如其名称所示，replaceFirst替换第一个匹配项，replaceAll替换所有匹配项： 12345678910@Testpublic void whenReplaceFirstWorks_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;dog&quot;); Matcher matcher = pattern.matcher( &quot;dogs are domestic animals, dogs are friendly&quot;); String newStr = matcher.replaceFirst(&quot;cat&quot;); assertEquals( &quot;cats are domestic animals, dogs are friendly&quot;, newStr);&#125; 替换所有匹配项：123456789@Testpublic void whenReplaceAllWorks_thenCorrect() &#123; Pattern pattern = Pattern.compile(&quot;dog&quot;); Matcher matcher = pattern.matcher( &quot;dogs are domestic animals, dogs are friendly&quot;); String newStr = matcher.replaceAll(&quot;cat&quot;); assertEquals(&quot;cats are domestic animals, cats are friendly&quot;, newStr);&#125;","categories":[],"tags":[]},{"title":"Java 正则表达式示例","slug":"Java-Technologies/java-regular-expression-example","date":"2018-12-21T01:49:26.446Z","updated":"2018-12-21T02:19:34.447Z","comments":true,"path":"Java-Technologies/java-regular-expression-example/","link":"","permalink":"http://it.jiu-shu.com/Java-Technologies/java-regular-expression-example/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package test.com;import static org.junit.Assert.*;import java.util.regex.Matcher;import java.util.regex.Pattern;import org.junit.Test;/** * Unit Test for domain regular expression * @author Joe */public class DomainRegexTester &#123; private final static Pattern mainDomainPattern = Pattern.compile(&quot;(m\\\\.)?((www|en|pt|es|ru)\\\\.)?okchem\\\\.com&quot;); private final static Pattern vipDomainPattern = Pattern.compile(&quot;(\\\\w&#123;3,30&#125;)\\\\.(m\\\\.)?((en|pt|es|ru)\\\\.)okchem\\\\.com&quot;); public static boolean match(String regex, String text) &#123; Pattern pattern = Pattern.compile(regex); Matcher matcher = pattern.matcher(text); return matcher.matches(); &#125; @Test public void testMatchGroup_NonVIP_PC() &#123; Matcher pcMatcherWww = mainDomainPattern.matcher(&quot;www.okchem.com&quot;); if(pcMatcherWww.find()) &#123; assertTrue(&quot;www&quot;.equals(pcMatcherWww.group(3))); assertTrue(&quot;www.&quot;.equals(pcMatcherWww.group(2))); &#125; Matcher pcMatcherEn = mainDomainPattern.matcher(&quot;en.okchem.com&quot;); if(pcMatcherEn.find()) &#123; assertTrue(pcMatcherEn.group(1)==null); assertTrue(&quot;en&quot;.equals(pcMatcherEn.group(3))); &#125; Matcher mobileMatcherEn = mainDomainPattern.matcher(&quot;m.okchem.com&quot;); if(mobileMatcherEn.find()) &#123; assertTrue(&quot;m.&quot;.equals(mobileMatcherEn.group(1))); &#125; Matcher mobileMatcherEs = mainDomainPattern.matcher(&quot;m.es.okchem.com&quot;); if(mobileMatcherEs.find()) &#123; assertTrue(&quot;es&quot;.equals(mobileMatcherEs.group(3))); assertTrue(&quot;es.&quot;.equals(mobileMatcherEs.group(2))); &#125; &#125; @Test public void testMainDomainMatch() &#123; assertTrue(matchMain(&quot;www.okchem.com&quot;)); assertTrue(matchMain(&quot;pt.okchem.com&quot;)); assertTrue(matchMain(&quot;es.okchem.com&quot;)); assertTrue(matchMain(&quot;pt.okchem.com&quot;)); assertTrue(matchMain(&quot;ru.okchem.com&quot;)); assertTrue(matchMain(&quot;m.okchem.com&quot;)); assertTrue(matchMain(&quot;m.pt.okchem.com&quot;)); assertTrue(matchMain(&quot;m.es.okchem.com&quot;)); assertTrue(matchMain(&quot;m.ru.okchem.com&quot;)); assertTrue(matchMain(&quot;m.www.okchem.com&quot;)); assertFalse(matchMain(&quot;m.www.jiu-shu.com&quot;)); &#125; public void testVipDomainmatch() &#123; /*** VIP store domain ***/ assertTrue(matchVIP(&quot;vipcode.ru.okchem.com&quot;)); assertTrue(matchVIP(&quot;vipcode.en.okchem.com&quot;)); assertTrue(matchVIP(&quot;vipcode.es.okchem.com&quot;)); assertTrue(matchVIP(&quot;vipcode.pt.okchem.com&quot;)); assertTrue(matchVIP(&quot;vipcode.m.pt.okchem.com&quot;)); assertTrue(matchVIP(&quot;vipcode.m.ru.okchem.com&quot;)); assertTrue(matchVIP(&quot;vipcode.m.en.okchem.com&quot;)); assertTrue(matchVIP(&quot;vipcode.m.es.okchem.com&quot;)); assertFalse(matchVIP(&quot;v.pt.okchem.com&quot;));// vipcode is too short assertTrue(matchVIP(&quot;abcdefghij12345678901234567980.en.okchem.com&quot;));// vipcode is just 30 assertFalse(matchVIP(&quot;abcdefghij123456789012345679801.pt.okchem.com&quot;));// vipcode is too short assertFalse(matchVIP(&quot;v.m.pt.okchem.com&quot;));// vipcode is too short assertTrue(matchVIP(&quot;abcdefghij12345678901234567980.m.pt.okchem.com&quot;));// vipcode is just 30 assertFalse(matchVIP(&quot;abcdefghij123456789012345679801.m.pt.okchem.com&quot;));// vipcode is too short &#125; public static boolean matchMain(String text) &#123; Matcher matcher = mainDomainPattern.matcher(text); return matcher.matches(); &#125; public static boolean matchVIP(String text) &#123; Matcher matcher = vipDomainPattern.matcher(text); return matcher.matches(); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package test.com;import static org.junit.Assert.*;import java.util.regex.Matcher;import java.util.regex.Pattern;import org.junit.Test;/** * Unit Test for domain regular expression * @author Joe */public class DomainRegexTester &#123; private final static Pattern pattern = Pattern.compile(&quot;(\\\\w&#123;3,30&#125;\\\\.)?(m\\\\.)?((www|en|pt|es|ru)\\\\.)?okchem\\\\.com&quot;); public static boolean match(String regex, String text) &#123; Pattern pattern = Pattern.compile(regex); Matcher matcher = pattern.matcher(text); return matcher.matches(); &#125; @Test public void testMatchGroup_NonVIP_PC() &#123; Matcher matcher1 = pattern.matcher(&quot;www.okchem.com&quot;); if(matcher1.find()) &#123; assertTrue(&quot;www.&quot;.equals(matcher1.group(1))); assertTrue(matcher1.group(2)==null); assertTrue(matcher1.group(3)==null); assertTrue(matcher1.group(4)==null); &#125; Matcher matcher2 = pattern.matcher(&quot;en.okchem.com&quot;); if(matcher2.find()) &#123; assertTrue(&quot;en&quot;.equals(matcher2.group(4))); assertTrue(matcher2.group(2)==null); assertTrue(&quot;en.&quot;.equals(matcher2.group(3))); &#125; &#125; @Test public void testMatchGroup() &#123; Matcher matcher = pattern.matcher(&quot;www.okchem.com&quot;); if(matcher.find()) &#123; assertTrue(&quot;www.&quot;.equals(matcher.group(1))); assertTrue(matcher.group(2)==null); assertTrue(matcher.group(3)==null); &#125; &#125; @Test public void testParseLanguage_NonLanguage() throws Exception &#123; assertTrue(parseLanguageFromText(&quot;www.okchem.com&quot;)==null); assertTrue(parseLanguageFromText(&quot;m.okchem.com&quot;)==null); &#125; @Test public void testParseLanguage_HasLanguage() throws Exception &#123; assertTrue(&quot;pt&quot;.equals(parseLanguageFromText(&quot;pt.okchem.com&quot;))); assertTrue(&quot;pt&quot;.equals(parseLanguageFromText(&quot;m.pt.okchem.com&quot;))); assertTrue(&quot;ru&quot;.equals(parseLanguageFromText(&quot;vipcode.ru.okchem.com&quot;))); assertTrue(&quot;pt&quot;.equals(parseLanguageFromText(&quot;vipcode.m.pt.okchem.com&quot;))); &#125; @Test public void testDomainMatch() &#123; assertTrue(match(&quot;www.okchem.com&quot;)); assertTrue(match(&quot;pt.okchem.com&quot;)); assertTrue(match(&quot;es.okchem.com&quot;)); assertTrue(match(&quot;pt.okchem.com&quot;)); assertTrue(match(&quot;ru.okchem.com&quot;)); assertTrue(match(&quot;m.okchem.com&quot;)); assertTrue(match(&quot;m.pt.okchem.com&quot;)); assertTrue(match(&quot;m.es.okchem.com&quot;)); assertTrue(match(&quot;m.ru.okchem.com&quot;)); /*** VIP store domain ***/ assertTrue(match(&quot;vipcode.ru.okchem.com&quot;)); assertTrue(match(&quot;vipcode.en.okchem.com&quot;)); assertTrue(match(&quot;vipcode.es.okchem.com&quot;)); assertTrue(match(&quot;vipcode.pt.okchem.com&quot;)); assertTrue(match(&quot;vipcode.m.pt.okchem.com&quot;)); assertTrue(match(&quot;vipcode.m.ru.okchem.com&quot;)); assertTrue(match(&quot;vipcode.m.en.okchem.com&quot;)); assertTrue(match(&quot;vipcode.m.es.okchem.com&quot;)); assertFalse(match(&quot;vi.pt.okchem.com&quot;));// vipcode is too short assertTrue(match(&quot;abcdefghij12345678901234567980.en.okchem.com&quot;));// vipcode is just 30 assertFalse(match(&quot;abcdefghij123456789012345679801.pt.okchem.com&quot;));// vipcode is too short assertFalse(match(&quot;vi.m.pt.okchem.com&quot;));// vipcode is too short assertTrue(match(&quot;abcdefghij12345678901234567980.m.pt.okchem.com&quot;));// vipcode is just 30 assertFalse(match(&quot;abcdefghij123456789012345679801.m.pt.okchem.com&quot;));// vipcode is too short assertTrue(match(&quot;m.www.okchem.com&quot;)); assertFalse(match(&quot;m.www.jiu-shu.com&quot;)); &#125; public static boolean match(String text) &#123; Matcher matcher = pattern.matcher(text); return matcher.matches(); &#125; public static String parseLanguageFromText(String text) throws Exception &#123; Matcher matcherPc = pattern.matcher(text); if(matcherPc.find()) &#123; return matcherPc.group(4); &#125; throw new Exception(&quot;Not Match&quot;); &#125; &#125;","categories":[],"tags":[]},{"title":"Java并发编程的艺术 -02 Java并发机制的底层实现原理","slug":"Java-Technologies/Java-Concurrency-2","date":"2018-12-21T01:49:26.442Z","updated":"2018-12-21T02:19:31.744Z","comments":true,"path":"Java-Technologies/Java-Concurrency-2/","link":"","permalink":"http://it.jiu-shu.com/Java-Technologies/Java-Concurrency-2/","excerpt":"","text":"读Java 并发编程的艺术第二章 - Java并发机制的底层实现原理 volatile关键字volatile是轻量级的synchronized, 不会引起线程上下文的切换。volatile 只能保证其修饰变量的原子操作的数据一致，一些比如num++ 等都是复合操作，仅仅靠volatile修饰变量是无法保证并发情况下的数据一致的; 因此volatile不能像synchronized那样普遍用于线程安全。 线程安全的场景，一般来说我们很容易想到类似购票系统这种场景(安全计数器), 但是由于上面介绍的原因，仅仅靠volatile关键字是做不到’安全计数’的。 关于具体使用场景可以参考：文章： http://blog.csdn.net/hxpjava1/article/details/55188908 。 synchronized 会引起上线文切换? 以下示例说明了非原子操作的时候，volatile无法保证数据12345678910111213141516171819202122232425262728293031323334public class NonAtomicOperationOnVolatile &#123; static volatile int count = 0; public static void main(String[] args) &#123; Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; count--; &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; count++; &#125; &#125; &#125;); t1.start(); t2.start(); try &#123; t1.join(); t2.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(count); // 不是 0 &#125;&#125; synchronized 关键字synchronzied是偏重量级，但是在并发不是很大的情况下的优选实现方式。Java中的每一个对象都可以作为锁： 对于实例方法：锁是当前对象 对于静态方法：锁是当前类的Class 对象 对于同步方法块： 锁是synnchronized括号里的对象","categories":[],"tags":[]},{"title":"Java并发编程的艺术-01-并发编程的挑战","slug":"Java-Technologies/Java-Concurrency-1","date":"2018-12-21T01:49:26.440Z","updated":"2018-12-21T02:19:27.528Z","comments":true,"path":"Java-Technologies/Java-Concurrency-1/","link":"","permalink":"http://it.jiu-shu.com/Java-Technologies/Java-Concurrency-1/","excerpt":"","text":"并发编程的目的是为了让程序运行的更快 知识点汇总 并非启动更多线程程序并发就最大 多线程不一定就快，线程的创建和上下文切换需要成本 减少上下文切换 无锁并发 - 通过ID将数据分开 CAS算法； 使用Java的Atomic包 使用最少线程；避免创建不必要的线程导致太多线程等待 死锁示例下面的示例一般不会出现在大家的代码中，只做展示。 很多面试会有考死锁，简单来说当线程同时需要获取多个锁就很容易出现死锁 12345678910111213141516171819202122232425262728293031323334353637383940public class DeadLock &#123; public static String A = \"A\"; public static String B = \"B\"; public static void main(String[] args) &#123; Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (A) &#123; System.out.println(\"T1 Locked A\"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (B) &#123; System.out.println(\"T1 Locked B\"); &#125; &#125; &#125; &#125;); Thread t2 =new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (B) &#123; System.out.println(\"T2 Locked B\"); synchronized (A) &#123; System.out.println(\"T2 Locked A\"); &#125; &#125; &#125; &#125;); t1.start(); t2.start(); &#125;&#125; 避免死锁的出现 避免一个线程同时获取多个锁 资源限制当资源(cpu)的利用率已经很高，达到或者接近100%的时候，增加线程反而导致程序运行的更慢。","categories":[],"tags":[]},{"title":"无线路由器桥接步骤","slug":"It-Infrastructures/Wireless-Bridging","date":"2018-12-21T01:49:26.434Z","updated":"2018-11-01T01:03:17.004Z","comments":true,"path":"It-Infrastructures/Wireless-Bridging/","link":"","permalink":"http://it.jiu-shu.com/It-Infrastructures/Wireless-Bridging/","excerpt":"","text":"路由器A已经设置可以上网; 路由器A提供DHCP服务，网关地址：192.168.1.1; 现将无线路由器B桥接到A来扩大信号范围。步骤如下： 一：重置无线路由器B重置到初始状态 二：设置初始密码浏览器登录路由器B，一般登录地址192.168.1.1。 第一次打开，会提示输入密码：（假设输入密码：Peng12345） 三：设置无线路路由器的安全关闭WPS无线设置 &gt; WPS &gt; 关闭设置完成，等待路由器重启 设置密码无线设置 &gt; 无线安全设置 &gt; WPA-PSK/WPA2-PSK认证类型： WPA2； 加密算法： SKIP；设置密码 （比如： 66668888）此类算法目前万能钥匙服务破解。 保存后路由器重启，重新输入密码进行连接。 四：设置桥接进入 无线设置 &gt; 基本设置页面； 设置SSID名称； 点击开启WDS；通过扫描选择路由器A; (如果知道A的SSID和加密及信道信息等，可以直接输入)。 点击扫描后会列出供选择的wifi，选择A点击链接；输入对应的加密方式和密码。 然后路由器会重启，此时我们连接路由器B即可上网 在设置桥接的时候需要选定信道，保存的时候如果设置的信道和A的无线信号的信道不一致将无法保存；同时会提示并提示信道是几。为了保证B上网通畅，需要将A的无线信号的信道选定一个，而不是自动，防止重启路由信道变化后导致无法通过路由器B上网。 五：修改Lan 口地址 &amp; 关闭DHCP服务进入：网络参数&gt;Lan口设置；修改Lan口的地址为192.168.1.2 防止和A冲突；同时关闭DHCP服务。 关闭DHCP后有可能动态分配的IP地址和路由器的IP地址不在一个网段，比如：手机终端的地址是：192.168.2.101，这个时候手机浏览器是无法打开http://192.168.1.2 来配置路由器B的。如果需要进一步配置路由器B，则需要手动设置终端的静态IP地址，保证和路由器同一个网段（比如：192.168.1.13）来连接配置路由器B。配置完成后需要清除静态的IP地址，切换至动态IP地址才能上网。 六： 连接路由器B上网去吧把B放在你家窗口，和其他家的路由器桥接起来共享你们的网络吧。","categories":[],"tags":[]},{"title":"Mac Pro 上 配置 Shadowsocks NG","slug":"It-Infrastructures/shadowsocks-ng-mac","date":"2018-12-21T01:49:26.430Z","updated":"2018-12-21T02:47:14.855Z","comments":true,"path":"It-Infrastructures/shadowsocks-ng-mac/","link":"","permalink":"http://it.jiu-shu.com/It-Infrastructures/shadowsocks-ng-mac/","excerpt":"","text":"购买了shadowsocks 账号后，只需要下载Shadowsocks NG简单配置即可完成翻墙。下载地址：https://github.com/shadowsocks/ShadowsocksX-NG 百度shadowsocks搜不到什么文章，估计是被屏蔽了，可以理解，估计大部分翻墙的都是要上google的。 CDN上有很多文章，不过由于更新问题，大部分都容易误导人。 上面链接去找下载地址，下载后是无需安装的，直接运行。通过server -&gt; perference 来配置后即可。","categories":[],"tags":[]}]}